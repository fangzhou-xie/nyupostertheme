
@book{mueller2003,
  address = {{Cambridge ; New York}},
  edition = {3 edition},
  title = {Public {{Choice III}}},
  isbn = {978-0-521-89475-3},
  abstract = {This book represents a considerable revision and expansion of Public Choice II (1989). As in the previous editions, all of the major topics of public choice are covered. These include: why the state exists, voting rules, federalism, the theory of clubs, two-party and multiparty electoral systems, rent seeking, bureaucracy, interest groups, dictatorship, the size of government, voter participation, and political business cycles. Normative issues in public choice are also examined. The book is suitable for upper level courses in economics dealing with politics, and political science courses emphasizing rational actor models.},
  language = {English},
  publisher = {{Cambridge University Press}},
  author = {Mueller, Dennis C.},
  year = {2003}
}

@article{lemieux2004,
  title = {The {{Public Choice Revolution Theory}}},
  volume = {27},
  language = {eng},
  journal = {Regulation},
  author = {Lemieux, Pierre},
  year = {2004},
  pages = {22-29},
  file = {/Users/xiefangzhou/Zotero/storage/M6GMHVWE/Lemieux - 2004 - The Public Choice Revolution Theory.pdf}
}

@article{buchanan1959,
  title = {Positive {{Economics}}, {{Welfare Economics}}, and {{Political Economy}}},
  volume = {2},
  issn = {0022-2186},
  journal = {The Journal of Law and Economics},
  author = {Buchanan, James M.},
  year = {1959},
  pages = {124-138},
  file = {/Users/xiefangzhou/Zotero/storage/TBP2QWD6/466556.html}
}

@article{2018a,
  title = {Naval {{Base San Diego}}},
  copyright = {Creative Commons Attribution-ShareAlike License},
  abstract = {Naval Base San Diego, which locals refer to as 32nd Street Naval Station, is the second largest Surface Ship base of the United States Navy and is located in San Diego, California. Naval Base San Diego is the principal homeport of the Pacific Fleet, consisting of over 50 ships and over 190 tenant commands. The base is composed of 13 piers stretched over 977 acres (3.95 km2) of land and 326 acres (1.32 km2) of water. The total on base population is over 24,000 military personnel and over 10,000 civilians.},
  language = {en},
  journal = {Wikipedia},
  year = {2018},
  file = {/Users/xiefangzhou/Zotero/storage/QBXUAMY6/index.html},
  note = {Page Version ID: 855169090}
}

@book{russell1967,
  address = {{New York u.a}},
  title = {A {{History}} of {{Western Philosophy}}},
  isbn = {978-0-671-20158-6},
  abstract = {Hailed as ``lucid and magisterial'' by The Observer, this book is universally acclaimed as the outstanding one-volume work on the subject of Western philosophy.Considered to be one of the most important philosophical works of all time, the History of Western Philosophy is a dazzlingly unique exploration of the ideologies of significant philosophers throughout the ages\textemdash{}from Plato and Aristotle through to Spinoza, Kant and the twentieth century. Written by a man who changed the history of philosophy himself, this is an account that has never been rivaled since its first publication over sixty years ago. Since its first publication in 1945, Lord Russell's A History of Western Philosophy is still unparalleled in its comprehensiveness, its clarity, its erudition, its grace, and its wit. In seventy-six chapters he traces philosophy from the rise of Greek civilization to the emergence of logical analysis in the twentieth century.  Among the philosophers considered are: Pythagoras, Heraclitus, Parmenides, Empedocles, Anaxagoras, the Atomists, Protagoras, Socrates, Plato, Aristotle, the Cynics, the Sceptics, the Epicureans, the Stoics, Plotinus, Ambrose, Jerome, Augustine, Benedict, Gregory the Great, John the Scot, Aquinas, Duns Scotus, William of Occam, Machiavelli, Erasmus, More, Bacon, Hobbes, Descartes, Spinoza, Leibniz, Locke, Berkeley, Hume, Rousseau, Kant, Hegel, Schopenhauer, Nietzsche, the Utilitarians, Marx, Bergson, James, Dewey, and lastly the philosophers with whom Lord Russell himself is most closely associated\textemdash{}Cantor, Frege, and Whitehead, coauthor with Russell of the monumental Principia Mathematica.},
  language = {English},
  publisher = {{Simon \& Schuster/Touchstone}},
  author = {Russell, Bertrand},
  year = {1967}
}

@article{samuelson1954,
  title = {The {{Pure Theory}} of {{Public Expenditure}}},
  volume = {36},
  issn = {0034-6535},
  number = {4},
  journal = {The Review of Economics and Statistics},
  author = {Samuelson, Paul A.},
  year = {1954},
  pages = {387-389},
  file = {/Users/xiefangzhou/Zotero/storage/6IEKBJBX/Samuelson - 1954 - The Pure Theory of Public Expenditure.pdf}
}

@article{tullock1967,
  title = {The {{Welfare Costs}} of {{Tariffs}}, {{Monopolies}}, and {{Theft}}},
  volume = {5},
  issn = {1465-7295},
  language = {en},
  number = {3},
  journal = {Economic Inquiry},
  author = {Tullock, Gordon},
  year = {1967},
  pages = {224-232},
  file = {/Users/xiefangzhou/Zotero/storage/87WD5FLR/Tullock - 1967 - The Welfare Costs of Tariffs, Monopolies, and Thef.pdf;/Users/xiefangzhou/Zotero/storage/DL4SH52I/j.1465-7295.1967.tb01923.html}
}

@article{niskanen1968,
  title = {The {{Peculiar Economics}} of {{Bureaucracy}}},
  volume = {58},
  issn = {0002-8282},
  number = {2},
  journal = {The American Economic Review},
  author = {Niskanen, William A.},
  year = {1968},
  pages = {293-305},
  file = {/Users/xiefangzhou/Zotero/storage/IIHJSC5P/Niskanen - 1968 - The Peculiar Economics of Bureaucracy.pdf}
}

@article{coyne2008,
  title = {The {{Politics}} of {{Bureaucracy}} and the Failure of Post-War Reconstruction},
  volume = {135},
  issn = {1573-7101},
  abstract = {Gordon Tullock's The Politics of Bureaucracy must be considered one of the most important works on bureaucracy ever written. In this paper, I argue that Tullock's analysis of bureaucracy is as relevant as ever. To support this claim, I focus on U.S.-led reconstruction efforts which attempt to export liberal democracy via military occupation. Bureaucratic organizations play a key role in these reconstruction efforts and as such, Tullock's analysis is directly relevant. It is argued that Tullock's study clarifies not just the limits of bureaucratic activity, but also the importance of spontaneous orders for coordinating activities outside those limits and generating the very institutional context in which liberal democracy can evolve and sustain. The main conclusion is that the nature of public bureaucracy constrains the ability of the United States to exogenously impose liberal democratic institutions in foreign countries for the very reasons Tullock emphasized long ago.},
  language = {en},
  number = {1},
  journal = {Public Choice},
  author = {Coyne, Christopher J.},
  year = {2008},
  keywords = {Bureaucracy,D73,P16,Reconstruction,Spontaneous order},
  pages = {11-22},
  file = {/Users/xiefangzhou/Zotero/storage/RQ2A9P7M/Coyne - 2008 - The Politics of Bureaucracy and the failure of pos.pdf}
}

@article{2018,
  title = {Chinese Investment, and Influence, in {{Europe}} Is Growing},
  issn = {0013-0613},
  abstract = {The EU is, at last, beginning to take notice},
  journal = {The Economist},
  year = {2018-10-04T00:00:00Z, 2018-10-04T00:00:00Z},
  file = {/Users/xiefangzhou/Zotero/storage/E9IDRVBM/chinese-investment-and-influence-in-europe-is-growing.html}
}

@article{fehr1999,
  title = {A {{Theory}} of {{Fairness}}, {{Competition}}, and {{Cooperation}}},
  volume = {114},
  issn = {0033-5533},
  abstract = {Abstract.  There is strong evidence that people exploit their bargaining power in competitive markets but not in bilateral bargaining situations. There is also},
  language = {en},
  number = {3},
  journal = {The Quarterly Journal of Economics},
  author = {Fehr, Ernst and Schmidt, Klaus M.},
  year = {1999},
  pages = {817-868},
  file = {/Users/xiefangzhou/Zotero/storage/GZHK8HLX/Fehr and Schmidt - 1999 - A Theory of Fairness, Competition, and Cooperation.pdf;/Users/xiefangzhou/Zotero/storage/HTSHTMA6/1848113.html}
}

@article{hillman2010,
  title = {Expressive Behavior in Economics and Politics},
  volume = {26},
  issn = {0176-2680},
  abstract = {Expressive behavior is the self-interested quest for utility through acts and declarations that confirm a person's identity. Expressive voting is an example of expressive behavior. I introduce expressive behavior in the forms of expressive rhetoric and expressive generosity. The questions for society and for public policy are whether expressive behavior affects others, and if so whether beneficially or disadvantageously. In experiments, expressive behavior often benefits others. There are adverse social consequences when, in real-life decisions, expressive behavior results in unwanted public policies of expressive-policy traps. I consider the prospects for avoiding or exiting expressive-policy traps.},
  number = {4},
  journal = {European Journal of Political Economy},
  author = {Hillman, Arye L.},
  year = {2010},
  keywords = {Generosity,Identity,Policy trap,Rhetoric,Voting},
  pages = {403-418},
  file = {/Users/xiefangzhou/Zotero/storage/K4892GNF/Hillman - 2010 - Expressive behavior in economics and politics.pdf;/Users/xiefangzhou/Zotero/storage/KTHSYIQS/S0176268010000455.html}
}

@article{jones2000,
  title = {Civic {{Duty}} and {{Expressive Voting}}: {{Is Virtue}} Its Own {{Reward}}?},
  volume = {53},
  copyright = {WWZ and Helbing \& Lichtenhahn Verlag AG},
  issn = {1467-6435},
  shorttitle = {Civic {{Duty}} and {{Expressive Voting}}},
  abstract = {Turnout at elections cannot be easily explained by reference to instrumental rationality. The probability that any individual voter will alter an electoral outcome is miniscule and the net expected utility from voting is likely to be negative. Instead, high rates of turnout are explained by the consumption gains arising from the act of voting. This paper distinguishes between utility derived from fulfilling a civic duty and utility derived from expressing a political preference. Both considerations affect turnout but a test of the determinants of the decision of whether to vote and the decision of how to vote reveals that perceptions of the importance of civic duty are important when deciding whether to vote. Differences in preference for the political parties, differences in perceptions of policy certainty and differences in the integrity attributed to representatives of political parties are important when explaining how individuals vote. The implication is that intrinsic motivation is important when individuals consider whether or not to vote and the utility from expressive voting is more relevant when explaining how individuals vote. It follows that it is possible to explain high turnout rates even when there are periods of `consensus politics'. Moreover, policy designed to maintain standards in public life should be framed to `crowd in' intrinsiv motivation.},
  language = {en},
  number = {1},
  journal = {Kyklos},
  author = {Jones, Philip and Hudson, John},
  year = {2000},
  pages = {3-16},
  file = {/Users/xiefangzhou/Zotero/storage/HYEXFS76/Jones and Hudson - 2000 - Civic Duty and Expressive Voting Is Virtue its ow.pdf;/Users/xiefangzhou/Zotero/storage/U6MJMGG2/1467-6435.html}
}

@article{blais1999,
  title = {Why Do People Vote? {{An}} Experiment in Rationality},
  volume = {99},
  issn = {1573-7101},
  shorttitle = {Why Do People Vote?},
  abstract = {The study presents the findings of an experiment conducted during the 1993 Canadian fedeal election campaign. Students in two universities were exposed to a ten-minute presentation about the rational model of voting and the `paradox' that so many people vote when it is apparently irrational on a cost-benefit basis. Our data indicate that exposure to the presentation decreased turnout in the election by seven percentage points. This result contributes to the debate abut the effect of rational-choice models on real political behavior. More important, the experimental panel data permit the presentation's effect to be decomposed, and this helps explain why people do vote. In this study, turnout was reduced mainly because the presentation diminished the respondents' sense of duty, an effect that was indirect, because there was no reference in the presentation to such motives. Framing the voting act in rational-choice terms induced some students to reconsider whether they should feel obliged to vote.},
  language = {en},
  number = {1},
  journal = {Public Choice},
  author = {Blais, Andr{\'e} and Young, Robert},
  year = {1999},
  keywords = {Election Campaign,Panel Data,Political Behavior,Public Finance,Rational Model},
  pages = {39-55},
  file = {/Users/xiefangzhou/Zotero/storage/32667CCS/Blais and Young - 1999 - Why do people vote An experiment in rationality.pdf}
}

@article{schnellenbach2015,
  series = {Behavioral {{Political Economy}}},
  title = {Behavioral Political Economy: {{A}} Survey},
  volume = {40},
  issn = {0176-2680},
  shorttitle = {Behavioral Political Economy},
  abstract = {In explaining individual behavior in politics, economists should rely on the same motivational assumptions they use to explain behavior in the market: that is what Political Economy, understood as the application of economics to the study of political processes, is all about. In its standard variant, individuals who play the game of politics should also be considered rational and self-interested, unlike the benevolent despot of traditional welfare economics. History repeats itself with the rise of behavioral economics: Assuming cognitive biases to be present in the market, but not in politics, behavioral economists often call for government to intervene in a ``benevolent'' way. Recently, however, political economists have started to apply behavioral economics insights to the study of political processes, thereby re-establishing a unified methodology. This paper surveys the current state of the emerging field of ``behavioral political economy'' and considers the scope for further research.},
  journal = {European Journal of Political Economy},
  author = {Schnellenbach, Jan and Schubert, Christian},
  year = {2015},
  keywords = {Voting,Behavioral political economy,Cognitive biases,Paternalism,Rational irrationality,Social norms},
  pages = {395-417},
  file = {/Users/xiefangzhou/Zotero/storage/GH4JAF9N/Schnellenbach and Schubert - 2015 - Behavioral political economy A survey.pdf;/Users/xiefangzhou/Zotero/storage/8WKMFC7U/S0176268015000555.html}
}

@article{viscusi2015,
  title = {Behavioral {{Public Choice}}: {{The Behavioral Paradox}} of {{Government Policy}}},
  volume = {38},
  shorttitle = {Behavioral {{Public Choice}}},
  language = {eng},
  journal = {Harvard Journal of Law \& Public Policy},
  author = {Viscusi, W. Kip and Gayer, Ted},
  year = {2015},
  pages = {973-1008},
  file = {/Users/xiefangzhou/Zotero/storage/RD57PSRB/Viscusi and Gayer - 2015 - Behavioral Public Choice The Behavioral Paradox o.pdf}
}

@book{kahneman2013,
  address = {{New York}},
  edition = {1st edition},
  title = {Thinking, {{Fast}} and {{Slow}}},
  isbn = {978-0-374-53355-7},
  abstract = {Major New York Times bestsellerWinner of the National Academy of Sciences Best Book Award in 2012Selected by the New York Times Book Review as one of the ten best books of 2011A Globe and Mail Best Books of the Year 2011 TitleOne of The Economist's 2011 Books of the Year One of The Wall Street Journal's Best Nonfiction Books of the Year 20112013 Presidential Medal of Freedom RecipientKahneman's work with Amos Tversky is the subject of Michael Lewis's The Undoing Project: A Friendship That Changed Our MindsIn the international bestseller, Thinking, Fast and Slow, Daniel Kahneman, the renowned psychologist and winner of the Nobel Prize in Economics, takes us on a groundbreaking tour of the mind and explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. The impact of overconfidence on corporate strategies, the difficulties of predicting what will make us happy in the future, the profound effect of cognitive biases on everything from playing the stock market to planning our next vacation\rule{1em}{1pt}each of these can be understood only by knowing how the two systems shape our judgments and decisions.Engaging the reader in a lively conversation about how we think, Kahneman reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives\rule{1em}{1pt}and how we can use different techniques to guard against the mental glitches that often get us into trouble. Winner of the National Academy of Sciences Best Book Award and the Los Angeles Times Book Prize and selected by The New York Times Book Review as one of the ten best books of 2011, Thinking, Fast and Slow is destined to be a classic.},
  language = {English},
  publisher = {{Farrar, Straus and Giroux}},
  author = {Kahneman, Daniel},
  year = {2013}
}

@article{caplan2001,
  title = {Rational {{Irrationality}} and the {{Microfoundations}} of {{Political Failure}}},
  volume = {107},
  issn = {1573-7101},
  abstract = {Models of inefficient political failure have been criticized forimplicitly assuming the irrationality of voters (Wittman, 1989,1995, 1999; Coate and Morris, 1995). Building on Caplan's (1999a,1999b) model of ``rational irrationality'', the current papermaintains that the assumption of voter irrationality is boththeoretically and empirically plausible. It then examinesmicrofoundational criticisms of four classes of political failuremodels: rent-seeking, pork-barrel politics, bureaucracy, andeconomic reform. In each of the four cases, incorporating simpleforms of privately costless irrationality makes it possibleto clearly derive the models' standard conclusions. Moreover, itfollows that efforts to mitigate political failures will besocially suboptimal, as most of the literature implicitlyassumes. It is a mistake to discount the empirical evidence forthese models on theoretical grounds.},
  language = {en},
  number = {3},
  journal = {Public Choice},
  author = {Caplan, Bryan},
  year = {2001},
  keywords = {Public Finance,Empirical Evidence,Political Failure,Standard Conclusion,Theoretical Ground},
  pages = {311-331},
  file = {/Users/xiefangzhou/Zotero/storage/A449QCDI/Caplan - 2001 - Rational Irrationality and the Microfoundations of.pdf}
}

@article{caplan2009,
  title = {Irrational Principals},
  volume = {22},
  issn = {1573-7128},
  abstract = {Timothy Besley's Principled Agents? carefully surveys the modern social science literature on political agency problems and tries to chart a sensible middle course between the naive assumption that politicians maximize the public welfare and the pessimism of Virginia-style public choice. However, the literature that Besley showcases is seriously flawed. By building on the empirically discredited rational expectations assumption, it neglects the strongest normative argument against political accountability and overlooks the extent to which ``agency failures'' stem from principal negligence.},
  language = {en},
  number = {2},
  journal = {The Review of Austrian Economics},
  author = {Caplan, Bryan},
  year = {2009},
  keywords = {Behavioral political economy,D03,D72,D78,Principal-agent problems,Voter irrationality},
  pages = {159},
  file = {/Users/xiefangzhou/Zotero/storage/EQD4V2SF/Caplan - 2009 - Irrational principals.pdf}
}

@book{besley2006,
  title = {Principled {{Agents}}?: {{The Political Economy}} of {{Good Government}}},
  isbn = {978-0-19-927150-4},
  shorttitle = {Principled {{Agents}}?},
  abstract = {What is good government? Why do some governments fail? How do you implement political accountability in practice? What incentives do you need to put in place to ensure that politicians and public servants act in the public interest and not their own? These questions and many more are addressed in Timothy Besley's intriguing Lindahl lectures. Economic analyses of government usually divide into two broad camps. One which emphasizes government as a force for public good that can regulate markets, distribute resources and generally work towards improving the lives of its citizens. The other sees government as driven by private interests, susceptible to those with the power to influence its decisions and failing to incentivize its officials to act for the greater public good. This book adopts a middle way between the two extremes, the Publius approach, which recognizes the potential for government to act for the public good but also accepts the fact that things often go wrong. It shares the view that there are certain institutional preconditions for effective government but then proceed to examine exactly what those preconditions are. Timothy Besley emphasises that it is not just about designing an appropriate institutional framework but also about understanding the way incentives work and the process by which the political class is selected.},
  language = {en},
  publisher = {{OUP Oxford}},
  author = {Besley, Timothy},
  year = {2006},
  keywords = {Business \& Economics / Economics / Theory,Business \& Economics / Industries / General,Political Science / General,Political Science / Public Affairs \& Administration,Political Science / Public Policy / Economic Policy}
}

@article{nordin2014,
  title = {Do {{Voters Vote}} in {{Line}} with Their {{Policy Preferences}}?\textemdash{{The Role}} of {{Information}}},
  volume = {60},
  issn = {1610-241X},
  shorttitle = {Do {{Voters Vote}} in {{Line}} with Their {{Policy Preferences}}?},
  abstract = {Abstract.  In this article, I investigate how political information affects voting behavior. Specifically, I test (i) if more informed voters are more likely to},
  language = {en},
  number = {4},
  journal = {CESifo Economic Studies},
  author = {Nordin, Mattias},
  year = {2014},
  pages = {681-721},
  file = {/Users/xiefangzhou/Zotero/storage/IQ7QVJS2/Nordin - 2014 - Do Voters Vote in Line with their Policy Preferenc.pdf;/Users/xiefangzhou/Zotero/storage/2UKHH7AY/447715.html}
}

@article{pons2018,
  title = {Will a {{Five}}-{{Minute Discussion Change Your Mind}}? {{A Countrywide Experiment}} on {{Voter Choice}} in {{France}}},
  volume = {108},
  issn = {0002-8282},
  shorttitle = {Will a {{Five}}-{{Minute Discussion Change Your Mind}}?},
  abstract = {This paper provides the first estimate of the effect of door-to-door canvassing on actual electoral outcomes, via a countrywide experiment embedded in Francois Hollande's campaign in the 2012 French presidential election. While existing experiments randomized door-to-door visits at the individual level, the scale of this campaign (five million doors knocked) enabled randomization by precinct, the level at which vote shares are recorded administratively. Visits did not affect turnout, but increased Hollande's vote share in the first round and accounted for one-fourth of his victory margin in the second. Visits' impact persisted in later elections, suggesting a lasting persuasion effect.},
  language = {en},
  number = {6},
  journal = {American Economic Review},
  author = {Pons, Vincent},
  year = {2018},
  keywords = {Belief,Communication,Field Experiments; Consumer Economics: Empirical Analysis; Analysis of Collective Decision-Making: General; Political Processes: Rent-seeking; Lobbying; Elections; Legislatures; and Voting Behavior; Search,Information and Knowledge,Learning,Unawareness},
  pages = {1322-1363},
  file = {/Users/xiefangzhou/Zotero/storage/GJ4HICKG/Pons - 2018 - Will a Five-Minute Discussion Change Your Mind A .pdf;/Users/xiefangzhou/Zotero/storage/AGI5TM7R/articles.html}
}

@book{caplan2011,
  title = {The {{Myth}} of the {{Rational Voter}}: {{Why Democracies Choose Bad Policies}} - {{New Edition}}},
  isbn = {978-1-4008-2882-1},
  shorttitle = {The {{Myth}} of the {{Rational Voter}}},
  abstract = {The greatest obstacle to sound economic policy is not entrenched special interests or rampant lobbying, but the popular misconceptions, irrational beliefs, and personal biases held by ordinary voters. This is economist Bryan Caplan's sobering assessment in this provocative and eye-opening book. Caplan argues that voters continually elect politicians who either share their biases or else pretend to, resulting in bad policies winning again and again by popular demand. Boldly calling into question our most basic assumptions about American politics, Caplan contends that democracy fails precisely because it does what voters want. Through an analysis of Americans' voting behavior and opinions on a range of economic issues, he makes the convincing case that noneconomists suffer from four prevailing biases: they underestimate the wisdom of the market mechanism, distrust foreigners, undervalue the benefits of conserving labor, and pessimistically believe the economy is going from bad to worse. Caplan lays out several bold ways to make democratic government work better--for example, urging economic educators to focus on correcting popular misconceptions and recommending that democracies do less and let markets take up the slack. The Myth of the Rational Voter takes an unflinching look at how people who vote under the influence of false beliefs ultimately end up with government that delivers lousy results. With the upcoming presidential election season drawing nearer, this thought-provoking book is sure to spark a long-overdue reappraisal of our elective system.},
  language = {en},
  publisher = {{Princeton University Press}},
  author = {Caplan, Bryan},
  year = {2011},
  keywords = {Political Science / General,Political Science / Political Ideologies / Democracy,Political Science / Political Process / Campaigns \& Elections}
}

@techreport{conley2010,
  type = {Working {{Paper}}},
  title = {The {{Effect}} of {{Daughters}} on {{Partisanship}}},
  abstract = {Washington (2008) finds that, controlling for total number of children, each additional daughter makes a member of Congress more likely to vote liberally and attributes this finding to socialization. However, daughters' influence could manifest differently for elite politicians and the general citizenry, thanks to the selection gradient particular to the political process. This study asks whether the proportion of female biological offspring affects political party identification. Using nationally-representative data from the General Social Survey, we find that female offspring induce more conservative political identification. We hypothesize that this results from the change in reproductive fitness strategy that daughters may evince.},
  number = {15873},
  institution = {{National Bureau of Economic Research}},
  author = {Conley, Dalton and Rauscher, Emily},
  year = {2010},
  file = {/Users/xiefangzhou/Zotero/storage/69IGNITH/Conley and Rauscher - 2010 - The Effect of Daughters on Partisanship.pdf}
}

@article{conley2013,
  title = {The {{Effect}} of {{Daughters}} on {{Partisanship}} and {{Social Attitudes Toward Women}}},
  volume = {28},
  copyright = {\textcopyright{} 2013 Eastern Sociological Society},
  issn = {1573-7861},
  abstract = {Washington () finds that daughters promote liberal voting (at least with respect to women's issues) among U.S. Congress members and attributes this finding to socialization. However, daughters' influence could manifest differently for elite politicians and the general citizenry either due to self-selection or the Trivers-Willard hypothesis, which suggests that parents invest differently in male and female children depending on their social status. Using nationally representative data from the General Social Survey, this study asks whether biological daughters affect political party identification, traditional views of women, or opinions about abortion and teen sex. We find that female offspring promote identification with the more conservative Republican Party, but this effect depends on social status. There is no evidence that daughters promote liberal views of women and less consistent evidence that they influence views of abortion or teen sex. Overall, evidence supports the Trivers-Willard hypothesis, but with a more complex interaction by social status.},
  language = {en},
  number = {4},
  journal = {Sociological Forum},
  author = {Conley, Dalton and Rauscher, Emily},
  year = {2013},
  keywords = {attitudes,gender,identification,political behavior,socialization,voting},
  pages = {700-718},
  file = {/Users/xiefangzhou/Zotero/storage/GQDUT5GE/socf.html}
}

@article{oswald2010,
  title = {Daughters and {{Left}}-{{Wing Voting}}},
  volume = {92},
  issn = {0034-6535},
  abstract = {Abstract What determines human beings' political preferences? Using nationally representative longitudinal data, we show that having daughters makes people more likely to vote for left-wing political parties. Having sons leads people to favor right-wing parties. The paper checks that our result is not an artifact of family stopping rules, discusses the predictions from a simple economic model, and tests for possible reverse causality.},
  number = {2},
  journal = {The Review of Economics and Statistics},
  author = {Oswald, Andrew J and Powdthavee, Nattavudh},
  year = {2010},
  pages = {213-227},
  file = {/Users/xiefangzhou/Zotero/storage/VUKNZNKP/Oswald and Powdthavee - 2010 - Daughters and Left-Wing Voting.pdf;/Users/xiefangzhou/Zotero/storage/8MDNFRKF/rest.2010.html}
}

@article{greenstein2012a,
  title = {Is {{Wikipedia Biased}}?},
  volume = {102},
  issn = {0002-8282},
  number = {3},
  journal = {The American Economic Review},
  author = {Greenstein, Shane and Zhu, Feng},
  year = {2012},
  pages = {343-348},
  file = {/Users/xiefangzhou/Zotero/storage/VSW4C5EI/Greenstein and Zhu - 2012 - Is Wikipedia Biased.pdf}
}

@article{gentzkow2010,
  title = {What {{Drives Media Slant}}? {{Evidence From U}}.{{S}}. {{Daily Newspapers}}},
  volume = {78},
  copyright = {\textcopyright{} 2010 The Econometric Society},
  issn = {1468-0262},
  shorttitle = {What {{Drives Media Slant}}?},
  abstract = {We construct a new index of media slant that measures the similarity of a news outlet's language to that of a congressional Republican or Democrat. We estimate a model of newspaper demand that incorporates slant explicitly, estimate the slant that would be chosen if newspapers independently maximized their own profits, and compare these profit-maximizing points with firms' actual choices. We find that readers have an economically significant preference for like-minded news. Firms respond strongly to consumer preferences, which account for roughly 20 percent of the variation in measured slant in our sample. By contrast, the identity of a newspaper's owner explains far less of the variation in slant.},
  language = {en},
  number = {1},
  journal = {Econometrica},
  author = {Gentzkow, Matthew and Shapiro, Jesse M.},
  year = {2010},
  keywords = {Bias,media ownership,text categorization},
  pages = {35-71},
  file = {/Users/xiefangzhou/Zotero/storage/3FZMEWCU/Gentzkow and Shapiro - 2010 - What Drives Media Slant Evidence From U.S. Daily .pdf;/Users/xiefangzhou/Zotero/storage/8XE4VN4C/ECTA7195.html}
}

@article{elga2007,
  title = {Reflection and {{Disagreement}}},
  volume = {41},
  issn = {1468-0068},
  abstract = {How should you take into account the opinions of an advisor? When you completely defer to the advisor's judgment (the manner in which she responds to her evidence), then you should treat the advisor as a guru. Roughly, that means you should believe what you expect she would believe, if supplied with your extra evidence. When the advisor is your own future self, the resulting principle amounts to a version of the Reflection Principle\textemdash{}a version amended to handle cases of information loss. When you count an advisor as an epistemic peer, you should give her conclusions the same weight as your own. Denying that view\textemdash{}call it the ``equal weight view''\textemdash{}leads to absurdity: the absurdity that you could reasonably come to believe yourself to be an epistemic superior to an advisor simply by noting cases of disagreement with her, and taking it that she made most of the mistakes. Accepting the view seems to lead to another absurdity: that one should suspend judgment about everything that one's smart and well-informed friends disagree on, which means suspending judgment about almost everything interesting. But despite appearances, the equal weight view does not have this absurd consequence. Furthermore, the view can be generalized to handle cases involving not just epistemic peers, but also epistemic superiors and inferiors.},
  language = {en},
  number = {3},
  journal = {No{\^u}s},
  author = {Elga, Adam},
  year = {2007},
  pages = {478-502},
  file = {/Users/xiefangzhou/Zotero/storage/9RL6KDJ2/Elga - 2007 - Reflection and Disagreement.pdf;/Users/xiefangzhou/Zotero/storage/YJTMQMBK/j.1468-0068.2007.00656.html}
}

@techreport{gerber2009,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Personality {{Traits}} and the {{Dimensions}} of {{Political Ideology}}},
  abstract = {We use three large N nationally representative surveys to investigate the relationships between the Five Factor Model personality traits and political ideology. Prior examinations of the relationships between personality traits and political ideology have yielded mixed results. Numerous studies have shown that ideology is associated with the personality traits Openness and Conscientiousness, but the relationships between the other three personality traits (Agreeableness, Extraversion, and Emotional Stability) and ideology are weak and inconsistent across samples. We find that the failure to link these traits to political ideology is an artifact of the coarse measurement of political ideology used in prior work. Once ideology is decomposed into social and economic dimensions there is a strong association between economic attitudes and Agreeableness and Emotional Stability. Our finding that four of the five personality domains are strongly linked to political ideology implies that the role of personality in political attitudes may be substantially stronger and more general than suggested by previous research.},
  language = {en},
  number = {ID 1412863},
  institution = {{Social Science Research Network}},
  author = {Gerber, Alan and Huber, Gregory and Ha, Shang E. and Dowling, Conor and Doherty, David},
  year = {2009},
  keywords = {Big Five,economic conservatism,ideology,personality,social conservatism},
  file = {/Users/xiefangzhou/Zotero/storage/7C88W4W4/Gerber et al. - 2009 - Personality Traits and the Dimensions of Political.pdf;/Users/xiefangzhou/Zotero/storage/75YAB6EH/papers.html}
}

@inproceedings{yan2017,
  title = {The {{Perils}} of {{Classifying Political Orientation From Text}}},
  abstract = {Political communication often takes complex linguistic forms. Understanding political ideology from text is an important methodological task in studying political interactions between people in both new and traditional media. Therefore, there has been a spate of recent research that either relies on, or proposes new methodology for, the classification of political ideology from text data. In this paper, we study the effectiveness of these techniques for classifying ideology in the context of US politics. We construct three different datasets of conservative and liberal English texts from (1) the congressional record, (2) prominent conservative and liberal media websites, and (3) conservative and liberal wikis, and apply text classification algorithms with a domain adaptation technique. Our results are surprisingly negative. We find that the cross-domain learning performance, benchmarking the ability to generalize from one of these datasets to another, is poor, even though the algorithms perform very well in within-dataset cross-validation tests. We provide evidence that the poor performance is due to differences in the concepts that generate the true labels across datasets, rather than to a failure of domain adaptation methods. Our results suggest the need for extreme caution in interpreting the results of machine learning methodologies for classification of political text across domains. The one exception to our strongly negative results is that the classification methods show some ability to generalize from the congressional record to media websites. We show that this is likely because of the temporal movement of the use of specific phrases from politicians to the media.},
  booktitle = {{{LINKDEM}}@{{IJCAI}}},
  author = {Yan, Hao and Lavoie, Allen and Das, Sanmay},
  year = {2017},
  keywords = {Algorithm,Cross-validation (statistics),Document classification,Domain adaptation,Interaction,Machine learning,Text corpus,Wiki},
  file = {/Users/xiefangzhou/Zotero/storage/I334Z6CJ/Yan et al. - 2017 - The Perils of Classifying Political Orientation Fr.pdf}
}

@article{dellavigna2007,
  title = {The {{Fox News Effect}}: {{Media Bias}} and {{Voting}}},
  volume = {122},
  issn = {0033-5533},
  shorttitle = {The {{Fox News Effect}}},
  abstract = {Abstract.  Does media bias affect voting? We analyze the entry of Fox News in cable markets and its impact on voting. Between October 1996 and November 2000, th},
  language = {en},
  number = {3},
  journal = {The Quarterly Journal of Economics},
  author = {DellaVigna, Stefano and Kaplan, Ethan},
  year = {2007},
  pages = {1187-1234},
  file = {/Users/xiefangzhou/Zotero/storage/SQ467BXP/DellaVigna and Kaplan - 2007 - The Fox News Effect Media Bias and Voting.pdf;/Users/xiefangzhou/Zotero/storage/AQZPRK6J/1879517.html}
}

@article{allcott2017,
  title = {Social {{Media}} and {{Fake News}} in the 2016 {{Election}}},
  volume = {31},
  issn = {0895-3309},
  abstract = {Following the 2016 US presidential election, many have expressed concern about the effects of false stories ("fake news"), circulated largely through social media. We discuss the economics of fake news and present new data on its consumption prior to the election. Drawing on web browsing data, archives of fact-checking websites, and results from a new online survey, we find: 1) social media was an important but not dominant source of election news, with 14 percent of Americans calling social media their "most important" source; 2) of the known false news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared 8 million times; 3) the average American adult saw on the order of one or perhaps several fake news stories in the months around the election, with just over half of those who recalled seeing them believing them; and 4) people are much more likely to believe stories that favor their preferred candidate, especially if they have ideologically segregated social media networks.},
  language = {en},
  number = {2},
  journal = {Journal of Economic Perspectives},
  author = {Allcott, Hunt and Gentzkow, Matthew},
  year = {2017},
  keywords = {Economic Anthropology,Language,Media; Economic Sociology,Political Processes: Rent-Seeking; Lobbying; Elections; Legislatures; and Voting Behavior; Entertainment,Social and Economic Stratification},
  pages = {211-236},
  file = {/Users/xiefangzhou/Zotero/storage/28Q4XR93/Allcott and Gentzkow - 2017 - Social Media and Fake News in the 2016 Election.pdf;/Users/xiefangzhou/Zotero/storage/HTFVEIRL/articles.html}
}

@article{epstein2015,
  title = {The Search Engine Manipulation Effect ({{SEME}}) and Its Possible Impact on the Outcomes of Elections},
  volume = {112},
  copyright = {\textcopyright{}  . Freely available online through the PNAS open access option.},
  issn = {0027-8424, 1091-6490},
  abstract = {Internet search rankings have a significant impact on consumer choices, mainly because users trust and choose higher-ranked results more than lower-ranked results. Given the apparent power of search rankings, we asked whether they could be manipulated to alter the preferences of undecided voters in democratic elections. Here we report the results of five relevant double-blind, randomized controlled experiments, using a total of 4,556 undecided voters representing diverse demographic characteristics of the voting populations of the United States and India. The fifth experiment is especially notable in that it was conducted with eligible voters throughout India in the midst of India's 2014 Lok Sabha elections just before the final votes were cast. The results of these experiments demonstrate that (i) biased search rankings can shift the voting preferences of undecided voters by 20\% or more, (ii) the shift can be much higher in some demographic groups, and (iii) search ranking bias can be masked so that people show no awareness of the manipulation. We call this type of influence, which might be applicable to a variety of attitudes and beliefs, the search engine manipulation effect. Given that many elections are won by small margins, our results suggest that a search engine company has the power to influence the results of a substantial number of elections with impunity. The impact of such manipulations would be especially large in countries dominated by a single search engine company.},
  language = {en},
  number = {33},
  journal = {Proceedings of the National Academy of Sciences},
  author = {Epstein, Robert and Robertson, Ronald E.},
  year = {2015},
  keywords = {digital bandwagon effect,Internet influence,search engine manipulation effect,search rankings,voter manipulation},
  pages = {E4512-E4521},
  file = {/Users/xiefangzhou/Zotero/storage/6E6J26DA/Epstein and Robertson - 2015 - The search engine manipulation effect (SEME) and i.pdf;/Users/xiefangzhou/Zotero/storage/DGC2YRSZ/E4512.html},
  pmid = {26243876}
}

@article{neff2013,
  title = {Jointly {{They Edit}}: {{Examining}} the {{Impact}} of {{Community Identification}} on {{Political Interaction}} in {{Wikipedia}}},
  volume = {8},
  issn = {1932-6203},
  shorttitle = {Jointly {{They Edit}}},
  abstract = {Background In their 2005 study, Adamic and Glance coined the memorable phrase `divided they blog', referring to a trend of cyberbalkanization in the political blogosphere, with liberal and conservative blogs tending to link to other blogs with a similar political slant, and not to one another. As political discussion and activity increasingly moves online, the power of framing political discourses is shifting from mass media to social media. Methodology/Principal Findings Continued examination of political interactions online is critical, and we extend this line of research by examining the activities of political users within the Wikipedia community. First, we examined how users in Wikipedia choose to display their political affiliation. Next, we analyzed the patterns of cross-party interaction and community participation among those users proclaiming a political affiliation. In contrast to previous analyses of other social media, we did not find strong trends indicating a preference to interact with members of the same political party within the Wikipedia community. Conclusions/Significance Our results indicate that users who proclaim their political affiliation within the community tend to proclaim their identity as a `Wikipedian' even more loudly. It seems that the shared identity of `being Wikipedian' may be strong enough to triumph over other potentially divisive facets of personal identity, such as political affiliation.},
  language = {en},
  number = {4},
  journal = {PLOS ONE},
  author = {Neff, Jessica J. and Laniado, David and Kappler, Karolin E. and Volkovich, Yana and Arag{\'o}n, Pablo and Kaltenbrunner, Andreas},
  year = {2013},
  keywords = {Elections,Internet,Online encyclopedias,Political parties,Political theory,Social research,Social theory,Twitter},
  pages = {e60584},
  file = {/Users/xiefangzhou/Zotero/storage/YMVUXVDG/Neff et al. - 2013 - Jointly They Edit Examining the Impact of Communi.pdf;/Users/xiefangzhou/Zotero/storage/A77WL2KZ/article.html}
}

@techreport{algan2013,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Cooperation in a {{Peer Production Economy Experimental Evidence}} from {{Wikipedia}}.},
  abstract = {The impressive success of peer production \textendash{} a large-scale collaborative model of production primarily based on voluntary contributions \textendash{} is difficult to explain through the assumptions of standard economic theory. The aim of this paper is to study the prosocial foundations of cooperation in this new peer production economy. We provide the first field test of existing economic theories of prosocial motives for contributing to real-world public goods. We use an online experiment coupled with observational data to elicit social preferences within a diverse sample of 850 Wikipedia contributors, and seek to use to those measures to predict subjects' field contributions to the Wikipedia project. We find that subjects' field contributions to Wikipedia are strongly related to their level of reciprocity in a conditional Public Goods game and in a Trust game and to their revealed preference for social image within the Wikipedia community, but not to their level of altruism either in a standard or in a directed Dictator game. Our results have important theoretical and practical implications, as we show that reciprocity and social image are both strong motives for sustaining cooperation in peer production environments, while altruism is not.},
  language = {en},
  number = {ID 2843518},
  institution = {{Social Science Research Network}},
  author = {Algan, Yann and Benkler, Yochai and Fuster Morell, Mayo and Hergueux, J{\'e}r{\^o}me},
  year = {2013},
  keywords = {Field Experiments,Peer Production,Public Goods,Social Preferences,The Internet},
  file = {/Users/xiefangzhou/Zotero/storage/IZPH4DMV/papers.html}
}

@techreport{kummer2013,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Spillovers in {{Networks}} of {{User Generated Content}} \textendash{} {{Evidence}} from 23 {{Natural Experiments}} on {{Wikipedia}}},
  abstract = {Endogeneity in network formation hinders the identification of the role social networks play in generating spillovers, peer effects and other externalities. This paper tackles this problem and investigates how the link network between articles on the German Wikipedia influences the attention and content generation individual articles receive. Identification exploits local exogenous shocks on a small number of nodes in the network. It can thus avoid the usually required, but strong, assumptions of exogenous observed characteristics and link structure in networks. This approach also applies if, due to a lack of network information, identification through partial overlaps in the network structure fails (e.g. in classrooms). Exogenous variation is generated by natural and technical disasters or by articles being featured on the German Wikipedia's start page. The effects on neighboring pages are substantial; I observe an increase of almost 100 percent in terms of both views and content generation. The aggregate effect over all neighbors is also large: I find that a view on a treated article converts one for one into a view on a neighboring article. However, the resulting content generation is small in absolute terms.},
  language = {en},
  number = {ID 2356199},
  institution = {{Social Science Research Network}},
  author = {Kummer, Michael E.},
  year = {2013},
  keywords = {Information,Knowledge,Large-scale Networks,Natural Experiment,Social Media,Spillovers},
  file = {/Users/xiefangzhou/Zotero/storage/WJQJKV6E/papers.html}
}

@techreport{greenstein2012,
  type = {Working {{Paper}}},
  title = {Collective {{Intelligence}} and {{Neutral Point}} of {{View}}: {{The Case}} of {{Wikipedia}}},
  shorttitle = {Collective {{Intelligence}} and {{Neutral Point}} of {{View}}},
  abstract = {We examine whether collective intelligence helps achieve a neutral point of view using data from a decade of Wikipedia's articles on US politics. Our null hypothesis builds on Linus' Law, often expressed as "Given enough eyeballs, all bugs are shallow." Our findings are consistent with a narrow interpretation of Linus' Law, namely, a greater number of contributors to an article makes an article more neutral. No evidence supports a broad interpretation of Linus' Law. Moreover, several empirical facts suggest the law does not shape many articles. The majority of articles receive little attention, and most articles change only mildly from their initial slant.},
  number = {18167},
  institution = {{National Bureau of Economic Research}},
  author = {Greenstein, Shane and Zhu, Feng},
  year = {2012},
  file = {/Users/xiefangzhou/Zotero/storage/Y7FVLWRB/Greenstein and Zhu - 2012 - Collective Intelligence and Neutral Point of View.pdf}
}

@article{zhang2011,
  title = {Group {{Size}} and {{Incentives}} to {{Contribute}}: {{A Natural Experiment}} at {{Chinese Wikipedia}}},
  volume = {101},
  issn = {0002-8282},
  shorttitle = {Group {{Size}} and {{Incentives}} to {{Contribute}}},
  abstract = {The literature on the private provision of public goods suggests an inverse relationship between incentives to contribute and group size. We find, however, that after an exogenous reduction of group size at Chinese Wikipedia, the nonblocked contributors decrease their contributions by 42.8 percent on average. We attribute the cause to social effects: contributors receive social benefits that increase with both the amount of their contributions and group size, and the shrinking group size weakens these social benefits. Consistent with our explanation, we find that the more contributors value social benefits, the more they reduce their contributions after the block.  (JEL H41, L17, L82)},
  language = {en},
  number = {4},
  journal = {American Economic Review},
  author = {Zhang, Xiaoquan (Michael) and Zhu, Feng},
  year = {2011},
  keywords = {Media,Public Goods; Open Source Products and Markets; Entertainment},
  pages = {1601-1615},
  file = {/Users/xiefangzhou/Zotero/storage/SJG79CE9/Zhang and Zhu - 2011 - Group Size and Incentives to Contribute A Natural.pdf;/Users/xiefangzhou/Zotero/storage/2USJ64L7/articles.html}
}

@article{xu2013,
  title = {Impact of {{Wikipedia}} on {{Market Information Environment}}: {{Evidence}} on {{Management Disclosure}} and {{Investor Reaction}}},
  volume = {37},
  issn = {02767783, 21629730},
  shorttitle = {Impact of {{Wikipedia}} on {{Market Information Environment}}},
  abstract = {In this paper, we seek to determine whether a typical social media platform, Wikipedia, improves the information environment for investors in the financial market. Our theoretical lens leads us to expect that information aggregation about public companies on Wikipedia may influence how management's voluntary information disclosure reacts to market uncertainty with respect to investors' information about these companies. Our empirical analysis is based on a unique data set collected from financial records, management disclosure records, news article coverage, and a Wikipedia modification history of public companies. On the supply side of information, we find that information aggregation on Wikipedia can moderate the timing of managers' voluntary disclosure of companies' earnings disappointments, or bad news. On the demand side of information, we find that Wikipedia's information aggregation moderates investors' negative reaction to bad news. Taken together, these findings support the view that Wikipedia improves the information environment in the financial market and underscore the value of information aggregation through the use of information technology.},
  language = {en},
  number = {4},
  journal = {MIS Quarterly},
  author = {Xu, Sean Xin and Zhang, Xiaoquan (Michael)},
  year = {2013},
  pages = {1043-1068},
  file = {/Users/xiefangzhou/Zotero/storage/5BWS98EX/Tsinghua University Beijing et al. - 2013 - Impact of Wikipedia on Market Information Environm.pdf}
}

@article{schroeder2015,
  title = {Big Data and {{Wikipedia}} Research: Social Science Knowledge across Disciplinary Divides},
  volume = {18},
  issn = {1369-118X},
  shorttitle = {Big Data and {{Wikipedia}} Research},
  abstract = {This paper examines research about Wikipedia that has been undertaken using big data approaches. The aim is to gauge the coherence as against the disparateness of studies from different disciplines, how these studies relate to each other, and to research about Wikipedia and new social media in general. The paper is partly based on interviews with big data researchers, and discusses a number of themes and implications of Wikipedia research, including about the workings of online collaboration, the way that contributions mirror (or not) aspects of real-world geographies, and how contributions can be used to predict offline social and economic trends. Among the findings is that in some areas of research, studies build on and extend each other's results. However, most of the studies stay within disciplinary silos and could be better integrated with other research on Wikipedia and with research about new media. Wikipedia is among few sources in big data research where the data are openly available, unlike many studies where data are proprietary. Thus, it has lent itself to a burgeoning and promising body of research. The paper concludes that in order to fulfil this promise, this research must pay more attention to theories and research from other disciplines, and also go beyond questions based narrowly on the availability of data and towards a more powerful analytical grasp of the phenomenon being investigated.},
  number = {9},
  journal = {Information, Communication \& Society},
  author = {Schroeder, Ralph and Taylor, Linnet},
  year = {2015},
  keywords = {big data,interdisciplinarity,new media,Wikipedia},
  pages = {1039-1056},
  file = {/Users/xiefangzhou/Zotero/storage/G2W6HDTF/Schroeder and Taylor - 2015 - Big data and Wikipedia research social science kn.pdf;/Users/xiefangzhou/Zotero/storage/PQG773Z4/1369118X.2015.html}
}

@article{zhang2012,
  title = {Network {{Positions}} and {{Contributions}} to {{Online Public Goods}}: {{The Case}} of {{Chinese Wikipedia}}},
  volume = {29},
  issn = {0742-1222},
  shorttitle = {Network {{Positions}} and {{Contributions}} to {{Online Public Goods}}},
  abstract = {We study the effect of collaboration network structure on the contribution behavior of participating editors in Wikipedia. Collaboration in Wikipedia is organized around articles, and any two editors co-editing an article have a collaborative relationship. Based on the economic theories about network games and social role theory, we propose that an editor's position in the collaboration network influences the editor's decisions about her total contribution as well as the allocation of her efforts. By leveraging panel data collected from the Chinese language version of Wikipedia and a natural experiment resulting from blocking it in mainland China, we find strong support for the proposed effect of network position on contribution behavior. Our analysis further reveals that different aspects of an individual's network position have distinct implications. This research enhances our understanding about how collaboration network structure shapes individual behavior in online mass collaboration platforms.},
  number = {2},
  journal = {Journal of Management Information Systems},
  author = {Zhang, Xiaoquan and Wang, Chong},
  year = {2012},
  keywords = {Wikipedia,effort allocation,mass collaboration,natural experiment,network centrality,online public goods},
  pages = {11-40},
  file = {/Users/xiefangzhou/Zotero/storage/GXCGBJXK/Zhang and Wang - 2012 - Network Positions and Contributions to Online Publ.pdf}
}

@article{safner2016,
  title = {Institutional Entrepreneurship, Wikipedia, and the Opportunity of the Commons},
  volume = {12},
  issn = {1744-1374, 1744-1382},
  abstract = {Copyright laws traditionally attempt to incentivize expression and minimize free rider problems through legal restrictions, at the expense of closing off access to cultural history. However, entrepreneurial changes to institutions and the creation of alternative governance structures can allow for spaces that facilitate expression without resorting to the copyright approach. Wikipedia, the free online encyclopedia, stands as a highly visible example of such institutional entrepreneurship, leveraging copyright law against its intended purpose. This paper uses the Bloomington School's IAD framework to explain the success of Wikipedia's alternative model of managing a common resource of free encyclopedia articles, and suggests a roadmap for understanding the role of institutional entrepreneurship in crafting alternative governance structures to foster expression.},
  language = {en},
  number = {4},
  journal = {Journal of Institutional Economics},
  author = {Safner, Ryan},
  year = {2016},
  pages = {743-771},
  file = {/Users/xiefangzhou/Zotero/storage/GIZBP6S2/Safner - 2016 - Institutional entrepreneurship, wikipedia, and the.pdf;/Users/xiefangzhou/Zotero/storage/PYV88UEU/B9796AD1644066E413EB3B0AE3A6FDAE.html}
}

@book{buchanan1999,
  address = {{Indianapolis}},
  edition = {Volume 3 ed. edition},
  title = {The {{Calculus}} of {{Consent}}},
  isbn = {978-0-86597-218-6},
  abstract = {The Calculus of Consent was co-authored by Buchanan with Gordon Tullock, with whom Buchanan collaborated on many books and academic enterprises throughout their careers. As Robert D. Tollison states in the foreword, ``[this book] is a radical departure from the way democracies conduct their business. The Calculus is already a book for the ages.''  This classic work analyzes the political organization of a free society through the lens of the economic organization of society. The authors acknowledge their unease as economists in analyzing the political organization, but they take the risk of forging into unfamiliar territory because they believe the benefits of their perspective will bear much fruit.  As the authors state, their objective in this book is ``to analyze the calculus of the rational individual when he is faced with questions of constitutional choice . . . .We examine the [choice] process extensively only with reference to the problem of decision-making rules.''  The authors describe their approach as ``economic individualism.'' They believe that economists have explored individual choice extensively in the market sector while social scientists have largely ignored the dynamics of individual decision-making in the dynamics of forming group action in the public sector.  Written in the early 1960s, The Calculus of Consent has become a bulwark of the public choice movement for which James M. Buchanan is so justly famous.  James M. Buchanan is an eminent economist who won the Alfred Nobel Memorial Prize in Economic Sciences in 1986 and is considered one of the greatest scholars of liberty in the twentieth century.  The entire series includes: Volume 1: The Logical Foundations of Constitutional Liberty Volume 2: Public Principles of Public Debt  Volume 3: The Calculus of Consent  Volume 4: Public Finance in Democratic Process Volume 5: The Demand and Supply of Public Goods Volume 6: Cost and Choice Volume 7: The Limits of Liberty Volume 8: Democracy in Deficit Volume 9: The Power to Tax Volume 10: The Reason of Rules Volume 11: Politics by Principle, Not Interest Volume 12: Economic Inquiry and Its Logic Volume 13: Politics as Public Choice Volume 14: Debt and Taxes Volume 15: Externalities and Public Expenditure Theory Volume 16: Choice, Contract, and Constitutions Volume 17: Moral Science and Moral Order Volume 18: Federalism, Liberty, and the Law Volume 19: Ideas, Persons, and Events Volume 20: Indexes},
  language = {English},
  publisher = {{Liberty Fund Inc.}},
  author = {Buchanan, James and Tullock, Gordon},
  year = {1999},
  file = {/Users/xiefangzhou/Zotero/storage/H7VEIKEU/Buchanan and Tullock - 1999 - The Calculus of Consent.pdf}
}

@article{spitzer2007,
  title = {The {{Neural Signature}} of {{Social Norm Compliance}}},
  volume = {56},
  issn = {0896-6273},
  abstract = {Summary
All known human societies establish social order by punishing violators of social norms. However, little is known about how the brain processes the punishment threat associated with norm violations. We use fMRI to study the neural circuitry behind social norm compliance by comparing a treatment in which norm violations can be punished with a control treatment in which punishment is impossible. Individuals' increase in norm compliance when punishment is possible exhibits a strong positive correlation~with activations in the lateral orbitofrontal cortex and right dorsolateral prefrontal cortex. Moreover, lateral orbitofrontal cortex activity is strongly correlated with Machiavellian personality characteristics. These findings indicate a neural network involved in social norm compliance that might constitute an important basis~for human sociality. Different activations of this network reveal individual differences in the behavioral response to the punishment threat and might thus provide a deeper understanding of the neurobiological sources of pathologies such as antisocial personality disorder.},
  number = {1},
  journal = {Neuron},
  author = {Spitzer, Manfred and Fischbacher, Urs and Herrnberger, B{\"a}rbel and Gr{\"o}n, Georg and Fehr, Ernst},
  year = {2007},
  keywords = {SYSBIO,SYSNEURO},
  pages = {185-196},
  file = {/Users/xiefangzhou/Zotero/storage/ZWZ42Z58/Spitzer et al. - 2007 - The Neural Signature of Social Norm Compliance.pdf;/Users/xiefangzhou/Zotero/storage/ZL2YQ7P7/S089662730700709X.html}
}

@article{hoffman1996,
  title = {Social {{Distance}} and {{Other}}-{{Regarding Behavior}} in {{Dictator Games}}},
  volume = {86},
  issn = {0002-8282},
  number = {3},
  journal = {The American Economic Review},
  author = {Hoffman, Elizabeth and McCabe, Kevin and Smith, Vernon L.},
  year = {1996},
  pages = {653-660},
  file = {/Users/xiefangzhou/Zotero/storage/UPXVDILQ/Hoffman et al. - 1996 - Social Distance and Other-Regarding Behavior in Di.pdf}
}

@article{elster1989,
  title = {Social {{Norms}} and {{Economic Theory}}},
  volume = {3},
  issn = {0895-3309},
  abstract = {One of the most persistent cleavages in the social sciences is the opposition between two lines of thought conveniently associated with Adam Smith and Emile Durkheim, between homo economicus and homo sociologicus. Of these, the former is supposed to be guided by instrumental rationality, while the behavior of the latter is dictated by social norms. In this paper I characterize this contrast more fully, and discuss attempts by economists to reduce norm-oriented action to some type of optimizing behavior. Social norms, as I understand them here, are emotional and behavioral propensities of individuals. Are norms rationalizations of self-interest? Are norms followed out of self-interest? Do norms exist to promote self-interest? Do norms exist to promote common interests? Do norms exist to promote genetic fitness?},
  language = {en},
  number = {4},
  journal = {Journal of Economic Perspectives},
  author = {Elster, Jon},
  year = {1989},
  keywords = {General Economics},
  pages = {99-117},
  file = {/Users/xiefangzhou/Zotero/storage/6PBQLC77/Elster - 1989 - Social Norms and Economic Theory.pdf;/Users/xiefangzhou/Zotero/storage/5JL9T3PS/articles.html}
}

@article{eckel1996,
  title = {Altruism in {{Anonymous Dictator Games}}},
  volume = {16},
  issn = {0899-8256},
  abstract = {We conduct double-anonymous dictator experiments to explore the role of altruism in motivating subjects' behavior. We vary the extent to which an anonymous recipient is deserving of aid and investigate its effect on the allocation of a fixed pie by student subjects. This is accomplished by including as treatments: (1) an anonymous student subject and (2) an established charity. We find that a significant increase in donations occurs when we increase the extent to which a donation goes to a recipient generally agreed to be ``deserving.'' We conclude that subjects are rational in the way they incorporate fairness into their decisions.Journal of Economic LiteratureClassification Numbers: A13, C91, D64.},
  number = {2},
  journal = {Games and Economic Behavior},
  author = {Eckel, Catherine C. and Grossman, Philip J.},
  year = {1996},
  pages = {181-191},
  file = {/Users/xiefangzhou/Zotero/storage/K7YPBZA8/Eckel and Grossman - 1996 - Altruism in Anonymous Dictator Games.pdf;/Users/xiefangzhou/Zotero/storage/34MR5ZJH/S0899825696900810.html}
}

@article{greenstein2018,
  title = {Do {{Experts}} or {{Crowd}}-{{Based Models Produce More Bias}}? {{Evidence}} from {{Encyclop{\ae}dia Britannica}} and {{Wikipedia}}},
  volume = {42},
  issn = {0276-7783},
  shorttitle = {Do {{Experts}} or {{Crowd}}-{{Based Models Produce More Bias}}?},
  abstract = {Organizations today can use both crowds and experts to produce knowledge. While prior work compares the accuracy of crowd-produced and expert-produced knowledge, we compare bias in these two models in the context of contested knowledge, which involves subjective, unverifiable, or controversial information. Using data from Encyclop{\ae}dia Britannica, authored by experts, and Wikipedia, an encyclopedia produced by an online community, we compare the slant and bias of pairs of articles on identical topics of U.S. politics. Our slant measure is less (more) than zero when an article leans towards Democratic (Republican) viewpoints, while bias is the absolute value of the slant. We find that Wikipedia articles are more slanted towards Democratic views than are Britannica articles, as well as more biased. The difference in bias between a pair of articles decreases with more revisions. The bias on a per word basis hardly differs between the sources because Wikipedia articles tend to be longer than Britannica articles. These results highlight the pros and cons of each knowledge production model, help identify the scope of the empirical generalization of prior studies comparing the information quality of the two production models, and offer implications for organizations managing crowd-based knowledge production.},
  language = {en-us},
  number = {3},
  journal = {MIS Quarterly},
  author = {Greenstein, Shane and Zhu, Feng},
  year = {2018},
  pages = {945-959},
  file = {/Users/xiefangzhou/Zotero/storage/64WKSS59/Greenstein and Zhu - Do Experts or Crowd-based Models Produce More Bias.pdf;/Users/xiefangzhou/Zotero/storage/KB5MT8YZ/item.html}
}

@inproceedings{west2012,
  address = {{New York, NY, USA}},
  series = {{{WikiSym}} '12},
  title = {Drawing a {{Data}}-Driven {{Portrait}} of {{Wikipedia Editors}}},
  isbn = {978-1-4503-1605-7},
  abstract = {While there has been a substantial amount of research into the editorial and organizational processes within Wikipedia, little is known about how Wikipedia editors (Wikipedians) relate to the online world in general. We attempt to shed light on this issue by using aggregated log data from Yahoo!'s browser toolbar in order to analyze Wikipedians' editing behavior in the context of their online lives beyond Wikipedia. We broadly characterize editors by investigating how their online behavior differs from that of other users; e.g., we find that Wikipedia editors search more, read more news, play more games, and, perhaps surprisingly, are more immersed in popular culture. Then we inspect how editors' general interests relate to the articles to which they contribute; e.g., we confirm the intuition that editors are more familiar with their active domains than average users. Finally, we analyze the data from a temporal perspective; e.g., we demonstrate that a user's interest in the edited topic peaks immediately before the edit. Our results are relevant as they illuminate novel aspects of what has become many Web users' prevalent source of information.},
  booktitle = {Proceedings of the {{Eighth Annual International Symposium}} on {{Wikis}} and {{Open Collaboration}}},
  publisher = {{ACM}},
  author = {West, Robert and Weber, Ingmar and Castillo, Carlos},
  year = {2012},
  keywords = {Wikipedia,editors,expertise,web usage},
  pages = {3:1--3:10},
  file = {/Users/xiefangzhou/Zotero/storage/AMMEXD49/West et al. - 2012 - Drawing a Data-driven Portrait of Wikipedia Editor.pdf}
}

@techreport{inglehart2016,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Trump, {{Brexit}}, and the {{Rise}} of {{Populism}}: {{Economic Have}}-{{Nots}} and {{Cultural Backlash}}},
  shorttitle = {Trump, {{Brexit}}, and the {{Rise}} of {{Populism}}},
  abstract = {Rising support for populist parties has disrupted the politics of many Western societies. What explains this phenomenon? Two theories are examined here. Perhaps the most widely-held view of mass support for populism -- the economic insecurity perspective -- emphasizes the consequences of profound changes transforming the workforce and society in post-industrial economies. Alternatively, the cultural backlash thesis suggests that support can be explained as a retro reaction by once-predominant sectors of the population to progressive value change. To consider these arguments, Part I develops the conceptual and theoretical framework. Part II of the study uses the 2014 Chapel Hill Expert Survey (CHES) to identify the ideological location of 268 political parties in 31 European countries. Part III compares the pattern of European party competition at national-level. Part IV uses the pooled European Social Survey 1-6 (2002-2014) to examine the cross-national evidence at individual level for the impact of the economic insecurity and cultural values as predictors of voting for populist parties. Part V summarizes the key findings and considers their implications. Overall, we find the most consistent evidence supporting the cultural backlash thesis.},
  language = {en},
  number = {ID 2818659},
  institution = {{Social Science Research Network}},
  author = {Inglehart, Ronald F. and Norris, Pippa},
  year = {2016},
  keywords = {cultural value change,democracy,economic insecurity,elections,populist parties and leaders,radical right},
  file = {/Users/xiefangzhou/Zotero/storage/NBNTR7UQ/Inglehart and Norris - 2016 - Trump, Brexit, and the Rise of Populism Economic .pdf;/Users/xiefangzhou/Zotero/storage/5PVME9GE/papers.html}
}

@book{russell2001,
  title = {The {{Problems}} of {{Philosophy}}},
  isbn = {978-0-19-150076-3},
  abstract = {'Is there any knowledge in the world which is so certain that no reasonable man could doubt it?' Philosophy is the attempt to answer such ultimate questions, not carelessly and dogmatically, as we might deal with them in ordinary life, but critically, after analysing how and why the questions arise and clarifying the assumptions and concepts on which they are based. This classic work, first published in 1912, has never been supplanted as an approachable introduction to the theory of philosophical enquiry. It gives Russell's views on such subjects as the distinction between appearance and reality, the existence and nature of matter, idealism, knowledge by acquaintance and by description, induction, and the limits and value of philosophical knowledge. This edition includes an introduction by John Skorupski contextualizing Russell's work, and a guide to further reading.},
  language = {en},
  publisher = {{OUP Oxford}},
  author = {Russell, Bertrand},
  year = {2001},
  keywords = {Philosophy / Movements / Analytic}
}

@book{buchanan1999a,
  address = {{Indianapolis}},
  edition = {1},
  title = {Logical {{Foundations}} of {{Constitutional Liberty}}},
  volume = {1},
  isbn = {978-0-86597-214-8},
  abstract = {The thirty-one papers presented in this volume offer scholars and general readers alike a comprehensive introduction to the work of one of the greatest economists of the modern era. Many of Buchanan's most important essays are gathered in this inaugural volume of the twenty-volume series from Liberty Fund of his Collected Works.  The essays are arranged thematically and so present a complete perspective on Buchanan's work. The six sections include: 1. Introduction 2. Politics without Romance 3. Public Finance and Democratic Process 4. The Economist and Economic Order 5. Ethics and Economics 6. The Reason of Rules  The editors have focused on papers that Buchanan has written without collaboration and which present Buchanan's earlier, classic statements on crucial subjects rather than his subsequent elaborations which appear in later volumes in the series. Included, too, is Buchanan's Nobel address, "The Constitution of Economic Policy," and the text of the Nobel Committee's press release explaining why Buchanan was awarded the prize for Economics in 1986. The volume also includes Buchanan's autobiographical essay, "Better Than Plowing," in which he gives not only a brief account of his life, but also his own assessment of what is important, distinctive, and enduring in his work. The foreword by the three series editors will be valuable to all readers who wish to engage the challenging but epochal writings of the father of modern public choice theory.  The entire series includes: Volume 1: The Logical Foundations of Constitutional Liberty Volume 2: Public Principles of Public Debt  Volume 3: The Calculus of Consent  Volume 4: Public Finance in Democratic Process Volume 5: The Demand and Supply of Public Goods Volume 6: Cost and Choice Volume 7: The Limits of Liberty Volume 8: Democracy in Deficit Volume 9: The Power to Tax Volume 10: The Reason of Rules Volume 11: Politics by Principle, Not Interest Volume 12: Economic Inquiry and Its Logic Volume 13: Politics as Public Choice Volume 14: Debt and Taxes Volume 15: Externalities and Public Expenditure Theory Volume 16: Choice, Contract, and Constitutions Volume 17: Moral Science and Moral Order Volume 18: Federalism, Liberty, and the Law Volume 19: Ideas, Persons, and Events Volume 20: Indexes},
  language = {English},
  publisher = {{Liberty Fund Inc.}},
  author = {Buchanan, James M.},
  year = {1999}
}

@article{hardin1968,
  title = {The {{Tragedy}} of the {{Commons}}},
  volume = {162},
  copyright = {\textcopyright{} 1968},
  issn = {0036-8075, 1095-9203},
  abstract = {The population problem has no technical solution; it requires a fundamental extension in morality.},
  language = {en},
  number = {3859},
  journal = {Science},
  author = {Hardin, Garrett},
  year = {1968},
  pages = {1243-1248},
  file = {/Users/xiefangzhou/Zotero/storage/HEYTEV2M/Hardin - 1968 - The Tragedy of the Commons.pdf;/Users/xiefangzhou/Zotero/storage/AGT5YG5K/1243.html},
  pmid = {5699198}
}

@article{dourado2015,
  title = {Public Choice Perspectives on Intellectual Property},
  volume = {163},
  issn = {1573-7101},
  abstract = {We mine two public choice traditions for insights into intellectual property rights: the Virginia school, centered on James Buchanan and Gordon Tullock, and the Bloomington or Institutional Analysis and Development school, centered on Elinor Ostrom and Vincent Ostrom. We apply the perspectives of each school to issues of intellectual property and develop new insights, questions, and focuses of attention. We also explore tensions and synergies between the two schools on issues of intellectual property.},
  language = {en},
  number = {1},
  journal = {Public Choice},
  author = {Dourado, Eli and Tabarrok, Alex},
  year = {2015},
  keywords = {D72,Bloomington school,Copyright,D02,Institutional analysis and development,Institutional economics,Intellectual property,O30,Patents,Public choice,Virginia school},
  pages = {129-151},
  file = {/Users/xiefangzhou/Zotero/storage/DLIERPXP/Dourado and Tabarrok - 2015 - Public choice perspectives on intellectual propert.pdf}
}

@article{frimer2017,
  title = {Liberals and Conservatives Are Similarly Motivated to Avoid Exposure to One Another's Opinions},
  volume = {72},
  issn = {0022-1031},
  abstract = {Ideologically committed people are similarly motivated to avoid ideologically crosscutting information. Although some previous research has found that political conservatives may be more prone to selective exposure than liberals are, we find similar selective exposure motives on the political left and right across a variety of issues. The majority of people on both sides of the same-sex marriage debate willingly gave up a chance to win money to avoid hearing from the other side (Study 1). When thinking back to the 2012 U.S. Presidential election (Study 2), ahead to upcoming elections in the U.S. and Canada (Study 3), and about a range of other Culture War issues (Study 4), liberals and conservatives reported similar aversion toward learning about the views of their ideological opponents. Their lack of interest was not due to already being informed about the other side or attributable election fatigue. Rather, people on both sides indicated that they anticipated that hearing from the other side would induce cognitive dissonance (e.g., require effort, cause frustration) and undermine a sense of shared reality with the person expressing disparate views (e.g., damage the relationship; Study 5). A high-powered meta-analysis of our data sets (N=2417) did not detect a difference in the intensity of liberals' (d=0.63) and conservatives' (d=0.58) desires to remain in their respective ideological bubbles.},
  journal = {Journal of Experimental Social Psychology},
  author = {Frimer, Jeremy A. and Skitka, Linda J. and Motyl, Matt},
  year = {2017},
  keywords = {Confirmation bias,Ideological symmetry,Liberals and conservatives,Motivation,Selective exposure},
  pages = {1-12},
  file = {/Users/xiefangzhou/Zotero/storage/42HD6RQ6/Frimer et al. - 2017 - Liberals and conservatives are similarly motivated.pdf;/Users/xiefangzhou/Zotero/storage/24MWWN98/S0022103116304024.html}
}

@article{kahan2017,
  title = {Motivated Numeracy and Enlightened Self-Government},
  volume = {1},
  issn = {2398-063X, 2398-0648},
  abstract = {Why does public conflict over societal risks persist in the face of compelling and widely accessible scientific evidence? We conducted an experiment to probe two alternative answers: the `science comprehension thesis' (SCT), which identifies defects in the public's knowledge and reasoning capacities as the source of such controversies; and the `identity-protective cognition thesis' (ICT), which treats cultural conflict as disabling the faculties that members of the public use to make sense of decision-relevant science. In our experiment, we presented subjects with a difficult problem that turned on their ability to draw valid causal inferences from empirical data. As expected, subjects highest in numeracy \textendash{} a measure of the ability and disposition to make use of quantitative information \textendash{} did substantially better than less numerate ones when the data were presented as results from a study of a new skin rash treatment. Also as expected, subjects' responses became politically polarized \textendash{} and even less accurate \textendash{} when the same data were presented as results from the study of a gun control ban. But contrary to the prediction of SCT, such polarization did not abate among subjects highest in numeracy; instead, it increased. This outcome supported ICT, which predicted that more numerate subjects would use their quantitative-reasoning capacity selectively to conform their interpretation of the data to the result most consistent with their political outlooks. We discuss the theoretical and practical significance of these findings.},
  language = {en},
  number = {1},
  journal = {Behavioural Public Policy},
  author = {Kahan, Dan M. and Peters, Ellen and Dawson, Erica Cantrell and Slovic, Paul},
  year = {2017},
  pages = {54-86},
  file = {/Users/xiefangzhou/Zotero/storage/NJF8J7SZ/Kahan et al. - 2017 - Motivated numeracy and enlightened self-government.pdf;/Users/xiefangzhou/Zotero/storage/V2AXBL7D/EC9F2410D5562EF10B7A5E2539063806.html}
}

@techreport{nyhan2017,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Taking {{Corrections Literally But Not Seriously}}? {{The Effects}} of {{Information}} on {{Factual Beliefs}} and {{Candidate Favorability}}},
  shorttitle = {Taking {{Corrections Literally But Not Seriously}}?},
  abstract = {Are citizens willing to accept fact-checks of false or unsupported claims of candidates they support in the heat of a political campaign? Previous studies have reached conflicting conclusions about people's willingness to update their factual beliefs in response to counter-attitudinal information. To discriminate between these findings, we conducted two experiments during the 2016 presidential campaign. Our results indicate that correcting misleading claims that Donald Trump made during his convention speech and in the first general election debate reduced belief in the claims in question even among his supporters. However, attitudes toward Trump were not affected. These results suggest that corrective information can reduce misperceptions, but will often have minimal effects on candidate evaluations or vote choice.},
  language = {en},
  number = {ID 2995128},
  institution = {{Social Science Research Network}},
  author = {Nyhan, Brendan and Porter, Ethan and Reifler, Jason and Wood, Thomas},
  year = {2017},
  keywords = {Brendan Nyhan,Ethan Porter,Jason Reifler,SSRN,Taking Corrections Literally But Not Seriously? The Effects of Information on Factual Beliefs and Candidate Favorability,Thomas Wood},
  file = {/Users/xiefangzhou/Zotero/storage/82NXQDQK/papers.html}
}

@article{landry2006,
  title = {Toward an {{Understanding}} of the {{Economics}} of {{Charity}}: {{Evidence}} from a {{Field Experiment}}},
  volume = {121},
  issn = {0033-5533},
  shorttitle = {Toward an {{Understanding}} of the {{Economics}} of {{Charity}}},
  abstract = {Abstract.  This study develops theory and uses a door-to-door fund-raising field experiment to explore the economics of charity. We approached nearly 5000 house},
  language = {en},
  number = {2},
  journal = {The Quarterly Journal of Economics},
  author = {Landry, Craig E. and Lange, Andreas and List, John A. and Price, Michael K. and Rupp, Nicholas G.},
  year = {2006},
  pages = {747-782},
  file = {/Users/xiefangzhou/Zotero/storage/RJGXVX84/1884044.html}
}

@book{hardy1969,
  edition = {Reprint edition},
  title = {A {{Mathematician}}'s {{Apology}}},
  language = {English},
  publisher = {{Cambridge University}},
  author = {Hardy, G. H.},
  year = {1969}
}

@article{freeden2006,
  title = {Ideology and Political Theory},
  volume = {11},
  issn = {1356-9317},
  abstract = {Ideology, and its study, have been subject to an interpretational tug-of-war among political theorists that, until recently, has devalued their status as an object of scholarship. Disputes have raged over the scientific standing of ideology, its epistemological status, and its totalitarian and liberal manifestations. Many political philosophers have eschewed its group orientation, and the more recent interest of students of ideology in ordinary political language and in the unconscious and the indeterminate. Following an historical survey of changing fashions and more durable features in the analysis of ideology, it is argued that ideology should be explored as the most typical form of political thinking, and that its study conducts political theorists to the heart of the political. Ideology is now seen as ubiquitous, while the methodologies through which ideologies are studied take on board conceptual malleability and ideational pluralism, and offer bridges between identifying `social facts' and their inevitable interpretation.},
  number = {1},
  journal = {Journal of Political Ideologies},
  author = {Freeden, Michael},
  year = {2006},
  pages = {3-22},
  file = {/Users/xiefangzhou/Zotero/storage/V6JIM5K5/Freeden - 2006 - Ideology and political theory.pdf;/Users/xiefangzhou/Zotero/storage/SFU3PPRY/13569310500395834.html}
}

@article{hibbing2014,
  title = {Differences in Negativity Bias Underlie Variations in Political Ideology},
  volume = {37},
  issn = {0140-525X, 1469-1825},
  abstract = {Disputes between those holding differing political views are ubiquitous and deep-seated, and they often follow common, recognizable lines. The supporters of tradition and stability, sometimes referred to as conservatives, do battle with the supporters of innovation and reform, sometimes referred to as liberals. Understanding the correlates of those distinct political orientations is probably a prerequisite for managing political disputes, which are a source of social conflict that can lead to frustration and even bloodshed. A rapidly growing body of empirical evidence documents a multitude of ways in which liberals and conservatives differ from each other in purviews of life with little direct connection to politics, from tastes in art to desire for closure and from disgust sensitivity to the tendency to pursue new information, but the central theme of the differences is a matter of debate. In this article, we argue that one organizing element of the many differences between liberals and conservatives is the nature of their physiological and psychological responses to features of the environment that are negative. Compared with liberals, conservatives tend to register greater physiological responses to such stimuli and also to devote more psychological resources to them. Operating from this point of departure, we suggest approaches for refining understanding of the broad relationship between political views and response to the negative. We conclude with a discussion of normative implications, stressing that identifying differences across ideological groups is not tantamount to declaring one ideology superior to another.},
  language = {en},
  number = {3},
  journal = {Behavioral and Brain Sciences},
  author = {Hibbing, John R. and Smith, Kevin B. and Alford, John R.},
  year = {2014},
  keywords = {attitudes,conservatives,liberals,negativity,physiology,politics,psychology},
  pages = {297-307},
  file = {/Users/xiefangzhou/Zotero/storage/GFVVPKKG/Hibbing et al. - 2014 - Differences in negativity bias underlie variations.pdf;/Users/xiefangzhou/Zotero/storage/HFZTJEMN/72A29464D2FD037B03F7485616929560.html}
}

@article{baddeley2004,
  title = {An Introduction to Prior Information Derived from Probabilistic Judgements: Elicitation of Knowledge, Cognitive Bias and Herding},
  volume = {239},
  copyright = {\textcopyright{} The Geological Society of London 2004},
  issn = {0305-8719, 2041-4927},
  shorttitle = {An Introduction to Prior Information Derived from Probabilistic Judgements},
  abstract = {Skip to Next Section
Opinion of geological experts is often formed despite a paucity of data and is usually based on prior experience. In such situations humans employ heuristics (rules of thumb) to aid analysis and interpretation of data. As a result, future judgements are bootstrapped from, and hence biased by, both the heuristics employed and prior opinion.
This paper reviews the causes of bias and error inherent in prior information derived from the probabilistic judgements of people. Parallels are developed between the evolution of scientific opinion on one hand and the limits on rational behaviour on the other. We show that the combination of data paucity and commonly employed heuristics can lead to herding behaviour within groups of experts. Elicitation theory mitigates the effects of such behaviour, but a method to estimate reliable uncertainties on expert judgements remains elusive.
We have also identified several key directions in which future research is likely to lead to methods that reduce such emergent group behaviour, thereby increasing the probability that the stock of common knowledge will converge in a stable manner towards facts about the Earth as it really is. These include: (1) measuring the frequency with which different heuristics tend to be employed by experts within the geosciences; (2) developing geoscience-specific methods to reduce biases originating from the use of such heuristics; (3) creating methods to detect scientific herding behaviour; and (4) researching how best to reconcile opinions from multiple experts in order to obtain the best probabilistic description of an unknown, objective reality (in cases where one exists).
Skip to Previous Section
Opinion of geological experts is often formed despite a paucity of data and is usually based on prior experience. In such situations humans employ heuristics (rules of thumb) to aid analysis and interpretation of data. As a result, future judgements are bootstrapped from, and hence biased by, both the heuristics employed and prior opinion.
This paper reviews the causes of bias and error inherent in prior information derived from the probabilistic judgements of people. Parallels are developed between the evolution of scientific opinion on one hand and the limits on rational behaviour on the other. We show that the combination of data paucity and commonly employed heuristics can lead to herding behaviour within groups of experts. Elicitation theory mitigates the effects of such behaviour, but a method to estimate reliable uncertainties on expert judgements remains elusive.
We have also identified several key directions in which future research is likely to lead to methods that reduce such emergent group behaviour, thereby increasing the probability that the stock of common knowledge will converge in a stable manner towards facts about the Earth as it really is. These include: (1) measuring the frequency with which different heuristics tend to be employed by experts within the geosciences; (2) developing geoscience-specific methods to reduce biases originating from the use of such heuristics; (3) creating methods to detect scientific herding behaviour; and (4) researching how best to reconcile opinions from multiple experts in order to obtain the best probabilistic description of an unknown, objective reality (in cases where one exists).},
  language = {en},
  number = {1},
  journal = {Geological Society, London, Special Publications},
  author = {Baddeley, Michelle C. and Curtis, Andrew and Wood, Rachel},
  year = {2004},
  pages = {15-27},
  file = {/Users/xiefangzhou/Zotero/storage/5Y45AEGZ/Baddeley et al. - 2004 - An introduction to prior information derived from .pdf;/Users/xiefangzhou/Zotero/storage/DLYS2E3Z/15.html}
}

@article{grimmer2013,
  title = {Text as {{Data}}: {{The Promise}} and {{Pitfalls}} of {{Automatic Content Analysis Methods}} for {{Political Texts}}},
  volume = {21},
  issn = {1047-1987, 1476-4989},
  shorttitle = {Text as {{Data}}},
  abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods\textemdash{}they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
  language = {en},
  number = {3},
  journal = {Political Analysis},
  author = {Grimmer, Justin and Stewart, Brandon M.},
  year = {2013/ed},
  pages = {267-297},
  file = {/Users/xiefangzhou/Zotero/storage/YBVK99SP/Grimmer and Stewart - 2013 - Text as Data The Promise and Pitfalls of Automati.pdf;/Users/xiefangzhou/Zotero/storage/ALI3PFD2/F7AAC8B2909441603FEB25C156448F20.html}
}

@article{glott2010,
  title = {Wikipedia {{Survey}}-{{Overview}} of {{Results}}, {{UNU}}-{{Merit Collaborative Creativity Group}}},
  author = {Glott, Ruediger and Schmidt, Philipp and Ghosh, Rishab},
  year = {2010},
  file = {/Users/xiefangzhou/Zotero/storage/EY3KMDJ9/Glott et al. - 2010 - Wikipedia Survey-Overview of Results, UNU-Merit Co.pdf}
}

@article{michie2013,
  title = {The {{Behavior Change Technique Taxonomy}} (v1) of 93 {{Hierarchically Clustered Techniques}}: {{Building}} an {{International Consensus}} for the {{Reporting}} of {{Behavior Change Interventions}}},
  volume = {46},
  issn = {0883-6612},
  shorttitle = {The {{Behavior Change Technique Taxonomy}} (v1) of 93 {{Hierarchically Clustered Techniques}}},
  abstract = {AbstractBackground.  CONSORT guidelines call for precise reporting of behavior change interventions: we need rigorous methods of characterizing active content o},
  language = {en},
  number = {1},
  journal = {Annals of Behavioral Medicine},
  author = {Michie, Susan and Richardson, Michelle and Johnston, Marie and Abraham, Charles and Francis, Jill and Hardeman, Wendy and Eccles, Martin P. and Cane, James and Wood, Caroline E.},
  year = {2013},
  pages = {81-95},
  file = {/Users/xiefangzhou/Zotero/storage/5LLNBPMZ/Michie et al. - 2013 - The Behavior Change Technique Taxonomy (v1) of 93 .pdf;/Users/xiefangzhou/Zotero/storage/MYFV2RXP/4563254.html}
}

@article{farhi2018,
  title = {Deadly {{Embrace}}: {{Sovereign}} and {{Financial Balance Sheets Doom Loops}}},
  volume = {85},
  issn = {0034-6527},
  shorttitle = {Deadly {{Embrace}}},
  abstract = {Abstract.  The recent unravelling of the Eurozone's financial integration raised concerns about feedback loops between sovereign and banking insolvency. This ar},
  language = {en},
  number = {3},
  journal = {The Review of Economic Studies},
  author = {Farhi, Emmanuel and Tirole, Jean},
  year = {2018},
  pages = {1781-1823},
  file = {/Users/xiefangzhou/Zotero/storage/I3BRRDHF/Farhi and Tirole - 2018 - Deadly Embrace Sovereign and Financial Balance Sh.pdf;/Users/xiefangzhou/Zotero/storage/DPQ42BYC/4563322.html}
}

@article{bourles2017,
  title = {Altruism in {{Networks}}},
  volume = {85},
  copyright = {\textcopyright{} 2017 The Econometric Society},
  issn = {1468-0262},
  abstract = {We provide the first analysis of altruism in networks. Agents are embedded in a fixed network and care about the well-being of their network neighbors. Depending on incomes, they may provide financial support to their poorer friends. We study the Nash equilibria of the resulting game of transfers. We show that equilibria maximize a concave potential function. We establish existence, uniqueness of equilibrium consumption, and generic uniqueness of equilibrium transfers. We characterize the geometry of the network of transfers and highlight the key role played by transfer intermediaries. We then study comparative statics. A positive income shock to an individual benefits all. For small changes in incomes, agents in a component of the network of transfers act as if they were organized in an income-pooling community. A decrease in income inequality or expansion of the altruism network may increase consumption inequality.},
  language = {en},
  number = {2},
  journal = {Econometrica},
  author = {Bourl{\`e}s, Renaud and Bramoull{\'e}, Yann and Perez-Richet, Eduardo},
  year = {2017},
  keywords = {altruism,inequality,neutrality,Private transfers,social networks},
  pages = {675-689},
  file = {/Users/xiefangzhou/Zotero/storage/4E79DL9V/Bourlès et al. - 2017 - Altruism in Networks.pdf;/Users/xiefangzhou/Zotero/storage/25CMLLQR/ECTA13533.html}
}

@article{noldeke2018,
  title = {The {{Implementation Duality}}},
  volume = {86},
  copyright = {\textcopyright{} 2018 The Econometric Society},
  issn = {1468-0262},
  abstract = {Conjugate duality relationships are pervasive in matching and implementation problems and provide much of the structure essential for characterizing stable matches and implementable allocations in models with quasilinear (or transferable) utility. In the absence of quasilinearity, a more abstract duality relationship, known as a Galois connection, takes the role of (generalized) conjugate duality. While weaker, this duality relationship still induces substantial structure. We show that this structure can be used to extend existing results for, and gain new insights into, adverse-selection principal-agent problems and two-sided matching problems without quasilinearity.},
  language = {en},
  number = {4},
  journal = {Econometrica},
  author = {N{\"o}ldeke, Georg and Samuelson, Larry},
  year = {2018},
  keywords = {conjugate duality,Galois connection,imperfectly transferable utility,Implementation,optimal transport,principal-agent model,two-sided matching},
  pages = {1283-1324},
  file = {/Users/xiefangzhou/Zotero/storage/Z9CBWIUE/Nöldeke and Samuelson - 2018 - The Implementation Duality.pdf;/Users/xiefangzhou/Zotero/storage/TRUMAM9D/ECTA13307.html}
}

@techreport{fajgelbaum2017,
  type = {Working {{Paper}}},
  title = {Optimal {{Transport Networks}} in {{Spatial Equilibrium}}},
  abstract = {We study optimal transport networks in spatial equilibrium. We develop a framework consisting of a neoclassical trade model with labor mobility in which locations are arranged on a graph. Goods must be shipped through linked locations, and transport costs depend on congestion and on the infrastructure in each link, giving rise to an optimal transport problem in general equilibrium. The optimal transport network is the solution to a social planner's problem of building infrastructure in each link. We provide conditions such that this problem is globally convex, guaranteeing its numerical tractability. We also study cases with increasing returns to transport technologies in which global convexity fails. We apply the framework to assess optimal investments and inefficiencies in observed road networks in 25 European countries. The counterfactuals suggest larger gains from road network expansion and larger losses from misallocation of current roads in lower-income countries.},
  number = {23200},
  institution = {{National Bureau of Economic Research}},
  author = {Fajgelbaum, Pablo D and Schaal, Edouard},
  year = {2017},
  file = {/Users/xiefangzhou/Zotero/storage/CDIR6BVA/Fajgelbaum and Schaal - 2017 - Optimal Transport Networks in Spatial Equilibrium.pdf}
}

@article{humphries2018,
  title = {The {{Causes}} and {{Consequences}} of {{Self}}-{{Employment}} over the {{Life Cycle}}},
  abstract = {This paper uses population panel data from Sweden to investigate the causes and consequences of self-employment over the life cycle, and to evaluate how self-employment decisions can be influenced by policy. In the first part of the paper, I use machine learning methods to summarize the patterns of self-employment behavior observed in the data. I find that careers involving self-employment fit into a small number of economically distinct groups. Some self-employment spells are short, with minimal capital investment and rapid return to paid employment, while others persist and have substantial capital devoted to the business from the outset. Guided by these descriptive results, I develop and estimate a dynamic Roy model in which self-employment decisions depend on factors such as cognitive and non-cognitive skills, prior work experience, the cost of capital, and other labor market opportunities. The model integrates traditional models of dynamic career choice that feature human capital investment and models of business start-up that feature physical capital investment. I estimate the model and use it to evaluate policies designed to promote self-employment. Cognitive and non-cognitive skills, education, and prior work experience are important determinants of the types of businesses individuals start, how much capital they employ, and how long they remain in self-employment. Subsidies that incentivize self-employment are generally ineffective, both in terms of promoting long-lasting firms and in terms of improving the welfare and earnings of those induced to enter self-employment.},
  language = {en},
  author = {Humphries, John Eric},
  year = {2018},
  pages = {83},
  file = {/Users/xiefangzhou/Zotero/storage/8VVAPD3C/Humphries - 2018 - The Causes and Consequences of Self-Employment ove.pdf}
}

@article{nowlin2016,
  title = {Modeling {{Issue Definitions Using Quantitative Text Analysis}}},
  volume = {44},
  copyright = {\textcopyright{} 2015 Policy Studies Organization},
  issn = {1541-0072},
  abstract = {Issue definitions, the way policy issues are understood, are an important component for understanding the policymaking process. Research on issue definitions has been divided between a macro level that examines collective issue definitions and a micro level focusing on the ways in which policy actors frame policy issues. This article develops a model of issue definitions that assumes issues are multidimensional, competition exists among policy actors in defining issues, and that collective issue definitions can be understood as the aggregation of individual issue definitions. This model is then estimated using quantitative text analysis. While various approaches to text analysis and categorization have been used by scholars, latent Dirichlet allocation (LDA), a specific type of topic modeling, is used to estimate issue definitions. Using LDA, witness testimony taken from Congressional hearings that occurred from 1975 to 2012 about the issue of used nuclear fuel (UNF) is examined and seven distinct dimensions of the UNF debate are estimated. The construct validity of these dimensions is checked by testing them against two major policy changes that occurred in the UNF domain. I conclude with a discussion of the strengths and weakness of topic modeling, and how this approach could be used to test hypotheses drawn from several of the major policymaking theories.},
  language = {en},
  number = {3},
  journal = {Policy Studies Journal},
  author = {Nowlin, Matthew C.},
  year = {2016},
  keywords = {issue definitions,policy process,text analysis},
  pages = {309-331},
  file = {/Users/xiefangzhou/Zotero/storage/8VRRZDCQ/Nowlin - 2016 - Modeling Issue Definitions Using Quantitative Text.pdf;/Users/xiefangzhou/Zotero/storage/RG5EAZSF/psj.html}
}

@article{anderes2016,
  title = {Discrete {{Wasserstein}} Barycenters: Optimal Transport for Discrete Data},
  volume = {84},
  copyright = {Springer-Verlag Berlin Heidelberg 2016},
  issn = {14322994},
  shorttitle = {Discrete {{Wasserstein}} Barycenters},
  abstract = {Wasserstein barycenters correspond to optimal solutions of transportation problems for several marginals, and as such have a wide range of applications ranging from economics to statistics and computer science. When the marginal probability measures are absolutely continuous (or vanish on small sets) the theory of Wasserstein barycenters is well-developed [see the seminal paper (Agueh and Carlier in SIAM J Math Anal 43(2):904-924, 2011 )]. However, exact continuous computation of Wasserstein barycenters in this setting is tractable in only a small number of specialized cases. Moreover, in many applications data is given as a set of probability measures with finite support. In this paper, we develop theoretical results for Wasserstein barycenters in this discrete setting. Our results rely heavily on polyhedral theory which is possible due to the discrete structure of the marginals. The results closely mirror those in the continuous case with a few exceptions. In this discrete setting we establish that Wasserstein barycenters must also be discrete measures and there is always a barycenter which is provably sparse. Moreover, for each Wasserstein barycenter there exists a non-mass-splitting optimal transport to each of the discrete marginals. Such non-mass-splitting transports do not generally exist between two discrete measures unless special mass balance conditions hold. This makes Wasserstein barycenters in this discrete setting special in this regard. We illustrate the results of our discrete barycenter theory with a proof-of-concept computation for a hypothetical transportation problem with multiple marginals: distributing a fixed set of goods when the demand can take on different distributional shapes characterized by the discrete marginal distributions. A Wasserstein barycenter, in this case, represents an optimal distribution of inventory facilities which minimize the squared distance/transportation cost totaled over all demands.},
  language = {English},
  number = {2},
  journal = {Mathematical Methods of Operations Research; Heidelberg},
  author = {Anderes, Ethan and Borgwardt, Steffen and Miller, Jacob},
  year = {2016},
  keywords = {90B80,90C05,90C10,90C46,90C90,Barycenter,Mathematical programming,Multiple marginals,Optimal transport,Polyhedral theory},
  pages = {389-409},
  file = {/Users/xiefangzhou/Zotero/storage/E5WBR4JA/Anderes et al. - 2016 - Discrete Wasserstein barycenters optimal transpor.pdf}
}

@article{jorgensen2004,
  title = {Travel Distance and Optimal Transport Policy},
  volume = {38},
  issn = {0191-2615},
  abstract = {A theoretical model is adopted in order to discuss optimal fare and optimal quality of supply schemes for a transport operator. The analysis shows how fare and quality of supply are related to travel distance and to the transport operator's emphasis on profit versus consumer surplus. Under reasonable assumptions imposed on the actual functions we find that the more weight the operator attaches to profit, the higher the fare level and the higher the generalised travel costs. How the operator's objectives influence the quality of transport and perhaps more surprisingly how travelling distance influences fares, quality of transport and generalised travel costs, are ambiguous with relation to the starting restrictions placed on the actual functions. The paper then discusses the special case in which the quality of transport is exogenous to the transport operator. One important result is that higher demands set to the transport operator regarding the quality of the transport supply do not necessarily reduce the transport users' generalised travel costs. Some of the model's results are commented in the light of empirical studies from Norway.},
  number = {5},
  journal = {Transportation Research Part B: Methodological},
  author = {J{\o}rgensen, Finn and Pedersen, P{\aa}l Andreas},
  year = {2004},
  keywords = {Generalised costs,Operators' objectives,Optimal fare,Optimal quality,Travel distance},
  pages = {415-430},
  file = {/Users/xiefangzhou/Zotero/storage/T4XB8JIS/Jørgensen and Pedersen - 2004 - Travel distance and optimal transport policy.pdf;/Users/xiefangzhou/Zotero/storage/JZAMC6ZI/S0191261503000493.html}
}

@article{carroll1994,
  title = {Does {{Consumer Sentiment Forecast Household Spending}}? {{If So}}, {{Why}}?},
  volume = {84},
  issn = {0002-8282},
  shorttitle = {Does {{Consumer Sentiment Forecast Household Spending}}?},
  number = {5},
  journal = {The American Economic Review},
  author = {Carroll, Christopher D. and Fuhrer, Jeffrey C. and Wilcox, David W.},
  year = {1994},
  pages = {1397-1408},
  file = {/Users/xiefangzhou/Zotero/storage/R865GC3V/Carroll et al. - 1994 - Does Consumer Sentiment Forecast Household Spendin.pdf}
}

@article{blei2003,
  title = {Latent {{Dirichlet Allocation}}},
  volume = {3},
  issn = {ISSN 1533-7928},
  number = {Jan},
  journal = {Journal of Machine Learning Research},
  author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  year = {2003},
  pages = {993-1022},
  file = {/Users/xiefangzhou/Zotero/storage/2GW75FW6/Blei et al. - 2003 - Latent Dirichlet Allocation.pdf;/Users/xiefangzhou/Zotero/storage/TX4FMWHZ/blei03a.html}
}

@article{dybowski2018,
  title = {The Economic Effects of {{U}}.{{S}}. Presidential Tax Communication: {{Evidence}} from a Correlated Topic Model},
  volume = {55},
  issn = {0176-2680},
  shorttitle = {The Economic Effects of {{U}}.{{S}}. Presidential Tax Communication},
  abstract = {We combine a probabilistic topic model and a dictionary-based sentiment analysis to construct a time series, which indicates when and how (positive vs. negative) the U.S. president communicates his tax policy news to the public. The econometric analyses show that optimistic tax policy statements stimulate consumption, investment, and output, even after controlling for tax foresight. We also find that consumer sentiment reacts positively to more optimistic tax news, suggesting that sentiment plays an important role in the transmission from U.S. presidential tax policy communication to economic activity.},
  journal = {European Journal of Political Economy},
  author = {Dybowski, T. P. and Ad{\"a}mmer, P.},
  year = {2018},
  keywords = {News,Sentiment,Tax policy,Topic models,U.S. president},
  pages = {511-525},
  file = {/Users/xiefangzhou/Zotero/storage/8JZSVPPY/Dybowski and Adämmer - 2018 - The economic effects of U.S. presidential tax comm.pdf;/Users/xiefangzhou/Zotero/storage/JL67A9V2/S0176268017302355.html}
}

@article{athey2018,
  title = {The {{Impact}} of {{Machine Learning}} on {{Economics}}},
  journal = {The Economics of Artificial Intelligence: An Agenda},
  author = {Athey, Susan},
  year = {2018},
  file = {/Users/xiefangzhou/Zotero/storage/GBIBVRS2/Athey - 2018 - The Impact of Machine Learning on Economics.pdf;/Users/xiefangzhou/Zotero/storage/RQADYJYV/c14009.html}
}

@article{dudik2011,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1103.4601},
  primaryClass = {cs, stat},
  title = {Doubly {{Robust Policy Evaluation}} and {{Learning}}},
  abstract = {We study decision making in environments where the reward is only partially observed, but can be modeled as a function of an action and an observed context. This setting, known as contextual bandits, encompasses a wide variety of applications including health-care policy and Internet advertising. A central task is evaluation of a new policy given historic data consisting of contexts, actions and received rewards. The key challenge is that the past data typically does not faithfully represent proportions of actions taken by a new policy. Previous approaches rely either on models of rewards or models of the past policy. The former are plagued by a large bias whereas the latter have a large variance. In this work, we leverage the strength and overcome the weaknesses of the two approaches by applying the doubly robust technique to the problems of policy evaluation and optimization. We prove that this approach yields accurate value estimates when we have either a good (but not necessarily consistent) model of rewards or a good (but not necessarily consistent) model of past policy. Extensive empirical comparison demonstrates that the doubly robust approach uniformly improves over existing techniques, achieving both lower variance in value estimation and better policies. As such, we expect the doubly robust approach to become common practice.},
  journal = {arXiv:1103.4601 [cs, stat]},
  author = {Dudik, Miroslav and Langford, John and Li, Lihong},
  year = {2011},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/S8AZWRCX/Dudik et al. - 2011 - Doubly Robust Policy Evaluation and Learning.pdf;/Users/xiefangzhou/Zotero/storage/JYYRIT9T/1103.html}
}

@inproceedings{blei2006,
  address = {{New York, NY, USA}},
  series = {{{ICML}} '06},
  title = {Dynamic {{Topic Models}}},
  isbn = {978-1-59593-383-6},
  abstract = {A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics. Variational approximations based on Kalman filters and nonparametric wavelet regression are developed to carry out approximate posterior inference over the latent topics. In addition to giving quantitative, predictive models of a sequential corpus, dynamic topic models provide a qualitative window into the contents of a large document collection. The models are demonstrated by analyzing the OCR'ed archives of the journal Science from 1880 through 2000.},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Machine Learning}}},
  publisher = {{ACM}},
  author = {Blei, David M. and Lafferty, John D.},
  year = {2006},
  pages = {113--120},
  file = {/Users/xiefangzhou/Zotero/storage/3IU85Y3U/Blei and Lafferty - 2006 - Dynamic Topic Models.pdf}
}

@article{hoffman,
  title = {Stochastic {{Variational Inference}}},
  abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
  language = {en},
  author = {Hoffman, Matthew D},
  pages = {45},
  file = {/Users/xiefangzhou/Zotero/storage/Z4LHWH2Q/Hoffman - Stochastic Variational Inference.pdf}
}

@article{blei2012,
  title = {Probabilistic {{Topic Models}}},
  volume = {55},
  issn = {0001-0782},
  abstract = {Surveying a suite of algorithms that offer a solution to managing large document archives.},
  number = {4},
  journal = {Commun. ACM},
  author = {Blei, David M.},
  year = {2012},
  pages = {77--84},
  file = {/Users/xiefangzhou/Zotero/storage/HSJTLDG8/Blei - 2012 - Probabilistic Topic Models.pdf}
}

@inproceedings{rudolph2018,
  address = {{Republic and Canton of Geneva, Switzerland}},
  series = {{{WWW}} '18},
  title = {Dynamic {{Embeddings}} for {{Language Evolution}}},
  isbn = {978-1-4503-5639-8},
  abstract = {Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the ArXiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.},
  booktitle = {Proceedings of the 2018 {{World Wide Web Conference}}},
  publisher = {{International World Wide Web Conferences Steering Committee}},
  author = {Rudolph, Maja and Blei, David},
  year = {2018},
  keywords = {dynamic modeling,exponential family embeddings,probabilistic modeling,semantic change,word embeddings},
  pages = {1003--1011},
  file = {/Users/xiefangzhou/Zotero/storage/NXSGV7TV/Rudolph and Blei - 2018 - Dynamic Embeddings for Language Evolution.pdf}
}

@incollection{xu2018,
  title = {Distilled {{Wasserstein Learning}} for {{Word Embedding}} and {{Topic Modeling}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 31},
  publisher = {{Curran Associates, Inc.}},
  author = {Xu, Hongteng and Wang, Wenlin and Liu, Wei and Carin, Lawrence},
  editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and {Cesa-Bianchi}, N. and Garnett, R.},
  year = {2018},
  pages = {1723--1732},
  file = {/Users/xiefangzhou/Zotero/storage/5FCSN8Y3/Xu et al. - 2018 - Distilled Wasserstein Learning for Word Embedding .pdf;/Users/xiefangzhou/Zotero/storage/VLKU4XGW/7443-distilled-wasserstein-learning-for-word-embedding-and-topic-modeling.html}
}

@article{hansen2018,
  title = {Transparency and {{Deliberation Within}} the {{FOMC}}: {{A Computational Linguistics Approach}}},
  volume = {133},
  issn = {0033-5533},
  shorttitle = {Transparency and {{Deliberation Within}} the {{FOMC}}},
  abstract = {Abstract.  How does transparency, a key feature of central bank design, affect monetary policy makers' deliberations? Theory predicts a positive discipline effe},
  language = {en},
  number = {2},
  journal = {The Quarterly Journal of Economics},
  author = {Hansen, Stephen and McMahon, Michael and Prat, Andrea},
  year = {2018},
  pages = {801-870},
  file = {/Users/xiefangzhou/Zotero/storage/SA3Z2AZC/Hansen et al. - 2018 - Transparency and Deliberation Within the FOMC A C.pdf;/Users/xiefangzhou/Zotero/storage/UF9GTN9U/4582916.html}
}

@article{baker2016,
  title = {Measuring {{Economic Policy Uncertainty}}},
  volume = {131},
  issn = {0033-5533},
  abstract = {Abstract.  We develop a new index of economic policy uncertainty (EPU) based on newspaper
                    coverage frequency. Several types of evidence\textemdash{}incl},
  language = {en},
  number = {4},
  journal = {The Quarterly Journal of Economics},
  author = {Baker, Scott R. and Bloom, Nicholas and Davis, Steven J.},
  year = {2016},
  pages = {1593-1636},
  file = {/Users/xiefangzhou/Zotero/storage/AATW99L5/Baker et al. - 2016 - Measuring Economic Policy Uncertainty.pdf;/Users/xiefangzhou/Zotero/storage/GQKAMHJH/BBD_QJEformat,_Online_Appendix_Text,_Tables_and_Figures.pdf;/Users/xiefangzhou/Zotero/storage/2K7E9YGJ/2468873.html}
}

@article{larsen2017,
  title = {Components of {{Uncertainty}}},
  issn = {1556-5068},
  abstract = {Uncertainty is acknowledged to be a source of economic fluctuations. But, does the type of uncertainty matter for the economy's response to an uncertainty shock? This paper offers a novel identification strategy to disentangle different types of uncertainty. It uses machine learning techniques to classify different types of news instead of specifying a set of keywords. It is found that, depending on its source, the effects of uncertainty on macroeconomic variable may differ. I find that both good (expansionary effect) and bad (contractionary effect) types of uncertainty exist.},
  language = {en},
  journal = {SSRN Electronic Journal},
  author = {Larsen, Vegard H.},
  year = {2017},
  file = {/Users/xiefangzhou/Zotero/storage/JD4BEZKP/Larsen - 2017 - Components of Uncertainty.pdf}
}

@article{azqueta-gavaldon2017,
  title = {Developing News-Based {{Economic Policy Uncertainty}} Index with Unsupervised Machine Learning},
  volume = {158},
  issn = {0165-1765},
  abstract = {I propose creating a news-based Economic Policy Uncertainty (EPU) index by employing an unsupervised algorithm able to deduce the subject of each article without the need for pre-labeled data.},
  journal = {Economics Letters},
  author = {{Azqueta-Gavald{\'o}n}, Andr{\'e}s},
  year = {2017},
  keywords = {Economic Policy Uncertainty (EPU),Latent Dirichlet Allocation (LDA),Unsupervised machine learning},
  pages = {47-50},
  file = {/Users/xiefangzhou/Zotero/storage/J7YIWAQ6/Azqueta-Gavaldón - 2017 - Developing news-based Economic Policy Uncertainty .pdf;/Users/xiefangzhou/Zotero/storage/9QVTJ43J/S0165176517302598.html}
}

@inproceedings{genevay2016,
  address = {{Barcelona, Spain}},
  series = {Proc. {{NIPS}} 2016},
  title = {Stochastic {{Optimization}} for {{Large}}-Scale {{Optimal Transport}}},
  abstract = {Optimal transport (OT) defines a powerful framework to compare probability distributions in a geometrically faithful way. However, the practical impact of OT is still limited because of its computational burden. We propose a new class of stochastic optimization algorithms to cope with large-scale problems routinely encountered in machine learning applications. These methods are able to manipulate arbitrary distributions (either discrete or continuous) by simply requiring to be able to draw samples from them, which is the typical setup in high-dimensional learning problems. This alleviates the need to discretize these densities, while giving access to provably convergent methods that output the correct distance without discretization error. These algorithms rely on two main ideas: (a) the dual OT problem can be re-cast as the maximization of an expectation ; (b) entropic regularization of the primal OT problem results in a smooth dual optimization optimization which can be addressed with algorithms that have a provably faster convergence. We instantiate these ideas in three different setups: (i) when comparing a discrete distribution to another, we show that incremental stochastic optimization schemes can beat Sinkhorn's algorithm, the current state-of-the-art finite dimensional OT solver; (ii) when comparing a discrete distribution to a continuous density, a semi-discrete reformulation of the dual program is amenable to averaged stochastic gradient descent, leading to better performance than approximately solving the problem by discretization ; (iii) when dealing with two continuous densities, we propose a stochastic gradient descent over a reproducing kernel Hilbert space (RKHS). This is currently the only known method to solve this problem, apart from computing OT on finite samples. We backup these claims on a set of discrete, semi-discrete and continuous benchmark problems.},
  booktitle = {{{NIPS}} 2016 - {{Thirtieth Annual Conference}} on {{Neural Information Processing System}}},
  author = {Genevay, Aude and Cuturi, Marco and Peyr{\'e}, Gabriel and Bach, Francis},
  editor = {{NIPS}},
  year = {2016},
  keywords = {Optimal transport,RKHS,stochastic optimization,Wasserstein distance},
  file = {/Users/xiefangzhou/Zotero/storage/Q45L3HEG/Genevay et al. - 2016 - Stochastic Optimization for Large-scale Optimal Tr.pdf}
}

@inproceedings{wallach2006,
  address = {{New York, NY, USA}},
  series = {{{ICML}} '06},
  title = {Topic {{Modeling}}: {{Beyond Bag}}-of-Words},
  isbn = {978-1-59593-383-6},
  shorttitle = {Topic {{Modeling}}},
  abstract = {Some models of textual corpora employ text generation methods involving n-gram statistics, while others use latent topic variables inferred using the "bag-of-words" assumption, in which word order is ignored. Previously, these methods have not been combined. In this work, I explore a hierarchical generative probabilistic model that incorporates both n-gram statistics and latent topic variables by extending a unigram topic model to include properties of a hierarchical Dirichlet bigram language model. The model hyperparameters are inferred using a Gibbs EM algorithm. On two data sets, each of 150 documents, the new model exhibits better predictive accuracy than either a hierarchical Dirichlet bigram language model or a unigram topic model. Additionally, the inferred topics are less dominated by function words than are topics discovered using unigram statistics, potentially making them more meaningful.},
  booktitle = {Proceedings of the 23rd {{International Conference}} on {{Machine Learning}}},
  publisher = {{ACM}},
  author = {Wallach, Hanna M.},
  year = {2006},
  pages = {977--984},
  file = {/Users/xiefangzhou/Zotero/storage/4H3IUBEF/Wallach - 2006 - Topic Modeling Beyond Bag-of-words.pdf}
}

@techreport{dunker2015,
  type = {Working {{Paper}}},
  title = {Nonparametric Identification of Endogenous and Heterogeneous Aggregate Demand Models: {{Complements}}, Bundles and the Market Level},
  copyright = {http://www.econstor.eu/dspace/Nutzungsbedingungen},
  shorttitle = {Nonparametric Identification of Endogenous and Heterogeneous Aggregate Demand Models},
  abstract = {This paper studies nonparametric identification in market level demand models for differentiated products. We generalize common models by allowing for the distribution of heterogeneity parameters (random coefficients) to have a nonparametric distribution across the population and give conditions under which the density of the random coefficients is identified. We show that key identifying restrictions are provided by (i) a set of moment conditions generated by instrumental variables together with an inversion of aggregate demand in unobserved product characteristics; and (ii) an integral transform (Radon transform) that maps the random coefficient density to the aggregate demand. This feature is shown to be common across a wide class of models, and we illustrate this by studying leading demand models. Our examples include demand models based on the multinomial choice (Berry, Levinsohn, Pakes, 1995), the choice of bundles of goods that can be substitutes or complements, and the choice of goods consumed in multiple units.},
  language = {eng},
  number = {CWP51/15},
  institution = {{cemmap working paper}},
  author = {Dunker, Fabian and Hoderlein, Stefan and Kaido, Hiroaki},
  year = {2015},
  file = {/Users/xiefangzhou/Zotero/storage/L64YLN3S/Dunker et al. - 2015 - Nonparametric identification of endogenous and het.pdf;/Users/xiefangzhou/Zotero/storage/RZIWUMKV/130070.html}
}

@article{fosgerau2018,
  title = {Demand {{Models}} for {{Differentiated Goods}} with {{Complementarity}} and {{Substitutability}}},
  issn = {1556-5068},
  abstract = {We develop a class of demand models for differentiated products. The new models facilitate the BLP method (Berry et al., 1995) while numerical inversion of the demand system is not required. They can accommodate rich patterns of substitution and complementarity while being easily estimated with standard regression techniques and allowing very large choice sets. We use the new models to describe markets for differentiated products that exhibit segmentation according to several dimensions and illustrate their application by estimating demand for cereals in Chicago.},
  language = {en},
  journal = {SSRN Electronic Journal},
  author = {Fosgerau, Mogens and {de Palma}, Andre and Monardo, Julien},
  year = {2018},
  file = {/Users/xiefangzhou/Zotero/storage/R4HM7U6D/Fosgerau et al. - 2018 - Demand Models for Differentiated Goods with Comple.pdf}
}

@article{lee2015,
  title = {A Computationally Fast Estimator for Random Coefficients Logit Demand Models Using Aggregate Data},
  volume = {46},
  issn = {0741-6261},
  abstract = {[This article proposes a computationally fast estimator for random coefficients logit demand models using aggregate data that Berry, Levinsohn, and Pakes (1995; hereinafter, BLP) suggest. Our method, which we call approximate BLP (ABLP), is based on a linear approximation of market share functions. The computational advantages of ABLP include (i) the linear approximation enables us to adopt an analytic inversion of the market share equations instead of a numerical inversion that BLP propose, (ii) ABLP solves the market share equations only at the optimum, and (iii) it minimizes over a typically small dimensional parameter space. We show that the ABLP estimator is equivalent to the BLP estimator in large data sets. Our Monte Carlo experiments illustrate that ABLP is faster than other approaches, especially for large data sets.]},
  number = {1},
  journal = {The RAND Journal of Economics},
  author = {Lee, Jinhyuk and Seo, Kyoungwon},
  year = {2015},
  pages = {86-102},
  file = {/Users/xiefangzhou/Zotero/storage/DCEUWNHC/Lee and Seo - 2015 - A computationally fast estimator for random coeffi.pdf}
}

@techreport{galichon2015,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Cupid's {{Invisible Hand}}: {{Social Surplus}} and {{Identification}} in {{Matching Models}}},
  shorttitle = {Cupid's {{Invisible Hand}}},
  abstract = {We investigate a model of one-to-one matching with transferable utility when some of the characteristics of the players are unobservable to the analyst. We allow for a wide class of distributions of unobserved heterogeneity, subject only to a separability assumption that generalizes Choo and Siow (2006). We first show that the stable matching maximizes a  social gain function that trades off exploiting complementarities in observable characteristic sand matching on unobserved characteristics. We use this result to derive simple closed-form formulae that identify the joint surplus in every possible match and the equilibrium utilities of all participants, given any known distribution of unobserved heterogeneity. If transfers are observed, then the pre-transfer utilities of both partners are also identified. We discuss  computational issues and provide an algorithm that is extremely efficient in important instances. Finally, we present two estimators of the joint surplus and we  revisit Choo and Siow's empirical application  to illustrate the potential of our more general approach.},
  language = {en},
  number = {ID 1804623},
  institution = {{Social Science Research Network}},
  author = {Galichon, Alfred and Salanie, Bernard},
  year = {2015},
  keywords = {SSRN,Alfred Galichon,Bernard Salanie,Cupid’s Invisible Hand: Social Surplus and Identification in Matching Models},
  file = {/Users/xiefangzhou/Zotero/storage/MH6VKJZY/Galichon and Salanie - 2015 - Cupid’s Invisible Hand Social Surplus and Identif.pdf;/Users/xiefangzhou/Zotero/storage/XLPAC6W9/papers.html}
}

@article{choo2006,
  title = {Who {{Marries Whom}} and {{Why}}},
  volume = {114},
  issn = {0022-3808},
  abstract = {This paper proposes and estimates a static transferable utility model of the                     marriage market. The model generates a nonparametric marriage matching function                     with spillover effects. It rationalizes the standard interpretation of marriage                     rate regressions and points out its limitations. The model was used to estimate                     U.S. marital behavior in 1971/72 and 1981/82. The marriage matching function                     estimates show that the gains to marriage for young adults fell substantially                     over the decade. Unlike contradictory marriage rate regression results, the                     marriage matching function estimates showed that the legalization of abortion                     had a significant quantitative impact on the fall in the gains to marriage for                     young men and women.},
  number = {1},
  journal = {Journal of Political Economy},
  author = {Choo, Eugene and Siow, Aloysius},
  year = {2006},
  pages = {175-201},
  file = {/Users/xiefangzhou/Zotero/storage/P4H9WNAN/Choo and Siow - 2006 - Who Marries Whom and Why.pdf;/Users/xiefangzhou/Zotero/storage/MJTLK3HD/498585.html}
}

@techreport{bonnet2018,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Yogurts {{Choose Consumers}}? {{Estimation}} of {{Random Utility Models}} via {{Two}}-{{Sided Matching}}},
  shorttitle = {Yogurts {{Choose Consumers}}?},
  abstract = {In this paper we show that the problem of demand inversion in multinomial choice models is equivalent to the determination of stable outcomes in matching models. This result is very general and applies to random utility models that are not necessarily additive or smooth. Based on this equivalence, we argue that the algorithms for the determination of stable matchings can provide effective computational methods to inverse multinomial choice models, and we give a numerical benchmark of these algorithms. Our approach allows to estimate models that were previously difficult to estimate, such as the pure characteristics model, as well as nonadditive random utility models. The equivalence also allows to exploit the theory of stable matchings in order to describe important properties of the set of utilities solution to the demand inversion problem, and to study the cases of existence and uniqueness of identified utilities, as well as obtain consistency results.},
  language = {en},
  number = {ID 2928876},
  institution = {{Social Science Research Network}},
  author = {Bonnet, Odran and Galichon, Alfred and O'Hara, Keith and Shum, Matthew},
  year = {2018},
  keywords = {Deferred Acceptance,Optimal Transport,Partial Identification,Pure Characteristics Model,Random Utility Models,Two-Sided Matching},
  file = {/Users/xiefangzhou/Zotero/storage/2U58UUIX/Bonnet et al. - 2018 - Yogurts Choose Consumers Estimation of Random Uti.pdf;/Users/xiefangzhou/Zotero/storage/23E8FEXD/papers.html}
}

@article{berry1995,
  title = {Automobile {{Prices}} in {{Market Equilibrium}}},
  volume = {63},
  issn = {0012-9682},
  abstract = {[This paper develops techniques for empirically analyzing demand and supply in differentiated products markets and then applies these techniques to analyze equilibrium in the U.S. automobile industry. Our primary goal is to present a framework which enables one to obtain estimates of demand and cost parameters for a class of oligopolistic differentiated products markets. These estimates can be obtained using only widely available product-level and aggregate consumer-level data, and they are consistent with a structural model of equilibrium in an oligopolistic industry. When we apply the techniques developed here to the U.S. automobile market, we obtain cost and demand parameters for (essentially) all models marketed over a twenty year period.]},
  number = {4},
  journal = {Econometrica},
  author = {Berry, Steven and Levinsohn, James and Pakes, Ariel},
  year = {1995},
  pages = {841-890},
  file = {/Users/xiefangzhou/Zotero/storage/KY7CW4WB/Berry et al. - 1995 - Automobile Prices in Market Equilibrium.pdf}
}

@book{train2009,
  title = {Discrete {{Choice Methods}} with {{Simulation}}},
  isbn = {978-1-139-48037-6},
  abstract = {This book describes the new generation of discrete choice methods, focusing on the many advances that are made possible by simulation. Researchers use these statistical methods to examine the choices that consumers, households, firms, and other agents make. Each of the major models is covered: logit, generalized extreme value, or GEV (including nested and cross-nested logits), probit, and mixed logit, plus a variety of specifications that build on these basics. Recent advances in Bayesian procedures are explored, including the use of the Metropolis-Hastings algorithm and its variant Gibbs sampling. This second edition adds chapters on endogeneity and expectation-maximization (EM) algorithms. No other book incorporates all these fields, which have arisen in the past 25 years. The procedures are applicable in many fields, including energy, transportation, environmental studies, health, labor, and marketing.},
  language = {en},
  publisher = {{Cambridge University Press}},
  author = {Train, Kenneth E.},
  year = {2009},
  keywords = {Business \& Economics / Econometrics,Business \& Economics / Statistics,Mathematics / Probability \& Statistics / General},
  file = {/Users/xiefangzhou/Zotero/storage/6ZA5X9SJ/Train - Discrete Choice Methods with Simulation.pdf}
}

@article{nevo2000,
  title = {A {{Practitioner}}'s {{Guide}} to {{Estimation}} of {{Random}}-{{Coefficients Logit Models}} of {{Demand}}},
  volume = {9},
  issn = {1530-9134},
  abstract = {Estimation of demand is at the heart of many recent studies that examine questions of market power, mergers, innovation, and valuation of new brands in differentiated-products markets. This paper focuses on one of the main methods for estimating demand for differentiated products: random-coefficients logit models. The paper carefully discusses the latest innovations in these methods with the hope of increasing the understanding, and therefore the trust among researchers who have never used them, and reducing the difficulty of their use, thereby aiding in realizing their full potential.},
  language = {en},
  number = {4},
  journal = {Journal of Economics \& Management Strategy},
  author = {Nevo, Aviv},
  year = {2000},
  pages = {513-548},
  file = {/Users/xiefangzhou/Zotero/storage/7KU4BLSP/Nevo - 2000 - A Practitioner's Guide to Estimation of Random-Coe.pdf;/Users/xiefangzhou/Zotero/storage/F65N57AJ/j.1430-9134.2000.00513.html}
}

@techreport{gentzkow2017,
  type = {Working {{Paper}}},
  title = {Text as {{Data}}},
  abstract = {An ever increasing share of human interaction, communication, and culture is recorded as digital text. We provide an introduction to the use of text as an input to economic research. We discuss the features that make text different from other forms of data, offer a practical overview of relevant statistical methods, and survey a variety of applications.},
  number = {23276},
  institution = {{National Bureau of Economic Research}},
  author = {Gentzkow, Matthew and Kelly, Bryan T and Taddy, Matt},
  year = {2017},
  file = {/Users/xiefangzhou/Zotero/storage/PU37Y8X8/Gentzkow et al. - 2017 - Text as Data.pdf}
}

@article{zook2003,
  title = {Underground {{Globalization}}: {{Mapping}} the {{Space}} of {{Flows}} of the {{Internet Adult Industry}}},
  volume = {35},
  issn = {0308-518X, 1472-3409},
  shorttitle = {Underground {{Globalization}}},
  abstract = {This paper develops a case study of the Internet adult industry in order to study the ways in which electronic commerce interacts with geography. Digital products, low barriers to entry, cost differentials, and sensitivity to regulation have created a pervasive and complex geography of models, webmasters, and consumers around the globe. With a series of specially developed datasets on the location of content production, websites, and hosting it is shown that the online adult industry offers people and places outside major metropolitan areas opportunities to become active purveyors of this type of electronic commerce. The roles of these actors, however, are not simply determined by a spaceless logic of cyber-interaction but by histories and economies of the physical places they inhabit. In short, the `space of flows' cannot be understood without reference to the `space of places' to which it connects. This geography also provides a valuable counterpoint to mainstream electronic commerce and highlights the ability of socially marginal and underground interests to use the Internet to form and connect in global networks.},
  language = {en},
  number = {7},
  journal = {Environment and Planning A},
  author = {Zook, Matthew A},
  year = {2003},
  pages = {1261-1286},
  file = {/Users/xiefangzhou/Zotero/storage/4B7MPEZP/Zook - 2003 - Underground Globalization Mapping the Space of Fl.pdf}
}

@article{levitt2007,
  title = {What {{Do Laboratory Experiments Measuring Social Preferences Reveal About}} the {{Real World}}?},
  volume = {21},
  issn = {0895-3309},
  abstract = {A critical question facing experimental economists is whether behavior inside the laboratory is a good indicator of behavior outside the laboratory. To address that question, we build a model in which the choices that individuals make depend not just on financial implications, but also on the nature and extent of scrutiny by others, the particular context in which a decision is embedded, and the manner in which participants and tasks are selected. We present empirical evidence demonstrating the importance of these various factors. To the extent that lab and naturally occurring environments systematically differ on any of these dimensions, the results obtained inside and outside the lab need not correspond. Focusing on experiments designed to measure social preferences, we discuss the extent to which the existing laboratory results generalize to naturally-occurring markets. We summarize cases where the lab may understate the importance of social preferences as well as instances in which the lab might exaggerate
their importance. We conclude by emphasizing the importance of interpreting laboratory and field data through the lens of theory.},
  language = {en},
  number = {2},
  journal = {Journal of Economic Perspectives},
  author = {Levitt, Steven D. and List, John A.},
  year = {2007},
  pages = {153-174},
  file = {/Users/xiefangzhou/Zotero/storage/V92IRN2M/Levitt and List - 2007 - What Do Laboratory Experiments Measuring Social Pr.pdf;/Users/xiefangzhou/Zotero/storage/3TTWV88V/articles.html}
}

@article{levy2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.1279},
  primaryClass = {math},
  title = {A Numerical Algorithm for \${{L}}\_2\$ Semi-Discrete Optimal Transport in {{3D}}},
  abstract = {This paper introduces a numerical algorithm to compute the \$L\_2\$ optimal transport map between two measures \$\textbackslash{}mu\$ and \$\textbackslash{}nu\$, where \$\textbackslash{}mu\$ derives from a density \$\textbackslash{}rho\$ defined as a piecewise linear function (supported by a tetrahedral mesh), and where \$\textbackslash{}nu\$ is a sum of Dirac masses. I first give an elementary presentation of some known results on optimal transport and then observe a relation with another problem (optimal sampling). This relation gives simple arguments to study the objective functions that characterize both problems. I then propose a practical algorithm to compute the optimal transport map between a piecewise linear density and a sum of Dirac masses in 3D. In this semi-discrete setting, Aurenhammer et.al [\textbackslash{}emph\{8th Symposium on Computational Geometry conf. proc.\}, ACM (1992)] showed that the optimal transport map is determined by the weights of a power diagram. The optimal weights are computed by minimizing a convex objective function with a quasi-Newton method. To evaluate the value and gradient of this objective function, I propose an efficient and robust algorithm, that computes at each iteration the intersection between a power diagram and the tetrahedral mesh that defines the measure \$\textbackslash{}mu\$. The numerical algorithm is experimented and evaluated on several datasets, with up to hundred thousands tetrahedra and one million Dirac masses.},
  journal = {arXiv:1409.1279 [math]},
  author = {Levy, Bruno},
  year = {2014},
  keywords = {49M15; 35J96; 65D18,Mathematics - Analysis of PDEs},
  file = {/Users/xiefangzhou/Zotero/storage/F38B5JUW/Levy - 2014 - A numerical algorithm for $L_2$ semi-discrete opti.pdf;/Users/xiefangzhou/Zotero/storage/IXFG4EGI/1409.html}
}

@inproceedings{bottou2010,
  title = {Large-{{Scale Machine Learning}} with {{Stochastic Gradient Descent}}},
  isbn = {978-3-7908-2604-3},
  abstract = {During the last decade, the data sizes have grown faster than the speed of processors. In this context, the capabilities of statistical machine learning methods is limited by the computing time rather than the sample size. A more precise analysis uncovers qualitatively different tradeoffs for the case of small-scale and large-scale learning problems. The large-scale case involves the computational complexity of the underlying optimization algorithm in non-trivial ways. Unlikely optimization algorithms such as stochastic gradient descent show amazing performance for large-scale problems. In particular, second order stochastic gradient and averaged stochastic gradient are asymptotically efficient after a single pass on the training set.},
  language = {en},
  booktitle = {Proceedings of {{COMPSTAT}}'2010},
  publisher = {{Physica-Verlag HD}},
  author = {Bottou, L{\'e}on},
  editor = {Lechevallier, Yves and Saporta, Gilbert},
  year = {2010},
  keywords = {efficiency,online learning,stochastic gradient descent},
  pages = {177-186},
  file = {/Users/xiefangzhou/Zotero/storage/X5BS5EPA/Bottou - 2010 - Large-Scale Machine Learning with Stochastic Gradi.pdf}
}

@article{chiong2016,
  title = {Duality in Dynamic Discrete-Choice Models},
  volume = {7},
  copyright = {Copyright \textcopyright{} 2016 Khai Xiang Chiong, Alfred Galichon, and Matt Shum},
  issn = {1759-7331},
  abstract = {Using results from Convex Analysis, we investigate a novel approach to identification and estimation of discrete-choice models that we call the mass transport approach. We show that the conditional choice probabilities and the choice-specific payoffs in these models are related in the sense of conjugate duality, and that the identification problem is a mass transport problem. Based on this, we propose a new two-step estimator for these models; interestingly, the first step of our estimator involves solving a linear program that is identical to the classic assignment (two-sided matching) game of Shapley and Shubik (1971). The application of convex-analytic tools to dynamic discrete-choice models and the connection with two-sided matching models is new in the literature. Monte Carlo results demonstrate the good performance of this estimator, and we provide an empirical application based on Rust's (1987) bus engine replacement model.},
  language = {en},
  number = {1},
  journal = {Quantitative Economics},
  author = {Chiong, Khai Xiang and Galichon, Alfred and Shum, Matt},
  year = {2016},
  keywords = {C35,C61,Conditional choice probability inversion,D90,estimation of discrete choice models,mass transportation approach},
  pages = {83-115},
  file = {/Users/xiefangzhou/Zotero/storage/6E9C88JN/Chiong et al. - 2016 - Duality in dynamic discrete-choice models.pdf;/Users/xiefangzhou/Zotero/storage/LCASQGNG/QE436.html}
}

@article{demange1985,
  title = {The {{Strategy Structure}} of {{Two}}-{{Sided Matching Markets}}},
  volume = {53},
  issn = {0012-9682},
  abstract = {[We study two-sided markets in which agents are buyers and sellers or firms and workers or men and women. The agents are to form partnerships (which provide them with satisfaction) and at the same time make monetary transfers (e.g. salaries or dowries). The core of this market game is shown to have a particularly nice structure so that precise answers can be given to questions concerning comparative statics and manipulability.]},
  number = {4},
  journal = {Econometrica},
  author = {Demange, Gabrielle and Gale, David},
  year = {1985},
  pages = {873-888},
  file = {/Users/xiefangzhou/Zotero/storage/XTBFNK9X/Demange and Gale - 1985 - The Strategy Structure of Two-Sided Matching Marke.pdf}
}

@techreport{schoenherr2018,
  address = {{Rochester, NY}},
  type = {{{SSRN Scholarly Paper}}},
  title = {Political {{Connections}} and {{Allocative Distortions}}},
  abstract = {Exploiting a unique institutional setting in Korea, this paper documents how politicians can increase the amount of government resources allocated through their social networks to the benefit of private firms connected to these networks. After winning the election, the new president appoints members of his networks as CEOs of state-owned firms that act as intermediaries in allocating government contracts to private firms. In turn, these state firms allocate significantly more procurement contracts to private firms with a CEO from the same network. Contracts allocated to connected private firms are executed systematically worse and exhibit more frequent cost increases through renegotiations.},
  language = {en},
  number = {ID 2480261},
  institution = {{Social Science Research Network}},
  author = {Schoenherr, David},
  year = {2018},
  keywords = {social networks,allocative efficiency,political connections,public procurement,rent-seeking},
  file = {/Users/xiefangzhou/Zotero/storage/ESP3K8LA/Schoenherr - 2018 - Political Connections and Allocative Distortions.pdf;/Users/xiefangzhou/Zotero/storage/6M89U8WS/papers.html}
}

@article{claveria2016,
  title = {Combination Forecasts of Tourism Demand with Machine Learning Models},
  volume = {23},
  issn = {1350-4851},
  abstract = {The main objective of this study is to analyse whether the combination of regional predictions generated with machine learning (ML) models leads to improved forecast accuracy. With this aim, we construct one set of forecasts by estimating models on the aggregate series, another set by using the same models to forecast the individual series prior to aggregation, and then we compare the accuracy of both approaches. We use three ML techniques: support vector regression, Gaussian process regression and neural network models. We use an autoregressive moving average model as a benchmark. We find that ML methods improve their forecasting performance with respect to the benchmark as forecast horizons increase, suggesting the suitability of these techniques for mid- and long-term forecasting. In spite of the fact that the disaggregated approach yields more accurate predictions, the improvement over the benchmark occurs for shorter forecast horizons with the direct approach.},
  number = {6},
  journal = {Applied Economics Letters},
  author = {Claveria, Oscar and Monte, Enric and Torra, Salvador},
  year = {2016},
  keywords = {C22,C45,C63,Forecast combination,Gaussian process regression,machine learning,neural networks,support vector regression},
  pages = {428-431},
  file = {/Users/xiefangzhou/Zotero/storage/LQDWZI4S/Claveria et al. - 2016 - Combination forecasts of tourism demand with machi.pdf;/Users/xiefangzhou/Zotero/storage/CDAXIDKG/13504851.2015.html}
}

@article{bajari2015,
  title = {Machine {{Learning Methods}} for {{Demand Estimation}}},
  volume = {105},
  issn = {0002-8282},
  abstract = {We survey and apply several techniques from the statistical and computer science literature to the problem of demand estimation. To improve out-of-sample prediction accuracy, we propose a method of combining the underlying models via linear regression. Our method is robust to a large number of regressors; scales easily to very large data sets; combines model selection and estimation; and can flexibly approximate arbitrary non-linear functions. We illustrate our method using a standard scanner panel data set and find that our estimates are considerably more accurate in out-of-sample predictions of demand than some commonly used alternatives.},
  language = {English},
  number = {5},
  journal = {American Economic Review},
  author = {Bajari, Patrick and Nekipelov, Denis and Ryan, Stephen P. and Yang, Miaoyu},
  year = {2015},
  keywords = {Belief,Communication,Information and Knowledge,Learning,Regression,Single Equation Models,and Selection (C52),Consumer Economics: Empirical Analysis (D12),Estimation,Large Data Sets: Modeling and Analysis (C55),Model Evaluation,Search,Single Variables: General (C20),Unawareness (D83),Validation},
  pages = {481-485},
  file = {/Users/xiefangzhou/Zotero/storage/WPZIBVM2/Bajari et al. - 2015 - Machine Learning Methods for Demand Estimation.pdf}
}

@article{abdessalem2018,
  title = {A Wavelet Technique for the Study of Economic Socio-Political Situations in a Textual Analysis Framework},
  volume = {45},
  issn = {0144-3585},
  number = {3},
  journal = {Journal of Economic Studies},
  author = {Abdessalem, Habiba and Benammou, Saloua},
  year = {2018},
  keywords = {Correspondence analysis,K-means classification,Socio-political situations,Textual data,Wavelet thresholding},
  pages = {586-597},
  file = {/Users/xiefangzhou/Zotero/storage/82EJDFI8/Abdessalem and Benammou - 2018 - A wavelet technique for the study of economic soci.pdf;/Users/xiefangzhou/Zotero/storage/HTLXZ6F3/JES-08-2017-0231.html}
}

@article{berry2007,
  title = {The {{Pure Characteristics Demand Model}}*},
  volume = {48},
  issn = {1468-2354},
  abstract = {In this article, we consider a class of discrete choice models in which consumers care about a finite set of product characteristics. These models have been used extensively in the theoretical literature on product differentiation and the goal of this article is to translate them into a form that is useful for empirical work. Most recent econometric applications of discrete choice models implicitly let the dimension of the characteristic space increase with the number of products (they have ``tastes for products''). The two models have different theoretical properties, and these, in turn, can have quite pronounced implications for both substitution patterns and for the welfare impacts of changes in the number and characteristics of the goods marketed. After developing those properties, we provide alternative algorithms for estimating the parameters of the pure characteristic model and compare their properties to those of the algorithm for estimating the model with tastes for products. We conclude with a series of Monte Carlo results. These are designed to illustrate: (i) the computational properties of the alternative algorithms for computing the pure characteristic model, and (ii) the differences in the implications of the pure characteristic model from the models with tastes for products.},
  language = {en},
  number = {4},
  journal = {International Economic Review},
  author = {Berry, Steven and Pakes, Ariel},
  year = {2007},
  pages = {1193-1225},
  file = {/Users/xiefangzhou/Zotero/storage/VM6TQBSY/Berry and Pakes - 2007 - The Pure Characteristics Demand Model.pdf;/Users/xiefangzhou/Zotero/storage/FYNWZDLU/j.1468-2354.2007.00459.html}
}

@article{dupuy2014,
  title = {Personality {{Traits}} and the {{Marriage Market}}},
  volume = {122},
  issn = {0022-3808},
  abstract = {Which and how many attributes are relevant for the sorting of agents in a matching market? This paper addresses these questions by constructing indices of mutual attractiveness that aggregate information about agents' attributes. The first k indices for agents on each side of the market provide the best approximation of the matching surplus by a k-dimensional model. The methodology is applied on a unique Dutch household survey containing information about education, height, body mass index, health, attitude toward risk, and personality traits of spouses.},
  number = {6},
  journal = {Journal of Political Economy},
  author = {Dupuy, Arnaud and Galichon, Alfred},
  year = {2014},
  pages = {1271-1319},
  file = {/Users/xiefangzhou/Zotero/storage/XGR6WB9D/Dupuy and Galichon - 2014 - Personality Traits and the Marriage Market.pdf;/Users/xiefangzhou/Zotero/storage/24SAWTNL/677191.html}
}

@article{karalevicius2018,
  title = {Using {{Sentiment Analysis}} to {{Predict Interday Bitcoin Price Movements}}},
  volume = {19},
  issn = {1526-5943},
  abstract = {The purpose of this study is to measure the interaction between media sentiment and the Bitcoin price. Because some researchers argued that the Bitcoin value is also determined by perception of users and investors, this paper examines how. The database of relative news articles as well as blog posts has been collected for the purpose of this research. Hence, each article has been given a sentiment score depending on the negative and positive words used in the article. This paper has identified that interaction between media sentiment and the Bitcoin price exists, and that there is a tendency for investors to overreact on news in a short period of time.},
  language = {English},
  number = {1},
  journal = {Journal of Risk Finance},
  author = {Karalevicius, Vytautas},
  year = {2018},
  keywords = {Asset Pricing,Bond Interest Rates (G12),Event Studies,Government and the Monetary System,Information and Market Efficiency,Insider Trading (G14),Monetary Systems,Payment Systems (E42),Regimes,Standards,Trading Volume},
  pages = {56-75},
  file = {/Users/xiefangzhou/Zotero/storage/XSEWVC5A/Karalevicius - 2018 - Using Sentiment Analysis to Predict Interday Bitco.pdf}
}

@article{manning2017,
  title = {How {{Local Are Labor Markets}}? {{Evidence}} from a {{Spatial Job Search Model}}},
  volume = {107},
  issn = {0002-8282},
  shorttitle = {How {{Local Are Labor Markets}}?},
  abstract = {This paper models the optimal search strategies of the unemployed across space to characterize local labor markets. Our methodology allows for linkages between numerous areas, while preserving tractability. We estimate that labor markets are quite local, as the attractiveness of jobs to applicants sharply decays with distance. Also, workers are discouraged from searching in areas with strong competition from other job-seekers. However, as labor markets overlap, a local stimulus or transport improvements have modest effects on local outcomes, because ripple effects in job applications dilute their impact across a series of overlapping markets.},
  language = {en},
  number = {10},
  journal = {American Economic Review},
  author = {Manning, Alan and Petrongolo, Barbara},
  year = {2017},
  keywords = {Population,Geographic Labor Mobility,Immigrant Workers; Unemployment: Models; Duration; Incidence; and Job Search; Urban; Rural; Regional; Real Estate; and Transportation Economics: Regional Migration,Neighborhood Characteristics; Regional Development Planning and Policy,Regional Labor Markets},
  pages = {2877-2907},
  file = {/Users/xiefangzhou/Zotero/storage/NN8Z2FF3/Manning and Petrongolo - 2017 - How Local Are Labor Markets Evidence from a Spati.pdf;/Users/xiefangzhou/Zotero/storage/9R5ELM7C/articles.html}
}

@article{martini2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.06510},
  primaryClass = {physics},
  title = {Entropic Selection of Concepts Unveils Hidden Topics in Documents Corpora},
  abstract = {The organization and evolution of science has recently become itself an object of scientific quantitative investigation, thanks to the wealth of information that can be extracted from scientific documents, such as citations between papers and co-authorship between researchers. However, only few studies have focused on the concepts that characterize full documents and that can be extracted and analyzed, revealing the deeper organization of scientific knowledge. Unfortunately, several concepts can be so common across documents that they hinder the emergence of the underlying topical structure of the document corpus, because they give rise to a large amount of spurious and trivial relations among documents. To identify and remove common concepts, we introduce a method to gauge their relevance according to an objective information-theoretic measure related to the statistics of their occurrence across the document corpus. After progressively removing concepts that, according to this metric, can be considered as generic, we find that the topic organization displays a correspondingly more refined structure.},
  journal = {arXiv:1705.06510 [physics]},
  author = {Martini, Andrea and Cardillo, Alessio and Rios, Paolo De Los},
  year = {2017},
  keywords = {Computer Science - Computation and Language,Computer Science - Digital Libraries,Computer Science - Social and Information Networks,Physics - Physics and Society},
  file = {/Users/xiefangzhou/Zotero/storage/DPGFV3QL/Martini et al. - 2017 - Entropic selection of concepts unveils hidden topi.pdf;/Users/xiefangzhou/Zotero/storage/VCZCAXSQ/1705.html}
}

@article{azzimonti2018,
  series = {Carnegie-{{Rochester}}-{{NYU Conference}} on {{Public Policy}} Held at the {{Stern School}} of {{Business}} at {{New York University}}},
  title = {Partisan Conflict and Private Investment},
  volume = {93},
  issn = {0304-3932},
  abstract = {American politics have been characterized by a high degree of partisan conflict in recent years. Combined with a divided government, this has led not only to significant Congressional gridlock, but also to spells of high fiscal policy uncertainty. The unusually slow recovery from the Great Recession during the same period suggests the possibility that the two phenomena may be related. In this paper, I investigate the hypothesis that political discord depresses private investment. To this end, I construct a novel high-frequency indicator of partisan conflict. The partisan conflict index (PCI) uses a semantic search methodology to measure the frequency of newspaper articles reporting lawmakers' disagreement about policy. I find a negative relationship between the PCI and aggregate investment in the US. Moreover, the decline is persistent, which may help explain the slow recovery observed since the 2007 recession ended. Partisan conflict is also associated with lower capital investment rates at the firm level, even when economic policy uncertainty and macroeconomic conditions are controlled for. I estimate that about 27\% of the decline in corporate investment between 2007\textendash{}2009 can be attributed to a rise in partisan conflict.},
  journal = {Journal of Monetary Economics},
  author = {Azzimonti, Marina},
  year = {2018},
  pages = {114-131},
  file = {/Users/xiefangzhou/Zotero/storage/BVRUPKEJ/Azzimonti - 2018 - Partisan conflict and private investment.pdf;/Users/xiefangzhou/Zotero/storage/MBMDJXQS/S0304393217301228.html}
}

@incollection{cuturi2013,
  title = {Sinkhorn {{Distances}}: {{Lightspeed Computation}} of {{Optimal Transport}}},
  shorttitle = {Sinkhorn {{Distances}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  publisher = {{Curran Associates, Inc.}},
  author = {Cuturi, Marco},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  year = {2013},
  pages = {2292--2300},
  file = {/Users/xiefangzhou/Zotero/storage/GSBI37QR/Cuturi - 2013 - Sinkhorn Distances Lightspeed Computation of Opti.pdf;/Users/xiefangzhou/Zotero/storage/4WGDI8GF/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport.html}
}

@incollection{altschuler2017,
  title = {Near-Linear Time Approximation Algorithms for Optimal Transport via {{Sinkhorn}} Iteration},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  publisher = {{Curran Associates, Inc.}},
  author = {Altschuler, Jason and Weed, Jonathan and Rigollet, Philippe},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  pages = {1964--1974},
  file = {/Users/xiefangzhou/Zotero/storage/MX5P28VV/Altschuler et al. - 2017 - Near-linear time approximation algorithms for opti.pdf;/Users/xiefangzhou/Zotero/storage/JCQS9D95/6792-near-linear-time-approximation-algorithms-for-optimal-transport-via-sinkhorn-iteration.html}
}

@article{schmitz2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1708.01955},
  title = {Wasserstein {{Dictionary Learning}}: {{Optimal Transport}}-Based Unsupervised Non-Linear Dictionary Learning},
  volume = {11},
  issn = {1936-4954},
  shorttitle = {Wasserstein {{Dictionary Learning}}},
  abstract = {This paper introduces a new nonlinear dictionary learning method for histograms in the probability simplex. The method leverages optimal transport theory, in the sense that our aim is to reconstruct histograms using so-called displacement interpolations (a.k.a. Wasserstein barycenters) between dictionary atoms; such atoms are themselves synthetic histograms in the probability simplex. Our method simultaneously estimates such atoms, and, for each datapoint, the vector of weights that can optimally reconstruct it as an optimal transport barycenter of such atoms. Our method is computationally tractable thanks to the addition of an entropic regularization to the usual optimal transportation problem, leading to an approximation scheme that is efficient, parallel and simple to differentiate. Both atoms and weights are learned using a gradient-based descent method. Gradients are obtained by automatic differentiation of the generalized Sinkhorn iterations that yield barycenters with entropic smoothing. Because of its formulation relying on Wasserstein barycenters instead of the usual matrix product between dictionary and codes, our method allows for nonlinear relationships between atoms and the reconstruction of input data. We illustrate its application in several different image processing settings.},
  number = {1},
  journal = {SIAM Journal on Imaging Sciences},
  author = {Schmitz, Morgan A. and Heitz, Matthieu and Bonneel, Nicolas and Mboula, Fred Maurice Ngol{\`e} and Coeurjolly, David and Cuturi, Marco and Peyr{\'e}, Gabriel and Starck, Jean-Luc},
  year = {2018},
  keywords = {Statistics - Machine Learning,Computer Science - Graphics,Mathematics - Optimization and Control},
  pages = {643-678},
  file = {/Users/xiefangzhou/Zotero/storage/ILR4AAFK/Schmitz et al. - 2018 - Wasserstein Dictionary Learning Optimal Transport.pdf;/Users/xiefangzhou/Zotero/storage/KMB4VX7J/1708.html}
}

@article{leonard2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1308.0215},
  primaryClass = {math},
  title = {A Survey of the {{Schr}}\textbackslash{}"odinger Problem and Some of Its Connections with Optimal Transport},
  abstract = {This article is aimed at presenting the Schr\textbackslash{}"odinger problem and some of its connections with optimal transport. We hope that it can be used as a basic user's guide to Schr\textbackslash{}"odinger problem. We also give a survey of the related literature. In addition, some new results are proved.},
  journal = {arXiv:1308.0215 [math]},
  author = {L{\'e}onard, Christian},
  year = {2013},
  keywords = {Mathematics - Optimization and Control,Mathematics - Functional Analysis,Mathematics - Probability},
  file = {/Users/xiefangzhou/Zotero/storage/ISFV8RWW/Léonard - 2013 - A survey of the Schrodinger problem and some of .pdf;/Users/xiefangzhou/Zotero/storage/WJPBRX2E/1308.html}
}

@article{agueh2011,
  title = {Barycenters in the {{Wasserstein Space}}},
  volume = {43},
  issn = {0036-1410},
  abstract = {In this paper, we introduce a notion of barycenter in the Wasserstein space which generalizes McCann's interpolation to the case of more than two measures. We provide existence, uniqueness, characterizations, and regularity of the barycenter and relate it to the multimarginal optimal transport problem considered by Gangbo and {\'S}wi{\k{e}}ch in [Comm. Pure Appl. Math., 51 (1998), pp. 23\textendash{}45]. We also consider some examples and, in particular, rigorously solve the Gaussian case. We finally discuss convexity of functionals in the Wasserstein space.},
  number = {2},
  journal = {SIAM Journal on Mathematical Analysis},
  author = {Agueh, M. and Carlier, G.},
  year = {2011},
  pages = {904-924},
  file = {/Users/xiefangzhou/Zotero/storage/FTRTPXXT/Agueh and Carlier - 2011 - Barycenters in the Wasserstein Space.pdf;/Users/xiefangzhou/Zotero/storage/LP3DY3BB/100805741.html}
}

@article{lopez-paz2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.03643},
  primaryClass = {cs, stat},
  title = {Unifying Distillation and Privileged Information},
  abstract = {Distillation (Hinton et al., 2015) and privileged information (Vapnik \& Izmailov, 2015) are two techniques that enable machines to learn from other machines. This paper unifies these two techniques into generalized distillation, a framework to learn from multiple machines and data representations. We provide theoretical and causal insight about the inner workings of generalized distillation, extend it to unsupervised, semisupervised and multitask learning scenarios, and illustrate its efficacy on a variety of numerical simulations on both synthetic and real-world data.},
  journal = {arXiv:1511.03643 [cs, stat]},
  author = {{Lopez-Paz}, David and Bottou, L{\'e}on and Sch{\"o}lkopf, Bernhard and Vapnik, Vladimir},
  year = {2015},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/ZNF4A8QM/Lopez-Paz et al. - 2015 - Unifying distillation and privileged information.pdf;/Users/xiefangzhou/Zotero/storage/F6ZLKEKQ/1511.html}
}

@article{singh2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1808.09663},
  primaryClass = {cs, stat},
  title = {Context {{Mover}}'s {{Distance}} \& {{Barycenters}}: {{Optimal}} Transport of Contexts for Building Representations},
  shorttitle = {Context {{Mover}}'s {{Distance}} \& {{Barycenters}}},
  abstract = {We propose a unified framework for building unsupervised representations of entities and their compositions, by viewing each entity as a histogram (or distribution) over its contexts. This enables us to take advantage of optimal transport and construct representations that effectively harness the geometry of the underlying space containing the contexts. Our method captures uncertainty via modelling the entities as distributions and simultaneously provides interpretability with the optimal transport map, hence giving a novel perspective for building rich and powerful feature representations. As a guiding example, we formulate unsupervised representations for text, and demonstrate it on tasks such as sentence similarity and word entailment detection. Empirical results show strong advantages gained through the proposed framework. This approach can potentially be used for any unsupervised or supervised problem (on text or other modalities) with a co-occurrence structure, such as any sequence data. The key tools at the core of this framework are Wasserstein distances and Wasserstein barycenters.},
  journal = {arXiv:1808.09663 [cs, stat]},
  author = {Singh, Sidak Pal and Hug, Andreas and Dieuleveut, Aymeric and Jaggi, Martin},
  year = {2018},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Computation and Language},
  file = {/Users/xiefangzhou/Zotero/storage/EB2C9FHW/Singh et al. - 2018 - Context Mover's Distance & Barycenters Optimal tr.pdf;/Users/xiefangzhou/Zotero/storage/UJPGCZC5/1808.html}
}

@article{courty2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1710.07457},
  primaryClass = {cs, stat},
  title = {Learning {{Wasserstein Embeddings}}},
  abstract = {The Wasserstein distance received a lot of attention recently in the community of machine learning, especially for its principled way of comparing distributions. It has found numerous applications in several hard problems, such as domain adaptation, dimensionality reduction or generative models. However, its use is still limited by a heavy computational cost. Our goal is to alleviate this problem by providing an approximation mechanism that allows to break its inherent complexity. It relies on the search of an embedding where the Euclidean distance mimics the Wasserstein distance. We show that such an embedding can be found with a siamese architecture associated with a decoder network that allows to move from the embedding space back to the original input space. Once this embedding has been found, computing optimization problems in the Wasserstein space (e.g. barycenters, principal directions or even archetypes) can be conducted extremely fast. Numerical experiments supporting this idea are conducted on image datasets, and show the wide potential benefits of our method.},
  journal = {arXiv:1710.07457 [cs, stat]},
  author = {Courty, Nicolas and Flamary, R{\'e}mi and Ducoffe, M{\'e}lanie},
  year = {2017},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Computer Vision and Pattern Recognition,Statistics - Computation},
  file = {/Users/xiefangzhou/Zotero/storage/23Z2TDSY/Courty et al. - 2017 - Learning Wasserstein Embeddings.pdf;/Users/xiefangzhou/Zotero/storage/GTI72WHV/1710.html}
}

@inproceedings{pennington2014,
  address = {{Doha, Qatar}},
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  shorttitle = {Glove},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  publisher = {{Association for Computational Linguistics}},
  author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  year = {2014},
  pages = {1532--1543},
  file = {/Users/xiefangzhou/Zotero/storage/LKRIUE57/Pennington et al. - 2014 - Glove Global Vectors for Word Representation.pdf}
}

@article{mikolov2013,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1301.3781},
  primaryClass = {cs},
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  journal = {arXiv:1301.3781 [cs]},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/xiefangzhou/Zotero/storage/KDSQF3TN/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/Users/xiefangzhou/Zotero/storage/IYK9PSJF/1301.html}
}

@incollection{mikolov2013a,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  publisher = {{Curran Associates, Inc.}},
  author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  year = {2013},
  pages = {3111--3119},
  file = {/Users/xiefangzhou/Zotero/storage/GIULBAF5/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf;/Users/xiefangzhou/Zotero/storage/MBTVJGDP/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.html}
}

@incollection{bengio2001,
  title = {A {{Neural Probabilistic Language Model}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 13},
  publisher = {{MIT Press}},
  author = {Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal},
  editor = {Leen, T. K. and Dietterich, T. G. and Tresp, V.},
  year = {2001},
  pages = {932--938},
  file = {/Users/xiefangzhou/Zotero/storage/MPYF9VKL/Bengio et al. - 2001 - A Neural Probabilistic Language Model.pdf;/Users/xiefangzhou/Zotero/storage/W83PZL2C/1839-a-neural-probabilistic-language-model.html}
}

@article{knight2008,
  title = {The {{Sinkhorn}}\textendash{{Knopp Algorithm}}: {{Convergence}} and {{Applications}}},
  volume = {30},
  issn = {0895-4798},
  shorttitle = {The {{Sinkhorn}}\textendash{{Knopp Algorithm}}},
  abstract = {As long as a square nonnegative matrix A contains sufficient nonzero elements, then the Sinkhorn\textendash{}Knopp algorithm can be used to balance the matrix, that is, to find a diagonal scaling of A that is doubly stochastic. It is known that the convergence is linear, and an upper bound has been given for the rate of convergence for positive matrices. In this paper we give an explicit expression for the rate of convergence for fully indecomposable matrices. We describe how balancing algorithms can be used to give a measure of web page significance. We compare the measure with some well known alternatives, including PageRank. We show that, with an appropriate modification, the Sinkhorn\textendash{}Knopp algorithm is a natural candidate for computing the measure on enormous data sets.},
  number = {1},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  author = {Knight, P.},
  year = {2008},
  pages = {261-275},
  file = {/Users/xiefangzhou/Zotero/storage/GZNBP5RY/Knight - 2008 - The Sinkhorn–Knopp Algorithm Convergence and Appl.pdf;/Users/xiefangzhou/Zotero/storage/6SY6PCFU/060659624.html}
}

@article{schrieber2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1610.03368},
  title = {{{DOTmark}} - {{A Benchmark}} for {{Discrete Optimal Transport}}},
  volume = {5},
  issn = {2169-3536},
  abstract = {The Wasserstein metric or earth mover's distance (EMD) is a useful tool in statistics, machine learning and computer science with many applications to biological or medical imaging, among others. Especially in the light of increasingly complex data, the computation of these distances via optimal transport is often the limiting factor. Inspired by this challenge, a variety of new approaches to optimal transport has been proposed in recent years and along with these new methods comes the need for a meaningful comparison. In this paper, we introduce a benchmark for discrete optimal transport, called DOTmark, which is designed to serve as a neutral collection of problems, where discrete optimal transport methods can be tested, compared to one another, and brought to their limits on large-scale instances. It consists of a variety of grayscale images, in various resolutions and classes, such as several types of randomly generated images, classical test images and real data from microscopy. Along with the DOTmark we present a survey and a performance test for a cross section of established methods ranging from more traditional algorithms, such as the transportation simplex, to recently developed approaches, such as the shielding neighborhood method, and including also a comparison with commercial solvers.},
  journal = {IEEE Access},
  author = {Schrieber, J{\"o}rn and Schuhmacher, Dominic and Gottschlich, Carsten},
  year = {2017},
  keywords = {Mathematics - Optimization and Control,Computer Science - Computer Vision and Pattern Recognition,90-08; 90-04; 90C05; 90C08},
  pages = {271-282},
  file = {/Users/xiefangzhou/Zotero/storage/8D47VKZI/Schrieber et al. - 2017 - DOTmark - A Benchmark for Discrete Optimal Transpo.pdf;/Users/xiefangzhou/Zotero/storage/FUBA4MNP/1610.html}
}

@article{peyre2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1803.00567},
  primaryClass = {stat},
  title = {Computational {{Optimal Transport}}},
  abstract = {Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a "global" cost to every such transport, using the "local" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.},
  journal = {arXiv:1803.00567 [stat]},
  author = {Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2018},
  keywords = {Statistics - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/F7FY7EUW/Peyré and Cuturi - 2018 - Computational Optimal Transport.pdf;/Users/xiefangzhou/Zotero/storage/QFJG64FN/1803.html}
}

@inproceedings{dvurechensky2018,
  title = {Computational {{Optimal Transport}}: {{Complexity}} by {{Accelerated Gradient Descent Is Better Than}} by {{Sinkhorn}}'s {{Algorithm}}},
  shorttitle = {Computational {{Optimal Transport}}},
  abstract = {We analyze two algorithms for approximating the general optimal transport (OT) distance between two discrete distributions of size \$n\$, up to accuracy \$\textbackslash{}varepsilon\$. For the first algorithm, which ...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Dvurechensky, Pavel and Gasnikov, Alexander and Kroshnin, Alexey},
  year = {2018},
  pages = {1367-1376},
  file = {/Users/xiefangzhou/Zotero/storage/BV3LN2WU/Dvurechensky et al. - 2018 - Computational Optimal Transport Complexity by Acc.pdf;/Users/xiefangzhou/Zotero/storage/2BMNI9WK/dvurechensky18a.html}
}

@article{ruder2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.04747},
  primaryClass = {cs},
  title = {An Overview of Gradient Descent Optimization Algorithms},
  abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
  journal = {arXiv:1609.04747 [cs]},
  author = {Ruder, Sebastian},
  year = {2016},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/4KIVVDAB/Ruder - 2016 - An overview of gradient descent optimization algor.pdf;/Users/xiefangzhou/Zotero/storage/NVC2CG4L/1609.html}
}

@article{genevay2017,
  title = {Learning {{Generative Models}} with {{Sinkhorn Divergences}}},
  abstract = {The ability to compare two degenerate probability distributions (i.e. two
probability distributions supported on two distinct low-dimensional manifolds
living in a much higher-dimensional space) is a crucial problem arising in the
estimation of generative models for high-dimensional observations such as those
arising in computer vision or natural language. It is known that optimal
transport metrics can represent a cure for this problem, since they were
specifically designed as an alternative to information divergences to handle
such problematic scenarios. Unfortunately, training generative machines using
OT raises formidable computational and statistical challenges, because of (i)
the computational burden of evaluating OT losses, (ii) the instability and lack
of smoothness of these losses, (iii) the difficulty to estimate robustly these
losses and their gradients in high dimension. This paper presents the first
tractable computational method to train large scale generative models using an
optimal transport loss, and tackles these three issues by relying on two key
ideas: (a) entropic smoothing, which turns the original OT loss into one that
can be computed using Sinkhorn fixed point iterations; (b) algorithmic
(automatic) differentiation of these iterations. These two approximations
result in a robust and differentiable approximation of the OT loss with
streamlined GPU execution. Entropic smoothing generates a family of losses
interpolating between Wasserstein (OT) and Maximum Mean Discrepancy (MMD), thus
allowing to find a sweet spot leveraging the geometry of OT and the favorable
high-dimensional sample complexity of MMD which comes with unbiased gradient
estimates. The resulting computational architecture complements nicely standard
deep network generative models by a stack of extra layers implementing the loss
function.},
  language = {en},
  author = {Genevay, Aude and Peyr{\'e}, Gabriel and Cuturi, Marco},
  year = {2017},
  file = {/Users/xiefangzhou/Zotero/storage/N6NXSBUS/Genevay et al. - 2017 - Learning Generative Models with Sinkhorn Divergenc.pdf;/Users/xiefangzhou/Zotero/storage/XFSHDTVA/1706.html}
}

@incollection{marzouk2016,
  address = {{Cham}},
  title = {Sampling via {{Measure Transport}}: {{An Introduction}}},
  isbn = {978-3-319-11259-6},
  shorttitle = {Sampling via {{Measure Transport}}},
  abstract = {We present the fundamentals of a measure transport approach to sampling. The idea is to construct a deterministic coupling \textendash{} i.e., a transport map \textendash{} between a complex ``target'' probability measure of interest and a simpler reference measure. Given a transport map, one can generate arbitrarily many independent and unweighted samples from the target simply by pushing forward reference samples through the map. If the map is endowed with a triangular structure, one can also easily generate samples from conditionals of the target measure. We consider two different and complementary scenarios: first, when only evaluations of the unnormalized target density are available and, second, when the target distribution is known only through a finite collection of samples. We show that in both settings, the desired transports can be characterized as the solutions of variational problems. We then address practical issues associated with the optimization-based construction of transports: choosing finite-dimensional parameterizations of the map, enforcing monotonicity, quantifying the error of approximate transports, and refining approximate transports by enriching the corresponding approximation spaces. Approximate transports can also be used to ``Gaussianize'' complex distributions and thus precondition conventional asymptotically exact sampling schemes. We place the measure transport approach in broader context, describing connections with other optimization-based samplers, with inference and density estimation schemes using optimal transport, and with alternative transformation-based approaches to simulation. We also sketch current work aimed at the construction of transport maps in high dimensions, exploiting essential features of the target distribution (e.g., conditional independence, low-rank structure). The approaches and algorithms presented here have direct applications to Bayesian computation and to broader problems of stochastic simulation.},
  language = {en},
  booktitle = {Handbook of {{Uncertainty Quantification}}},
  publisher = {{Springer International Publishing}},
  author = {Marzouk, Youssef and Moselhy, Tarek and Parno, Matthew and Spantini, Alessio},
  editor = {Ghanem, Roger and Higdon, David and Owhadi, Houman},
  year = {2016},
  keywords = {Optimal transport,Approximate Bayesian computation,Bayesian inference,Convex optimization,Density estimation,Knothe–Rosenblatt map,Measure transport,Monte Carlo methods},
  pages = {1-41},
  file = {/Users/xiefangzhou/Zotero/storage/NR5ZQE9B/Marzouk et al. - 2016 - Sampling via Measure Transport An Introduction.pdf}
}

@article{marzouk2016a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.05023},
  primaryClass = {math, stat},
  title = {An Introduction to Sampling via Measure Transport},
  abstract = {We present the fundamentals of a measure transport approach to sampling. The idea is to construct a deterministic coupling---i.e., a transport map---between a complex "target" probability measure of interest and a simpler reference measure. Given a transport map, one can generate arbitrarily many independent and unweighted samples from the target simply by pushing forward reference samples through the map. We consider two different and complementary scenarios: first, when only evaluations of the unnormalized target density are available, and second, when the target distribution is known only through a finite collection of samples. We show that in both settings the desired transports can be characterized as the solutions of variational problems. We then address practical issues associated with the optimization--based construction of transports: choosing finite-dimensional parameterizations of the map, enforcing monotonicity, quantifying the error of approximate transports, and refining approximate transports by enriching the corresponding approximation spaces. Approximate transports can also be used to "Gaussianize" complex distributions and thus precondition conventional asymptotically exact sampling schemes. We place the measure transport approach in broader context, describing connections with other optimization--based samplers, with inference and density estimation schemes using optimal transport, and with alternative transformation--based approaches to simulation. We also sketch current work aimed at the construction of transport maps in high dimensions, exploiting essential features of the target distribution (e.g., conditional independence, low-rank structure). The approaches and algorithms presented here have direct applications to Bayesian computation and to broader problems of stochastic simulation.},
  journal = {arXiv:1602.05023 [math, stat]},
  author = {Marzouk, Youssef and Moselhy, Tarek and Parno, Matthew and Spantini, Alessio},
  year = {2016},
  keywords = {Mathematics - Probability,Statistics - Computation,Statistics - Methodology},
  pages = {1-41},
  file = {/Users/xiefangzhou/Zotero/storage/8SEGJ9ES/Marzouk et al. - 2016 - An introduction to sampling via measure transport.pdf;/Users/xiefangzhou/Zotero/storage/PJRHLSH4/1602.html}
}

@article{verma2000,
  title = {An Introduction to Automatic Differentiation},
  volume = {78},
  issn = {0011-3891},
  abstract = {[Differentiation is one of the fundamental problems in numerical mathematics. The solution of many optimization problems and other applications require knowledge of the gradient, the Jacobian matrix, or the Hessian matrix of a given function. Automatic differentiation (AD) can compute fast and accurate derivatives of any degree computationally via propagating Taylor series coefficients using the chain rule. AD does not incur any truncation error and would yield exact results if the calculations were done in real arithmetic; in other words the derivatives obtained are accurate to machine precision. In this tutorial we uncover the details of the AD technology, presenting them in a simple manner. We present basics of AD and its complexity followed by some examples.]},
  number = {7},
  journal = {Current Science},
  author = {Verma, Arun},
  year = {2000},
  pages = {804-807},
  file = {/Users/xiefangzhou/Zotero/storage/G7UUWMS3/Verma - 2000 - An introduction to automatic differentiation.pdf}
}

@article{reich2013,
  title = {A {{Nonparametric Ensemble Transform Method}} for {{Bayesian Inference}}},
  volume = {35},
  issn = {1064-8275},
  abstract = {Many applications, such as intermittent data assimilation, lead to a  recursive application of Bayesian inference within a Monte Carlo context. Popular data assimilation algorithms include sequential Monte Carlo methods and ensemble Kalman filters (EnKFs). These methods differ in the way Bayesian inference is implemented. Sequential Monte Carlo methods rely on importance sampling combined with a resampling step, while EnKFs utilize a linear transformation of Monte Carlo samples based on the classic Kalman filter. While EnKFs have proven to be quite robust even for small ensemble sizes, they are not consistent since their derivation relies on a linear regression ansatz.  In this paper, we propose another transform method, which  does not rely on any a priori assumptions on the underlying prior and posterior distributions. The new method is based on solving an optimal transportation problem for discrete random variables.},
  number = {4},
  journal = {SIAM Journal on Scientific Computing},
  author = {Reich, S.},
  year = {2013},
  pages = {A2013-A2024},
  file = {/Users/xiefangzhou/Zotero/storage/EVRFHY7V/Reich - 2013 - A Nonparametric Ensemble Transform Method for Baye.pdf;/Users/xiefangzhou/Zotero/storage/VHW8MN6E/130907367.html}
}

@article{dolinsky2014,
  title = {Martingale Optimal Transport and Robust Hedging in Continuous Time},
  volume = {160},
  issn = {1432-2064},
  abstract = {The duality between the robust (or equivalently, model independent) hedging of path dependent European options and a martingale optimal transport problem is proved. The financial market is modeled through a risky asset whose price is only assumed to be a continuous function of time. The hedging problem is to construct a minimal super-hedging portfolio that consists of dynamically trading the underlying risky asset and a static position of vanilla options which can be exercised at the given, fixed maturity. The dual is a Monge\textendash{}Kantorovich type martingale transport problem of maximizing the expected value of the option over all martingale measures that have a given marginal at maturity. In addition to duality, a family of simple, piecewise constant super-replication portfolios that asymptotically achieve the minimal super-replication cost is constructed.},
  language = {en},
  number = {1},
  journal = {Probability Theory and Related Fields},
  author = {Dolinsky, Yan and Soner, H. Mete},
  year = {2014},
  keywords = {Optimal transport,60G44,91G10,European options,Min–max theorems,Prokhorov metric,Robust hedging},
  pages = {391-427},
  file = {/Users/xiefangzhou/Zotero/storage/QHHD55JW/Dolinsky and Soner - 2014 - Martingale optimal transport and robust hedging in.pdf}
}

@article{galichon2014,
  title = {A Stochastic Control Approach to No-Arbitrage Bounds given Marginals, with an Application to Lookback Options},
  volume = {24},
  issn = {1050-5164, 2168-8737},
  abstract = {We consider the problem of superhedging under volatility uncertainty for an investor allowed to dynamically trade the underlying asset, and statically trade European call options for all possible strikes with some given maturity. This problem is classically approached by means of the Skorohod Embedding Problem (SEP). Instead, we provide a dual formulation which converts the superhedging problem into a continuous martingale optimal transportation problem. We then show that this formulation allows us to recover previously known results about lookback options. In particular, our methodology induces a new proof of the optimality of Az{\'e}ma\textendash{}Yor solution of the SEP for a certain class of lookback options. Unlike the SEP technique, our approach applies to a large class of exotics and is suitable for numerical approximation techniques.},
  language = {EN},
  number = {1},
  journal = {The Annals of Applied Probability},
  author = {Galichon, A. and {Henry-Labord{\`e}re}, P. and Touzi, N.},
  year = {2014},
  keywords = {convex duality,Optimal control,volatility uncertainty},
  pages = {312-336},
  file = {/Users/xiefangzhou/Zotero/storage/X3TJH99N/Galichon et al. - 2014 - A stochastic control approach to no-arbitrage boun.pdf;/Users/xiefangzhou/Zotero/storage/HKRBB785/1389278727.html}
}

@article{hoffman2014,
  title = {The {{No}}-{{U}}-{{Turn Sampler}}: {{Adaptively Setting Path Lengths}} in {{Hamiltonian Monte Carlo}}},
  volume = {15},
  journal = {Journal of Machine Learning Research},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  year = {2014},
  pages = {1593-1623},
  file = {/Users/xiefangzhou/Zotero/storage/X8ULINB6/Hoffman and Gelman - 2014 - The No-U-Turn Sampler Adaptively Setting Path Len.pdf}
}

@article{benamou2015,
  title = {Iterative {{Bregman Projections}} for {{Regularized Transportation Problems}}},
  volume = {37},
  issn = {1064-8275},
  abstract = {This paper details a general numerical framework to approximate solutions to linear programs related to optimal transport. The general idea is to introduce an entropic regularization of the initial linear program. This regularized problem corresponds to a  Kullback--Leibler Bregman divergence projection of a vector (representing some initial joint distribution) on the polytope of constraints. We show that for many problems related to optimal transport, the set of linear constraints can be split in an intersection of a few simple constraints, for which the projections can be computed in closed form. This allows us to make use of iterative Bregman projections (when there are only equality constraints) or, more generally, Bregman--Dykstra iterations (when  inequality constraints are involved). We illustrate the usefulness of this approach for several variational problems related to optimal transport: barycenters for the optimal transport metric, tomographic reconstruction, multimarginal optimal transport, and in particular its application to Brenier's relaxed solutions of incompressible Euler equations, partial unbalanced optimal transport, and optimal transport with capacity constraints.},
  number = {2},
  journal = {SIAM Journal on Scientific Computing},
  author = {Benamou, J. and Carlier, G. and Cuturi, M. and Nenna, L. and Peyr{\'e}, G.},
  year = {2015},
  pages = {A1111-A1138},
  file = {/Users/xiefangzhou/Zotero/storage/EHZRHEZ3/Benamou et al. - 2015 - Iterative Bregman Projections for Regularized Tran.pdf;/Users/xiefangzhou/Zotero/storage/UM5MBZPZ/141000439.html}
}

@inproceedings{le2014,
  title = {Distributed {{Representations}} of {{Sentences}} and {{Documents}}},
  abstract = {Many machine learning algorithms require the  input to be represented as a fixed length feature  vector. When it comes to texts, one of the most  common representations is bag-of-words. Despite the...},
  language = {en},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Le, Quoc and Mikolov, Tomas},
  year = {2014},
  pages = {1188-1196},
  file = {/Users/xiefangzhou/Zotero/storage/WZVJ5JNM/Le and Mikolov - 2014 - Distributed Representations of Sentences and Docum.pdf;/Users/xiefangzhou/Zotero/storage/AX9W6256/le14.html}
}

@inproceedings{alvarez-melis2018,
  title = {Structured {{Optimal Transport}}},
  abstract = {Optimal Transport has recently gained interest in machine learning for applications ranging from domain adaptation to sentence similarities or deep learning. Yet, its ability to capture frequently ...},
  language = {en},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {{Alvarez-Melis}, David and Jaakkola, Tommi and Jegelka, Stefanie},
  year = {2018},
  pages = {1771-1780},
  file = {/Users/xiefangzhou/Zotero/storage/79RVJLQB/Alvarez-Melis et al. - 2018 - Structured Optimal Transport.pdf;/Users/xiefangzhou/Zotero/storage/F6LE9I75/alvarez-melis18a.html}
}

@inproceedings{ahmed2010,
  address = {{Arlington, Virginia, United States}},
  series = {{{UAI}}'10},
  title = {Timeline: {{A Dynamic Hierarchical Dirichlet Process Model}} for {{Recovering Birth}}/{{Death}} and {{Evolution}} of {{Topics}} in {{Text Stream}}},
  isbn = {978-0-9749039-6-5},
  shorttitle = {Timeline},
  abstract = {Topic models have proven to be a useful tool for discovering latent structures in document collections. However, most document collections often come as temporal streams and thus several aspects of the latent structure such as the number of topics, the topics' distribution and popularity are time-evolving. Several models exist that model the evolution of some but not all of the above aspects. In this paper we introduce infinite dynamic topic models, iDTM, that can accommodate the evolution of all the aforementioned aspects. Our model assumes that documents are organized into epochs, where the documents within each epoch are exchangeable but the order between the documents is maintained across epochs. iDTM allows for unbounded number of topics: topics can die or be born at any epoch, and the representation of each topic can evolve according to a Markovian dynamics. We use iDTM to analyze the birth and evolution of topics in the NIPS community and evaluated the efficacy of our model on both simulated and real datasets with favorable outcome.},
  booktitle = {Proceedings of the {{Twenty}}-{{Sixth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  publisher = {{AUAI Press}},
  author = {Ahmed, Amr and Xing, Eric P.},
  year = {2010},
  pages = {20--29},
  file = {/Users/xiefangzhou/Zotero/storage/MMUH3NX7/Ahmed and Xing - 2012 - Timeline A Dynamic Hierarchical Dirichlet Process.pdf}
}

@inproceedings{seroussi2011,
  address = {{Stroudsburg, PA, USA}},
  series = {{{CoNLL}} '11},
  title = {Authorship {{Attribution}} with {{Latent Dirichlet Allocation}}},
  isbn = {978-1-932432-92-3},
  abstract = {The problem of authorship attribution -- attributing texts to their original authors -- has been an active research area since the end of the 19th century, attracting increased interest in the last decade. Most of the work on authorship attribution focuses on scenarios with only a few candidate authors, but recently considered cases with tens to thousands of candidate authors were found to be much more challenging. In this paper, we propose ways of employing Latent Dirichlet Allocation in authorship attribution. We show that our approach yields state-of-the-art performance for both a few and many candidate authors, in cases where these authors wrote enough texts to be modelled effectively.},
  booktitle = {Proceedings of the {{Fifteenth Conference}} on {{Computational Natural Language Learning}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Seroussi, Yanir and Zukerman, Ingrid and Bohnert, Fabian},
  year = {2011},
  pages = {181--189},
  file = {/Users/xiefangzhou/Zotero/storage/UTD8JKFH/Seroussi et al. - 2011 - Authorship Attribution with Latent Dirichlet Alloc.pdf}
}

@article{andrieu2003,
  title = {An {{Introduction}} to {{MCMC}} for {{Machine Learning}}},
  volume = {50},
  issn = {1573-0565},
  abstract = {This purpose of this introductory paper is threefold. First, it introduces the Monte Carlo method with emphasis on probabilistic machine learning. Second, it reviews the main building blocks of modern Markov chain Monte Carlo simulation, thereby providing and introduction to the remaining papers of this special issue. Lastly, it discusses new interesting research horizons.},
  language = {en},
  number = {1},
  journal = {Machine Learning},
  author = {Andrieu, Christophe and {de Freitas}, Nando and Doucet, Arnaud and Jordan, Michael I.},
  year = {2003},
  keywords = {Markov chain Monte Carlo,MCMC,sampling,stochastic algorithms},
  pages = {5-43},
  file = {/Users/xiefangzhou/Zotero/storage/HISMUQNN/Andrieu et al. - 2003 - An Introduction to MCMC for Machine Learning.pdf}
}

@article{wang2019,
  title = {Convergence Rates of Latent Topic Models under Relaxed Identifiability Conditions},
  volume = {13},
  issn = {1935-7524},
  abstract = {In this paper we study the frequentist convergence rate for the Latent Dirichlet Allocation (Blei, Ng and Jordan, 2003) topic models. We show that the maximum likelihood estimator converges to one of the finitely many equivalent parameters in Wasserstein's distance metric at a rate of n-1/4n-1/4n\^\{-1/4\} without assuming separability or non-degeneracy of the underlying topics and/or the existence of more than three words per document, thus generalizing the previous works of Anandkumar et al. (2012, 2014) from an information-theoretical perspective. We also show that the n-1/4n-1/4n\^\{-1/4\} convergence rate is optimal in the worst case.},
  language = {EN},
  number = {1},
  journal = {Electronic Journal of Statistics},
  author = {Wang, Yining},
  year = {2019},
  keywords = {Latent Dirichlet Allocation,maximum likelihood,rates of convergence,topic models},
  pages = {37-66},
  file = {/Users/xiefangzhou/Zotero/storage/TJDSYQN5/Wang - 2019 - Convergence rates of latent topic models under rel.pdf;/Users/xiefangzhou/Zotero/storage/F4HJI2QQ/1546570941.html}
}

@inproceedings{kusner2015,
  series = {{{ICML}}'15},
  title = {From {{Word Embeddings}} to {{Document Distances}}},
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.},
  booktitle = {Proceedings of the {{32Nd International Conference}} on {{International Conference}} on {{Machine Learning}} - {{Volume}} 37},
  publisher = {{JMLR.org}},
  author = {Kusner, Matt J. and Sun, Yu and Kolkin, Nicholas I. and Weinberger, Kilian Q.},
  year = {2015},
  pages = {957--966},
  file = {/Users/xiefangzhou/Zotero/storage/XJTSILRA/Kusner et al. - From Word Embeddings To Document Distances.pdf}
}

@inproceedings{rolet2016,
  title = {Fast {{Dictionary Learning}} with a {{Smoothed Wasserstein Loss}}},
  abstract = {We consider in this paper the dictionary learning problem when the observations are normalized histograms of features. This problem can be tackled using non-negative matrix factorization approaches...},
  language = {en},
  booktitle = {Artificial {{Intelligence}} and {{Statistics}}},
  author = {Rolet, Antoine and Cuturi, Marco and Peyr{\'e}, Gabriel},
  year = {2016},
  pages = {630-638},
  file = {/Users/xiefangzhou/Zotero/storage/LEFTCHZI/Rolet et al. - 2016 - Fast Dictionary Learning with a Smoothed Wasserste.pdf;/Users/xiefangzhou/Zotero/storage/ZBUGVXI2/rolet16.html}
}

@inproceedings{wang2008,
  address = {{Arlington, Virginia, United States}},
  series = {{{UAI}}'08},
  title = {Continuous {{Time Dynamic Topic Models}}},
  isbn = {978-0-9749039-4-1},
  abstract = {In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a "topic" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.},
  booktitle = {Proceedings of the {{Twenty}}-{{Fourth Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  publisher = {{AUAI Press}},
  author = {Wang, Chong and Blei, David and Heckerman, David},
  year = {2008},
  pages = {579--586},
  file = {/Users/xiefangzhou/Zotero/storage/DE6I869N/Wang et al. - 2012 - Continuous Time Dynamic Topic Models.pdf}
}

@article{dognin2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1902.04999},
  primaryClass = {cs, stat},
  title = {Wasserstein {{Barycenter Model Ensembling}}},
  abstract = {In this paper we propose to perform model ensembling in a multiclass or a multilabel learning setting using Wasserstein (W.) barycenters. Optimal transport metrics, such as the Wasserstein distance, allow incorporating semantic side information such as word embeddings. Using W. barycenters to find the consensus between models allows us to balance confidence and semantics in finding the agreement between the models. We show applications of Wasserstein ensembling in attribute-based classification, multilabel learning and image captioning generation. These results show that the W. ensembling is a viable alternative to the basic geometric or arithmetic mean ensembling.},
  journal = {arXiv:1902.04999 [cs, stat]},
  author = {Dognin, Pierre and Melnyk, Igor and Mroueh, Youssef and Ross, Jerret and Santos, Cicero Dos and Sercu, Tom},
  year = {2019},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/6A249LFK/Dognin et al. - 2019 - Wasserstein Barycenter Model Ensembling.pdf;/Users/xiefangzhou/Zotero/storage/IFYSB4D4/1902.html}
}

@article{parno2018,
  title = {Transport {{Map Accelerated Markov Chain Monte Carlo}}},
  volume = {6},
  abstract = {We introduce a new framework for efficient sampling from complex probability distributions, using a combination of transport maps and the Metropolis--Hastings rule. The core idea is to use deterministic couplings to transform typical Metropolis proposal mechanisms (e.g., random walks, Langevin methods) into non-Gaussian proposal distributions that can more effectively explore the target density. Our approach adaptively constructs a lower triangular transport map---an approximation of the Knothe--Rosenblatt rearrangement---using information from previous Markov chain Monte Carlo (MCMC) states, via the solution of an optimization problem. This optimization problem is convex regardless of the form of the target distribution and can be solved efficiently without gradient information from the target probability distribution; the target distribution is instead represented via samples. Sequential updates enable efficient and parallelizable adaptation of the map even for large numbers of samples. We show that this approach uses inexact or truncated maps to produce an adaptive MCMC algorithm that is ergodic for the exact target distribution. Numerical demonstrations on a range of parameter inference problems show order-of-magnitude speedups over standard MCMC techniques, measured by the number of effectively independent samples produced per target density evaluation and per unit of wallclock time.},
  number = {2},
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  author = {Parno, M. and Marzouk, Y.},
  year = {2018},
  pages = {645-682},
  file = {/Users/xiefangzhou/Zotero/storage/WSBD53Q2/Parno and Marzouk - 2018 - Transport Map Accelerated Markov Chain Monte Carlo.pdf;/Users/xiefangzhou/Zotero/storage/TZUHE53F/17M1134640.html}
}

@book{villani2003,
  title = {Topics in {{Optimal Transportation}}},
  isbn = {978-0-8218-3312-4},
  abstract = {Cedric Villani's book is a lucid and very readable documentation of the tremendous recent analytic progress in ``optimal mass transportation'' theory and of its diverse and unexpected applications in optimization, nonlinear PDE, geometry, and mathematical physics. --Lawrence C. Evans, University of California at Berkeley In 1781, Gaspard Monge defined the problem of ``optimal transportation'', or the transferring of mass with the least possible amount of work, with applications to engineering in mind. In 1942, Leonid Kantorovich applied the newborn machinery of linear programming to Monge's problem, with applications to economics in mind. In 1987, Yann Brenier used optimal transportation to prove a new projection theorem on the set of measure preserving maps, with applications to fluid mechanics in mind. Each of these contributions marked the beginning of a whole mathematical theory, with many unexpected ramifications. Nowadays, the Monge-Kantorovich problem is used and studied by researchers from extremely diverse horizons, including probability theory, functional analysis, isoperimetry, partial differential equations, and even meteorology. Originating from a graduate course, the present volume is at once an introduction to the field of optimal transportation and a survey of the research on the topic over the last 15 years. The book is intended for graduate students and researchers, and it covers both theory and applications. Readers are only assumed to be familiar with the basics of measure theory and functional analysis.},
  language = {en},
  publisher = {{American Mathematical Soc.}},
  author = {Villani, C{\'e}dric},
  year = {2003},
  keywords = {Mathematics / General}
}

@book{villani2008,
  title = {Optimal {{Transport}}: {{Old}} and {{New}}},
  isbn = {978-3-540-71050-9},
  shorttitle = {Optimal {{Transport}}},
  abstract = {At the close of the 1980s, the independent contributions of Yann Brenier, Mike Cullen and John Mather launched a revolution in the venerable field of optimal transport founded by G. Monge in the 18th century, which has made breathtaking forays into various other domains of mathematics ever since. The author presents a broad overview of this area, supplying complete and self-contained proofs of all the fundamental results of the theory of optimal transport at the appropriate level of generality. Thus, the book encompasses the broad spectrum ranging from basic theory to the most recent research results.   PhD students or researchers can read the entire book without any prior knowledge of the field. A comprehensive bibliography with notes that extensively discuss the existing literature underlines the book's value as a most welcome reference text on this subject.},
  language = {en},
  publisher = {{Springer Science \& Business Media}},
  author = {Villani, C{\'e}dric},
  year = {2008},
  keywords = {Mathematics / Calculus,Mathematics / Differential Equations / General,Mathematics / Functional Analysis,Mathematics / Geometry / Differential,Mathematics / Mathematical Analysis},
  file = {/Users/xiefangzhou/Zotero/storage/YQGYNDAU/Villani - 2008 - Optimal Transport Old and New.pdf}
}

@book{galichon2016,
  title = {Optimal {{Transport Methods}} in {{Economics}}},
  isbn = {978-1-4008-8359-2},
  abstract = {Optimal Transport Methods in Economics is the first textbook on the subject written especially for students and researchers in economics. Optimal transport theory is used widely to solve problems in mathematics and some areas of the sciences, but it can also be used to understand a range of problems in applied economics, such as the matching between job seekers and jobs, the determinants of real estate prices, and the formation of matrimonial unions. This is the first text to develop clear applications of optimal transport to economic modeling, statistics, and econometrics. It covers the basic results of the theory as well as their relations to linear programming, network flow problems, convex analysis, and computational geometry. Emphasizing computational methods, it also includes programming examples that provide details on implementation. Applications include discrete choice models, models of differential demand, and quantile-based statistical estimation methods, as well as asset pricing models.Authoritative and accessible, Optimal Transport Methods in Economics also features numerous exercises throughout that help you develop your mathematical agility, deepen your computational skills, and strengthen your economic intuition.The first introduction to the subject written especially for economistsIncludes programming examplesFeatures numerous exercises throughoutIdeal for students and researchers alike},
  language = {en},
  publisher = {{Princeton University Press}},
  author = {Galichon, Alfred},
  year = {2016},
  keywords = {Business \& Economics / Economics / Theory,Business \& Economics / Econometrics,Business \& Economics / Statistics,Business \& Economics / Economics / Microeconomics,Mathematics / Applied},
  file = {/Users/xiefangzhou/Zotero/storage/T9JUGK85/Galichon - 2016 - Optimal Transport Methods in Economics.pdf}
}

@article{ekeland2010,
  title = {Notes on Optimal Transportation},
  volume = {42},
  issn = {1432-0479},
  abstract = {These are introductory lectures to the mathematical theory of optimal transportation, and its connections with the economic theory of incentives.},
  language = {en},
  number = {2},
  journal = {Economic Theory},
  author = {Ekeland, Ivar},
  year = {2010},
  keywords = {C61,Adverse selection,C65,C78,Contract theory,Convex analysis,D82,Optimal transportation},
  pages = {437-459},
  file = {/Users/xiefangzhou/Zotero/storage/SAZQM5CJ/Ekeland - 2010 - Notes on optimal transportation.pdf}
}

@book{santambrogio2015,
  title = {Optimal {{Transport}} for {{Applied Mathematicians}}: {{Calculus}} of {{Variations}}, {{PDEs}}, and {{Modeling}}},
  isbn = {978-3-319-20828-2},
  shorttitle = {Optimal {{Transport}} for {{Applied Mathematicians}}},
  abstract = {This monograph presents a rigorous mathematical introduction to optimal transport as a variational problem, its use in modeling various phenomena, and its connections with partial differential equations. Its main goal is to provide the reader with the techniques necessary to understand the current research in optimal transport and the tools which are most useful for its applications. Full proofs are used to illustrate mathematical concepts and each chapter includes a section that discusses applications of optimal transport to various areas, such as economics, finance, potential games, image processing and fluid dynamics. Several topics are covered that have never been previously in books on this subject, such as the Knothe transport, the properties of functionals on measures, the Dacorogna-Moser flow, the formulation through minimal flows with prescribed divergence formulation, the case of the supremal cost, and the most classical numerical methods. Graduate students and researchers in both pure and applied mathematics interested in the problems and applications of optimal transport will find this to be an invaluable resource.},
  language = {en},
  publisher = {{Birkh{\"a}user}},
  author = {Santambrogio, Filippo},
  year = {2015},
  keywords = {Mathematics / General,Mathematics / Calculus,Mathematics / Differential Equations / General,Mathematics / Functional Analysis,Mathematics / Mathematical Analysis},
  file = {/Users/xiefangzhou/Zotero/storage/57VX4AEN/Santambrogio - 2015 - Optimal Transport for Applied Mathematicians Calc.pdf}
}

@inproceedings{rubner1998,
  title = {A Metric for Distributions with Applications to Image Databases},
  abstract = {We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving "distribution mass" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search.},
  booktitle = {Sixth {{International Conference}} on {{Computer Vision}} ({{IEEE Cat}}. {{No}}.{{98CH36271}})},
  author = {Rubner, Y. and Tomasi, C. and Guibas, L. J.},
  year = {1998},
  keywords = {Application software,color,Computer displays,Computer science,distributions,easy-to-compute lower bounds,Frequency,Geoscience,Histograms,image colour analysis,image databases,Image databases,Image retrieval,image texture,linear optimization,multi-dimensional scaling displays,Navigation,partial matching,Psychology,texture,transportation problem,visual databases},
  pages = {59-66},
  file = {/Users/xiefangzhou/Zotero/storage/HXLSINP8/Rubner et al. - 1998 - A metric for distributions with applications to im.pdf;/Users/xiefangzhou/Zotero/storage/XYB4IHSU/710701.html}
}

@article{pass2015,
  title = {Multi-Marginal Optimal Transport: {{Theory}} and Applications},
  volume = {49},
  copyright = {\textcopyright{} EDP Sciences, SMAI 2015},
  issn = {0764-583X, 1290-3841},
  shorttitle = {Multi-Marginal Optimal Transport},
  abstract = {Over the past five years, multi-marginal optimal transport, a generalization of the well known optimal transport problem of Monge and Kantorovich, has begun to attract considerable attention, due in part to a wide variety of emerging applications. Here, we survey this problem, addressing fundamental theoretical questions including the uniqueness and structure of solutions. The answers to these questions uncover a surprising divergence from the classical two marginal setting, and reflect a delicate dependence on the cost function, which we then illustrate with a series of examples. We go on to describe some applications of the multi-marginal optimal transport problem, focusing primarily on matching in economics and density functional theory in physics.},
  language = {en},
  number = {6},
  journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
  author = {Pass, Brendan},
  year = {2015},
  pages = {1771-1790},
  file = {/Users/xiefangzhou/Zotero/storage/UZGMKTVM/Pass - 2015 - Multi-marginal optimal transport Theory and appli.pdf;/Users/xiefangzhou/Zotero/storage/IL8EVFWD/m2an150042.html}
}

@incollection{steyvers2007,
  address = {{Mahwah, NJ, US}},
  title = {Probabilistic Topic Models},
  isbn = {978-0-8058-5418-3 978-1-4106-1534-3},
  abstract = {Many chapters in this book illustrate that applying a statistical method such as latent semantic analysis (LSA; Landauer \& Dumais, 1997; Landauer, Foltz, \& Laham, 1998) to large databases can yield insight into human cognition. The LSA approach makes three claims: that semantic information can be derived from a word-document co-occurrence matrix; that dimensionality reduction is an essential part of this derivation; and that words and documents can be represented as points in Euclidean space. This chapter pursues an approach that is consistent with the first two of these claims, but differs in the third, describing a class of statistical models in which the semantic properties of words and documents are expressed in terms of probabilistic topics. The plan of this chapter is as follows. First, it describes the key ideas behind topic models in more detail and outlines how it is possible to identify the topics that appear in a set of documents. It then discusses methods for answering two kinds of questions about similarities: assessing the similarity between two documents and assessing the associative similarity between two words. It closes by considering how generative models have the potential to provide further insight into human cognition. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  booktitle = {Handbook of Latent Semantic Analysis},
  publisher = {{Lawrence Erlbaum Associates Publishers}},
  author = {Steyvers, Mark and Griffiths, Tom},
  year = {2007},
  keywords = {Analysis,Cognition,Models,Semantics,Statistical Probability},
  pages = {427-448},
  file = {/Users/xiefangzhou/Zotero/storage/RRFCJ85M/Steyvers and Griffiths - Probabilistic Topic Models.pdf;/Users/xiefangzhou/Zotero/storage/KFT6T45G/2007-04818-021.html}
}

@inproceedings{abadi2016,
  title = {{{TensorFlow}}: {{A}} System for Large-Scale Machine Learning},
  shorttitle = {{{TensorFlow}}},
  booktitle = {12th {{USENIX Symposium}} on {{Operating Systems Design}} and {{Implementation}} ({{OSDI}} 16)},
  author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  year = {2016},
  pages = {265--283},
  file = {/Users/xiefangzhou/Zotero/storage/WWRJX9AQ/Abadi et al. - 2016 - TensorFlow A system for large-scale machine learn.pdf}
}

@article{aruoba2016,
  series = {Innovations in {{Measurement}} in {{Economics}} and {{Econometrics}}},
  title = {Improving {{GDP}} Measurement: {{A}} Measurement-Error Perspective},
  volume = {191},
  issn = {0304-4076},
  shorttitle = {Improving {{GDP}} Measurement},
  abstract = {We provide a new measure of historical U.S. GDP growth, obtained by applying optimal signal-extraction techniques to the noisy expenditure-side and income-side GDP estimates. The quarter-by-quarter values of our new measure often differ noticeably from those of the traditional measures. Its dynamic properties differ as well, indicating that the persistence of aggregate output dynamics is stronger than previously thought.},
  number = {2},
  journal = {Journal of Econometrics},
  author = {Aruoba, S. Bora{\u g}an and Diebold, Francis X. and Nalewaik, Jeremy and Schorfheide, Frank and Song, Dongho},
  year = {2016},
  keywords = {Forecast combination,Business cycle,Contraction,Dynamic factor model,Expansion,Expenditure,Income,Output,Recession,State-space model,Turning point},
  pages = {384-397},
  file = {/Users/xiefangzhou/Zotero/storage/D7CLR9DA/Aruoba et al. - 2016 - Improving GDP measurement A measurement-error per.pdf;/Users/xiefangzhou/Zotero/storage/JJFX7PFU/S0304407615002857.html}
}

@incollection{aruoba2013,
  address = {{New York, NY}},
  title = {Improving {{U}}.{{S}}. {{GDP Measurement}}: {{A Forecast Combination Perspective}}},
  isbn = {978-1-4614-1653-1},
  shorttitle = {Improving {{U}}.{{S}}. {{GDP Measurement}}},
  abstract = {Two often-divergent U.S. GDP estimates are available, a widely-used expenditure-side version GDP{$\mathsl{E}$}E\_E, and a much less widely-used income-side version GDP{$\mathsl{I}$}I\_I. We propose and explore a ``forecast combination'' approach to combining them. We then put the theory to work, producing a superior combined estimate of GDP growth for the U.S., GDP{$\mathsl{C}$}C\_C. We compare GDP{$\mathsl{C}$}C\_C to GDP{$\mathsl{E}$}E\_E and GDP{$\mathsl{I}$}I\_I, with particular attention to behavior over the business cycle. We discuss several variations and extensions.},
  language = {en},
  booktitle = {Recent {{Advances}} and {{Future Directions}} in {{Causality}}, {{Prediction}}, and {{Specification Analysis}}: {{Essays}} in {{Honor}} of {{Halbert L}}. {{White Jr}}},
  publisher = {{Springer New York}},
  author = {Aruoba, S. Bora{\u g}an and Diebold, Francis X. and Nalewaik, Jeremy and Schorfheide, Frank and Song, Dongho},
  editor = {Chen, Xiaohong and Swanson, Norman R.},
  year = {2013},
  keywords = {Combine Estimate,Forecast Error,Forecast Error Variance,Posterior Median,Quadratic Loss},
  pages = {1-25},
  file = {/Users/xiefangzhou/Zotero/storage/7FVTUQ5C/Aruoba et al. - 2013 - Improving U.S. GDP Measurement A Forecast Combina.pdf}
}

@article{monnahan2017,
  title = {Faster Estimation of {{Bayesian}} Models in Ecology Using {{Hamiltonian Monte Carlo}}},
  volume = {8},
  copyright = {\textcopyright{} 2016 The Authors. Methods in Ecology and Evolution \textcopyright{} 2016 British Ecological Society},
  issn = {2041-210X},
  abstract = {Bayesian inference is a powerful tool to better understand ecological processes across varied subfields in ecology, and is often implemented in generic and flexible software packages such as the widely used BUGS family (BUGS, WinBUGS, OpenBUGS and JAGS). However, some models have prohibitively long run times when implemented in BUGS. A relatively new software platform called Stan uses Hamiltonian Monte Carlo (HMC), a family of Markov chain Monte Carlo (MCMC) algorithms which promise improved efficiency and faster inference relative to those used by BUGS. Stan is gaining traction in many fields as an alternative to BUGS, but adoption has been slow in ecology, likely due in part to the complex nature of HMC. Here, we provide an intuitive illustration of the principles of HMC on a set of simple models. We then compared the relative efficiency of BUGS and Stan using population ecology models that vary in size and complexity. For hierarchical models, we also investigated the effect of an alternative parameterization of random effects, known as non-centering. For small, simple models there is little practical difference between the two platforms, but Stan outperforms BUGS as model size and complexity grows. Stan also performs well for hierarchical models, but is more sensitive to model parameterization than BUGS. Stan may also be more robust to biased inference caused by pathologies, because it produces diagnostic warnings where BUGS provides none. Disadvantages of Stan include an inability to use discrete parameters, more complex diagnostics and a greater requirement for hands-on tuning. Given these results, Stan is a valuable tool for many ecologists utilizing Bayesian inference, particularly for problems where BUGS is prohibitively slow. As such, Stan can extend the boundaries of feasible models for applied problems, leading to better understanding of ecological processes. Fields that would likely benefit include estimation of individual and population growth rates, meta-analyses and cross-system comparisons and spatiotemporal models.},
  language = {en},
  number = {3},
  journal = {Methods in Ecology and Evolution},
  author = {Monnahan, Cole C. and Thorson, James T. and Branch, Trevor A.},
  year = {2017},
  keywords = {Bayesian inference,Markov chain Monte Carlo,hierarchical modelling,no-U-turn sampler,Stan},
  pages = {339-348},
  file = {/Users/xiefangzhou/Zotero/storage/Q9S4MMGG/Monnahan et al. - 2017 - Faster estimation of Bayesian models in ecology us.pdf;/Users/xiefangzhou/Zotero/storage/8IPB69X5/2041-210X.html}
}

@article{jenkins2011,
  title = {The {{Measurement}} of {{Economic Inequality}}},
  abstract = {This article provides an introduction to methods for the measurement of economic inequality. It reviews the inequality measures that economists have developed, and explains how one might choose between indices or check whether conclusions about inequality difference can be derived without choosing any specific index. It reviews mobility measurement and some fundamental questions about how the distributions of economic interest are defined.},
  language = {en},
  journal = {The Oxford Handbook of Economic Inequality},
  author = {Jenkins, Stephen P. and Kerm, Philippe Van},
  year = {2011},
  file = {/Users/xiefangzhou/Zotero/storage/Y5MVNY2K/oxfordhb-9780199606061-e-3.html}
}

@book{2011,
  title = {The {{Oxford Handbook}} of {{Economic Inequality}}},
  isbn = {978-0-19-174362-7},
  abstract = {The Oxford Handbook of Economic Inequality presents a challenging analysis of economic inequality, focusing primarily on economic inequality in highly-developed countries. This comprehensive and authoritative volume contains twenty-seven original contributions on topics ranging from gender to happiness, from poverty to top incomes, and from employers to the welfare state. The authors give their view on scientific research in their fields of expertise and add their own visions for future research.},
  language = {en\_US},
  publisher = {{Oxford University Press}},
  year = {2011},
  file = {/Users/xiefangzhou/Zotero/storage/89VWKCRH/oxfordhb-9780199606061.html}
}

@article{shorrocks1982,
  title = {Inequality {{Decomposition}} by {{Factor Components}}},
  volume = {50},
  issn = {0012-9682},
  abstract = {[This paper disaggregates the income of individuals or households into different factor components, such as earnings, investment income, and transfer payments, and considers how to assess the contributions of these sources to total income inequality. In the approach adopted, a number of basic principles of decomposition are proposed and their implications for the assignment of component contributions are examined.]},
  number = {1},
  journal = {Econometrica},
  author = {Shorrocks, A. F.},
  year = {1982},
  pages = {193-211},
  file = {/Users/xiefangzhou/Zotero/storage/GAN8URPN/Shorrocks - 1982 - Inequality Decomposition by Factor Components.pdf}
}

@article{garcia-penalosa2013,
  title = {Factor {{Components}} of {{Inequality}}: {{A Cross}}-{{Country Study}}},
  volume = {59},
  copyright = {\textcopyright{} 2013 International Association for Research in Income and Wealth},
  issn = {1475-4991},
  shorttitle = {Factor {{Components}} of {{Inequality}}},
  abstract = {This paper uses data from the Luxembourg Income Study to examine some of the forces that have driven changes in household income inequality over the last three decades of the twentieth century. We decompose inequality for six countries (Canada, Germany, Norway, Sweden, the U.K., and the U.S.) into the three sources of market income (earnings, property income, and income from self-employment) and taxes and transfers. Our findings indicate that although changes in the distribution of earnings are an important force behind recent trends, they are not the only one. Greater earnings dispersion has in some cases been accompanied by a reduction in the share of earnings which dampened its impact on overall household income inequality. In some countries the contribution of self-employment income to inequality has been on the rise, while in others, increases in inequality in capital income account for a substantial fraction of the observed distributional changes.},
  language = {en},
  number = {4},
  journal = {Review of Income and Wealth},
  author = {Garc{\'i}a-Pe{\~n}alosa, Cecilia and Orgiazzi, Elsa},
  year = {2013},
  keywords = {D31,D33,decomposition by population subgroups,factor decomposition,income inequality},
  pages = {689-727},
  file = {/Users/xiefangzhou/Zotero/storage/5V9ERJH3/García‐Peñalosa and Orgiazzi - 2013 - Factor Components of Inequality A Cross-Country S.pdf;/Users/xiefangzhou/Zotero/storage/AH3IMAQP/roiw.html}
}

@article{goubin2018,
  title = {Is {{Inequality}} a {{Latent Construct}}? {{An Assessment}} of {{Economic Inequality Indicators}} and {{Their Relation}} with {{Social Cohesion}} in {{Europe}}},
  volume = {136},
  issn = {1573-0921},
  shorttitle = {Is {{Inequality}} a {{Latent Construct}}?},
  abstract = {In this article, we analyse the relation between different economic inequality indicators and social cohesion. Previous research usually narrows down economic inequality to income inequality, or distinguishes several types of economic inequality. Little attention has until now been given to how different aspects of economic inequality might be related to each other and can have an effect on social cohesion. This article analyses several indicators of economic inequality and makes a distinction between indicators measuring income inequality, poverty, economic strain and unequal distributions of wealth. Arguing that these indicators represent different aspects of inequality, we hypothesise that they cannot be reduced to one latent concept of inequality and have specific relations with social cohesion. In order to test this hypothesis, we conducted an exploratory factor analysis. This resulted in two different factors: one associated with economic hardship, and one associated with imbalances in market outcomes. This would imply that inequality indicators can be classified into two underlying concepts. Secondly, we related the factor scores of the two latent concepts to the social cohesion indicators via regression analyses. This paper focuses on European countries and uses pooled data from the European Social Survey (period 2006\textendash{}2012), in combination with macro-level data drawn from the OECD, Eurostat and the World Bank. The results demonstrate that the strength of the link between inequality and citizens' attitudes depends on the type of inequality indicator we analyse: only the factor economic deprivation can be significantly linked to social cohesion.},
  language = {en},
  number = {1},
  journal = {Social Indicators Research},
  author = {Goubin, Silke},
  year = {2018},
  keywords = {Economic inequality,Factor analysis,Social cohesion},
  pages = {21-40},
  file = {/Users/xiefangzhou/Zotero/storage/2DBNDKSU/Goubin - 2018 - Is Inequality a Latent Construct An Assessment of.pdf}
}

@article{chetty2017,
  title = {The Fading {{American}} Dream: {{Trends}} in Absolute Income Mobility since 1940},
  volume = {356},
  copyright = {Copyright \textcopyright{} 2017, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  shorttitle = {The Fading {{American}} Dream},
  abstract = {Aspiring to do better than one's parents
The American dream promises that hard work and opportunity will lead to a better life. Although the specifics of what constitutes a better life vary from generation to generation, one constant is that children expect to do better\textemdash{}or at least to have a good chance at doing better\textemdash{}than their parents. Chetty et al. show that this dream did come true for children born in the middle of the 20th century, but only for half of children born in 1984 (see the Policy Forum by Katz and Krueger). A more even distribution of economic growth, rather than more growth, would allow more children to fulfill their dreams.
Science, this issue p. 398; see also p. 382
We estimated rates of ``absolute income mobility''\textemdash{}the fraction of children who earn more than their parents\textemdash{}by combining data from U.S. Census and Current Population Survey cross sections with panel data from de-identified tax records. We found that rates of absolute mobility have fallen from approximately 90\% for children born in 1940 to 50\% for children born in the 1980s. Increasing Gross Domestic Product (GDP) growth rates alone cannot restore absolute mobility to the rates experienced by children born in the 1940s. However, distributing current GDP growth more equally across income groups as in the 1940 birth cohort would reverse more than 70\% of the decline in mobility. These results imply that reviving the ``American dream'' of high rates of absolute mobility would require economic growth that is shared more broadly across the income distribution.
Only half of Americans see their dreams come true.
Only half of Americans see their dreams come true.},
  language = {en},
  number = {6336},
  journal = {Science},
  author = {Chetty, Raj and Grusky, David and Hell, Maximilian and Hendren, Nathaniel and Manduca, Robert and Narang, Jimmy},
  year = {2017},
  pages = {398-406},
  file = {/Users/xiefangzhou/Zotero/storage/QLFTXXQK/Chetty et al. - 2017 - The fading American dream Trends in absolute inco.pdf},
  pmid = {28438988}
}

@article{forse2007,
  title = {{Perception des in{\'e}galit{\'e}s {\'e}conomiques et sentiment de justice sociale}},
  volume = {n\textdegree{} 102},
  issn = {1265-9576},
  abstract = {{$<$}titre{$>$}R{\'e}sum{\'e}{$<$}/titre{$>$}L'analyse de sondages d'opinion r{\'e}alis{\'e}s dans huit des pays participant {\`a} l'International Social Survey Programme, dont l'enqu{\^e}te {\'e}tait en 1999 centr{\'e}e sur le th{\`e}me des in{\'e}galit{\'e}s, montre que les interview{\'e}s ont plut{\^o}t tendance {\`a} sous-estimer les tr{\`e}s grandes in{\'e}galit{\'e}s de revenu et {\`a} se croire davantage dans la moyenne qu'ils ne le sont effectivement. Ils fondent leur sentiment de macrojustice sur leur estimation de l'ampleur des {\'e}carts entre les in{\'e}galit{\'e}s qu'ils per{\c c}oivent et celles qu'ils jugent acceptables et, de ce point de vue, le sentiment dominant est partout que ces in{\'e}galit{\'e}s sont trop fortes. Ce n'est cependant pas au nom d'un {\'e}galitarisme absolu qu'elles sont critiqu{\'e}es. Une certaine hi{\'e}rarchie des salaires, {\`a} condition d'{\^e}tre plus resserr{\'e}e, n'est pas rejet{\'e}e. Cette application non stricte du principe d'{\'e}galit{\'e} se retrouve lorsqu'il s'agit d'appr{\'e}cier la justice de sa situation {\'e}conomique personnelle. Leur sentiment de microjustice est en effet li{\'e} {\`a} une frustration relative \guillemotleft{} solidaire \guillemotright{} et au degr{\'e} de r{\'e}duction souhait{\'e}e des in{\'e}galit{\'e}s. Au total, le principe d'{\'e}quit{\'e}, qui autorise sous certaines conditions une diff{\'e}renciation salariale selon des m{\'e}rites ou efforts individuels, n'est pas contest{\'e}. Mais la r{\'e}mun{\'e}ration effective de ces m{\'e}rites par le jeu insuffisamment corrig{\'e} du march{\'e} aboutit aux yeux des personnes sond{\'e}es {\`a} une in{\'e}galit{\'e} trop grande qui doit {\^e}tre r{\'e}duite pour aller vers une situation plus juste.},
  language = {fr},
  number = {3},
  journal = {Revue de l'OFCE},
  author = {Fors{\'e}, Michel and Parodi, Maxime},
  year = {2007},
  pages = {483-540},
  file = {/Users/xiefangzhou/Zotero/storage/SPH4NPGK/Forsé and Parodi - 2007 - Perception des inégalités économiques et sentiment.pdf;/Users/xiefangzhou/Zotero/storage/AB8U6LK5/revue-de-l-ofce-2007-3-page-483.html}
}

@article{grosfeld2010,
  title = {The Emerging Aversion to Inequality},
  volume = {18},
  copyright = {\textcopyright{} 2010 The Authors. Journal compilation \textcopyright{} 2010 The European Bank for Reconstruction and Development},
  issn = {1468-0351},
  abstract = {This paper provides evidence of the changing attitudes to inequality during transition to the market in Poland. Using repeated cross-sections of the population, it identifies a structural break in the relationship between income inequality and satisfaction. Whereas in the first stage of the transition process, an increase in income inequality was interpreted by the population as a positive signal of wider opportunities, later in the transition period increased inequality became a factor in dissatisfaction with the country's economic situation. This was accompanied by increasing public sentiment that the process of income distribution is flawed and corrupt.},
  language = {en},
  number = {1},
  journal = {Economics of Transition and Institutional Change},
  author = {Grosfeld, Irena and Senik, Claudia},
  year = {2010},
  keywords = {D31,Inequality,breakpoint,C25,D63,growth,I30,P20,P26,subjective well-being,transition},
  pages = {1-26},
  file = {/Users/xiefangzhou/Zotero/storage/J7YL2XDA/Grosfeld and Senik - 2010 - The emerging aversion to inequality.pdf;/Users/xiefangzhou/Zotero/storage/X87UNFZW/j.1468-0351.2009.00376.html}
}

@article{benabou2006,
  title = {Belief in a {{Just World}} and {{Redistributive Politics}}},
  volume = {121},
  issn = {0033-5533},
  abstract = {Abstract.  International surveys reveal wide differences between the views held in different countries concerning the causes of wealth or poverty and the extent},
  language = {en},
  number = {2},
  journal = {The Quarterly Journal of Economics},
  author = {B{\'e}nabou, Roland and Tirole, Jean},
  year = {2006},
  pages = {699-746},
  file = {/Users/xiefangzhou/Zotero/storage/LLGKIIZX/Bénabou and Tirole - 2006 - Belief in a Just World and Redistributive Politics.pdf;/Users/xiefangzhou/Zotero/storage/4RMWH8MA/1884036.html}
}

@article{osberg2006,
  title = {``{{Fair}}'' {{Inequality}}? {{Attitudes}} toward {{Pay Differentials}}: {{The United States}} in {{Comparative Perspective}}},
  volume = {71},
  issn = {0003-1224},
  shorttitle = {``{{Fair}}'' {{Inequality}}?},
  abstract = {Are American attitudes toward economic inequality different from those in other countries? One tradition in sociology suggests American ``exceptionalism,'' while another argues for convergence across nations in social norms, such as attitudes toward inequality. This article uses International Social Survey Program (ISSP) microdata to compare attitudes in different countries toward what individuals in specific occupations ``do earn'' and what they ``should earn,'' and to distinguish value preferences for more egalitarian outcomes from other confounding attitudes and perceptions. The authors suggest a method for summarizing individual preferences for the leveling of earnings and use kernel density estimates to describe and compare the distribution of individual preferences over time and cross-nationally. They find that subjective estimates of inequality in pay diverge substantially from actual data, and that although Americans do not, on the average, have different preferences for aggregate (in)equality, there is evidence for:},
  language = {en},
  number = {3},
  journal = {American Sociological Review},
  author = {Osberg, Lars and Smeeding, Timothy},
  year = {2006},
  pages = {450-473},
  file = {/Users/xiefangzhou/Zotero/storage/HM65VDNK/Osberg and Smeeding - 2006 - “Fair” Inequality Attitudes toward Pay Differenti.pdf}
}

@book{thomas1999,
  series = {Policy {{Research Working Papers}}},
  title = {Measuring {{Education Inequality}}: {{Gini Coefficients}} of {{Education}}},
  shorttitle = {Measuring {{Education Inequality}}},
  publisher = {{The World Bank}},
  author = {Thomas, Vinod and Wang, Yan and Fan, Xibo},
  year = {1999},
  keywords = {ACCESS TO EDUCATION,BASIC EDUCATION,EDUCATION,EDUCATIONAL DEVELOPMENT,EDUCATIONAL OPPORTUNITIES,EDUCATIONAL PLANNING,ETHICS,GROUPS,ILLITERACY,KNOWLEDGE,LITERACY,MATHEMATICS,PRIMARY EDUCATION,QUALITY OF EDUCATION,SECONDARY EDUCATION,STUDENTS,TEACHERS,TERTIARY EDUCATION,TRAINING,VALUES},
  file = {/Users/xiefangzhou/Zotero/storage/8ESKQHZ2/Thomas - 1999 - Measuring Education Inequality Gini Coefficients .pdf;/Users/xiefangzhou/Zotero/storage/7JDGI8G2/1813-9450-2525.html}
}

@article{yang2014,
  title = {An Analysis of Education Inequality in {{China}}},
  volume = {37},
  issn = {0738-0593},
  abstract = {This article analyzes both the current situation regarding education inequality in China, and its formation mechanisms. Policies promoting education have lead to remarkable progress in educational attainment, and also effectively decreased educational inequality. However, substantial inequalities in educational attainment remain, even though sustainable progress has been realized. Decomposition results using the Gini coefficient and Shapley value approach based on regression analysis indicate that the greatest contributing factors to educational inequality involve the urban\textendash{}rural and social stratification divisions. Moreover, the household register system which divides city and country, as well as increasing income inequality is deepening institutional barriers and stratum differentiation. Though gender and regional gaps have been reduced significantly, the population residing in economically disadvantaged areas, especially females, still warrants social concern. In addition, age related decomposition results indicate that increasing educational attainment for the young plays a key role in reducing education inequality. At last, we argue that more educational investment should be allocated to disadvantaged groups and lower income groups; especially eliminating some institutional barriers such as the hukou system, unequal distribution of good quality educational resources, and so on.},
  journal = {International Journal of Educational Development},
  author = {Yang, Jun and Huang, Xiao and Liu, Xin},
  year = {2014},
  keywords = {China,Education inequality,Gini coefficient,Shapley decomposition},
  pages = {2-10},
  file = {/Users/xiefangzhou/Zotero/storage/VLI45WCC/Yang et al. - 2014 - An analysis of education inequality in China.pdf;/Users/xiefangzhou/Zotero/storage/TAG5KWLC/S0738059314000273.html}
}

@book{lopez-acevedo2006,
  series = {Policy {{Research Working Papers}}},
  title = {Mexico : {{Two Decades Of The Evolution Of Education And Inequality}}},
  shorttitle = {Mexico},
  publisher = {{The World Bank}},
  author = {{Lopez-Acevedo}, Gladys},
  year = {2006},
  keywords = {EDUCATION,BANK,CONTRIBUTION,EARNINGS,ECONOMIC DEVELOPMENT,ECONOMIC MANAGEMENT,FAMILY STRUCTURE,HOUSEHOLD INCOME,INCOME,INCOME LEVEL,INCOMES,INFORMATION,LABOR MARKET,PROPERTIES,RATE OF RETURN,SALARY,SENIOR,WAGE,WAGES,WELFARE},
  file = {/Users/xiefangzhou/Zotero/storage/9A2TCBA5/1813-9450-3919.html}
}

@article{yang2019,
  title = {Boosting {{Exponential Gradient Strategy}} for {{Online Portfolio Selection}}: {{An Aggregating Experts}}' {{Advice Method}}},
  issn = {1572-9974},
  shorttitle = {Boosting {{Exponential Gradient Strategy}} for {{Online Portfolio Selection}}},
  abstract = {Online portfolio selection is one of the fundamental problems in the field of computational finance. Although existing online portfolio strategies have been shown to achieve good performance, we always have to set the values for different parameters of online portfolio strategies, where the optimal values can only be known in hindsight. To tackle the limits of existing strategies, we present a new online portfolio strategy based on the online learning character of Weak Aggregating Algorithm (WAA). Firstly, we consider a number of Exponential Gradient (EG({$\mathsl{H}$})({$\eta$})(\textbackslash{}eta )) strategies of different values of parameter {$\mathsl{H}\eta\backslash$}eta as experts, and then determine the next portfolio by using the WAA to aggregate the experts' advice. Furthermore, we theoretically prove that our strategy asymptotically achieves the same increasing rate as the best EG({$\mathsl{H}$})({$\eta$})(\textbackslash{}eta ) expert. We prove our strategy, as EG({$\mathsl{H}$})({$\eta$})(\textbackslash{}eta ) strategies, is universal. We present numerical analysis by using actual stock data from the American and Chinese markets, and the results show that it has good performance.},
  language = {en},
  journal = {Computational Economics},
  author = {Yang, Xingyu and He, Jin'an and Lin, Hong and Zhang, Yong},
  year = {2019},
  keywords = {Online expert advice,Online portfolio selection,Universal portfolio,Weak aggregating algorithm},
  file = {/Users/xiefangzhou/Zotero/storage/3TPRSLEK/Yang et al. - 2019 - Boosting Exponential Gradient Strategy for Online .pdf}
}

@article{ibourk2012,
  title = {Measuring {{Education Inequalities}}: {{Concentration}} and {{Dispersion}}-{{Based Approach}}. {{Lessons}} from {{Kuznets Curve}} in {{MENA Region}}},
  volume = {2},
  issn = {1925-0746},
  shorttitle = {Measuring {{Education Inequalities}}},
  abstract = {Although the quantity of education is widely used to measure the economical and social performances of educative systems, only a few works have addressed the issue of equity in education. In this work, we have calculated two measures of inequality in education based on Barro and Lee's (2010) data: the Gini index of education and the standard deviation of schooling. The sample comprises 15 countries from the MENA region over the period 1950-2010. We used hierarchical clustering to control for the heterogeneity of the sample and identify the existence of cluster of similar value. We applied the Kuznets curve of education over the countries of the region. The findings show a decline in the Gini index within all the participating countries, for men and women and also for all age groups. The results also indicate that the education distribution was more unequal in the middle-income countries than in the higher-income countries in 2010, although they had almost the same level in 1970. The results suggested that the shape of the Kuznets curve depends basically on the measure used to approximate the inequality. Indeed, the Kuznets hypothesis is emphasized once we use the standard deviation of schooling. The Gini index, for its part, has maintained a significant negative relationship within the average number of years of the study.},
  language = {en},
  number = {6},
  journal = {World Journal of Education},
  author = {Ibourk, Aomar and Amaghouss, Jabrane},
  year = {2012},
  keywords = {Age Groups,Classification,Economic Development,Equal Education,Foreign Countries,Qualitative Research,Statistical Analysis},
  pages = {51-65},
  file = {/Users/xiefangzhou/Zotero/storage/44H5RAQR/Ibourk and Amaghouss - 2012 - Measuring Education Inequalities Concentration an.pdf;/Users/xiefangzhou/Zotero/storage/PJE36CQ3/eric.ed.gov.html}
}

@inproceedings{chen2016,
  address = {{New York, NY, USA}},
  series = {{{KDD}} '16},
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  isbn = {978-1-4503-4232-2},
  shorttitle = {{{XGBoost}}},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  booktitle = {Proceedings of the {{22Nd ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{ACM}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  year = {2016},
  keywords = {large-scale,learning,machine},
  pages = {785--794},
  file = {/Users/xiefangzhou/Zotero/storage/FEZ893XB/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf}
}

@article{little2013,
  title = {{21st Century Learning and Progressive Education: An Intersection}},
  volume = {9},
  issn = {1554-5210},
  shorttitle = {{21st Century Learning and Progressive Education}},
  abstract = {The seminal tenets of progressive education bear a striking resemblance to the newly fashionable principles associated with with a new movement known as \rule{1em}{1pt}21st Century Education. This article traces the development of progressive education principles, starting with the founding of the Progressive Education Association, and shows their close proximity to 21st century educational attributes and goals. It demonstrates how the principles underpinning progressive education emerge over and over again as operative and successful educational practice, and how 21st century reformers may benefit from turning attention to other principles of progressive education to fully prepare students for the future},
  language = {scheme="ISO639-1"},
  number = {1},
  journal = {International Journal Of Progressive Education},
  author = {Little, Tom},
  year = {2013},
  pages = {84-96},
  file = {/Users/xiefangzhou/Zotero/storage/RJNIXV9F/Little - 2013 - 21st Century Learning and Progressive Education A.pdf;/Users/xiefangzhou/Zotero/storage/SLRZQR55/277317.html}
}

@article{burnham1960,
  title = {Psychiatry, {{Psychology}} and the {{Progressive Movement}}},
  volume = {12},
  issn = {0003-0678},
  number = {4},
  journal = {American Quarterly},
  author = {Burnham, John Chynoweth},
  year = {1960},
  pages = {457-465},
  file = {/Users/xiefangzhou/Zotero/storage/W9AS2YRI/Burnham - 1960 - Psychiatry, Psychology and the Progressive Movemen.pdf}
}

@inproceedings{oconnor2010,
  title = {From {{Tweets}} to {{Polls}}: {{Linking Text Sentiment}} to {{Public Opinion Time Series}}},
  copyright = {Authors who publish a paper in this conference agree to the following terms:    1. Author(s) agree to transfer their copyrights in their article/paper to the Association for the Advancement of Artificial Intelligence (AAAI), in order to deal with future requests for reprints, translations, anthologies, reproductions, excerpts, and other publications. This grant will include, without limitation, the entire copyright in the article/paper in all countries of the world, including all renewals, extensions, and reversions thereof, whether such rights current exist or hereafter come into effect, and also the exclusive right to create electronic versions of the article/paper, to the extent that such right is not subsumed under copyright.    2. The author(s) warrants that they are the sole author and owner of the copyright in the above article/paper, except for those portions shown to be in quotations; that the article/paper is original throughout; and that the undersigned right to make the grants set forth above is complete and unencumbered.    3. The author(s) agree that if anyone brings any claim or action alleging facts that, if true, constitute a breach of any of the foregoing warranties, the author(s) will hold harmless and indemnify AAAI, their grantees, their licensees, and their distributors against any liability, whether under judgment, decree, or compromise, and any legal fees and expenses arising out of that claim or actions, and the undersigned will cooperate fully in any defense AAAI may make to such claim or action. Moreover, the undersigned agrees to cooperate in any claim or other action seeking to protect or enforce any right the undersigned has granted to AAAI in the article/paper. If any such claim or action fails because of facts that constitute a breach of any of the foregoing warranties, the undersigned agrees to reimburse whomever brings such claim or action for expenses and attorneys' fees incurred therein.    4. Author(s) retain all proprietary rights other than copyright (such as patent rights).    5. Author(s) may make personal reuse of all or portions of the above article/paper in other works of their own authorship.    6. Author(s) may reproduce, or have reproduced, their article/paper for the author's personal use, or for company use provided that AAAI copyright and the source are indicated, and that the copies are not used in a way that implies AAAI endorsement of a product or service of an employer, and that the copies per se are not offered for sale. The foregoing right shall not permit the posting of the article/paper in electronic or digital form on any computer network, except by the author or the author's employer, and then only on the author's or the employer's own web page or ftp site. Such web page or ftp site, in addition to the aforementioned requirements of this Paragraph, must provide an electronic reference or link back to the AAAI electronic server, and shall not post other AAAI copyrighted materials not of the author's or the employer's creation (including tables of contents with links to other papers) without AAAI's written permission.    7. Author(s) may make limited distribution of all or portions of their article/paper prior to publication.    8. In the case of work performed under U.S. Government contract, AAAI grants the U.S. Government royalty-free permission to reproduce all or portions of the above article/paper, and to authorize others to do so, for U.S. Government purposes.    9. In the event the above article/paper is not accepted and published by AAAI, or is withdrawn by the author(s) before acceptance by AAAI, this agreement becomes null and void.},
  shorttitle = {From {{Tweets}} to {{Polls}}},
  abstract = {We connect measures of public opinion measured from  polls with sentiment measured from text. We analyze  several surveys on consumer confidence and political  opinion over the 2008 to 2009 period, and find they  correlate to sentiment word frequencies in contempora-  neous Twitter messages. While our results vary across  datasets, in several cases the correlations are as high as  80\%, and capture important large-scale trends. The re-  sults highlight the potential of text streams as a substi-  tute and supplement for traditional polling.  consumer confidence and political opinion, and can also pre-  dict future movements in the polls. We find that temporal  smoothing is a critically important issue to support a suc-  cessful model.},
  language = {en},
  booktitle = {Fourth {{International AAAI Conference}} on {{Weblogs}} and {{Social Media}}},
  author = {O'Connor, Brendan and Balasubramanyan, Ramnath and Routledge, Bryan R. and Smith, Noah A.},
  year = {2010},
  file = {/Users/xiefangzhou/Zotero/storage/ZEBZ5KH9/O'Connor et al. - 2010 - From Tweets to Polls Linking Text Sentiment to Pu.pdf;/Users/xiefangzhou/Zotero/storage/RWUG24F7/1536.html}
}

@article{mutz1997,
  title = {Reading {{Public Opinion}}: {{The Influence}} of {{News Coverage}} on {{Perceptions}} of {{Public Sentiment}}},
  volume = {61},
  issn = {0033-362X},
  shorttitle = {Reading {{Public Opinion}}},
  abstract = {[This study traces the effects of a purposefully chosen news agenda on the perceived and actual issue opinions of members of the mass public. Using a year-long, quasi-experimental design, we analyzed a newspaper's attempt to move community opinion and bring about policy change. We examined the success of these efforts from the perspective of their intended effects on public opinion and from the perspective of their unintended effects on perceptions of the broader political environment. Overall, our findings suggest that this strategy is extremely limited in its ability to bring about changes in the opinions of individual members of the mass public or even changes in the salience they attach to an issue at a personal level. Nonetheless, we find that this practice may have important effects on citizens' perceptions of the salience the community as a whole attaches to an issue and on their perceptions of the dominant opinion climate within their communities. Although these effects may not be identical to the goals of the news organization, the ability to alter the perceptual environment in which policy changes transpire implies that news organizations may be able to facilitate indirectly the very changes they seek.]},
  number = {3},
  journal = {The Public Opinion Quarterly},
  author = {Mutz, Diana C. and Soss, Joe},
  year = {1997},
  pages = {431-451},
  file = {/Users/xiefangzhou/Zotero/storage/253G5866/Mutz and Soss - 1997 - Reading Public Opinion The Influence of News Cove.pdf}
}

@article{hyvarinen2000,
  title = {Independent Component Analysis: Algorithms and Applications},
  volume = {13},
  issn = {0893-6080},
  shorttitle = {Independent Component Analysis},
  abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.},
  number = {4},
  journal = {Neural Networks},
  author = {Hyv{\"a}rinen, A. and Oja, E.},
  year = {2000},
  keywords = {Factor analysis,Blind signal separation,Independent component analysis,Projection pursuit,Representation,Source separation},
  pages = {411-430},
  file = {/Users/xiefangzhou/Zotero/storage/GSHXC3E9/Hyvärinen and Oja - 2000 - Independent component analysis algorithms and app.pdf;/Users/xiefangzhou/Zotero/storage/9EDJR5SS/S0893608000000265.html}
}

@article{mnih2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  volume = {518},
  copyright = {2015 Nature Publishing Group},
  issn = {1476-4687},
  abstract = {The theory of reinforcement learning provides a normative account1, deeply rooted in psychological2 and neuroscientific3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems4,5, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms3. While reinforcement learning agents have achieved some successes in a variety of domains6,7,8, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks9,10,11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games12. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
  language = {en},
  number = {7540},
  journal = {Nature},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  year = {2015},
  pages = {529-533},
  file = {/Users/xiefangzhou/Zotero/storage/WKMSWWKH/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf;/Users/xiefangzhou/Zotero/storage/FKLZDRIS/nature14236.html}
}

@article{schluter,
  title = {Restricted {{Boltzmann Machine Derivations}}},
  abstract = {This document gives detailed derivations for the central quantities of Restricted Boltzmann Machines (RBMs): The conditional distributions of visible and hidden units, and the log likelihood gradient with respect to the model parameters. It handles the standard Bernoulli-Bernoulli RBM (with binary visible and hidden units) as well as di erent formulations of the Gaussian-Bernoulli RBM (with real-valued visible units). It is not meant as a general introduction to RBMs, but as a supplement helping to follow the mathematics. If you are not familiar with RBMs, introductions can be found in [3] (mathematical), [2] (practical) or [7, Section 4.4] (intuitive).},
  language = {en},
  author = {Schl{\"u}ter, Jan},
  pages = {18},
  file = {/Users/xiefangzhou/Zotero/storage/6EIGZTIF/Schlüter - Restricted Boltzmann Machine Derivations.pdf}
}

@incollection{montavon2016,
  title = {Wasserstein {{Training}} of {{Restricted Boltzmann Machines}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  publisher = {{Curran Associates, Inc.}},
  author = {Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Cuturi, Marco},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  year = {2016},
  pages = {3718--3726},
  file = {/Users/xiefangzhou/Zotero/storage/VUXAEC4W/Montavon et al. - 2016 - Wasserstein Training of Restricted Boltzmann Machi.pdf;/Users/xiefangzhou/Zotero/storage/NLHZEALH/6248-wasserstein-training-of-restricted-boltzmann-machines.html}
}

@article{oster2018,
  title = {Diabetes and {{Diet}}: {{Purchasing Behavior Change}} in {{Response}} to {{Health Information}}},
  volume = {10},
  issn = {1945-7782},
  shorttitle = {Diabetes and {{Diet}}},
  abstract = {Individuals with obesity and related conditions are often reluctant to change their diet. Evaluating the details of this reluctance is hampered by limited data. I use household scanner data to estimate food purchase response to a diagnosis of diabetes. I use a machine learning approach to infer diagnosis from purchases of diabetes-related products. On average, households show 
significant, but relatively small, calorie reductions. These reductions are concentrated in unhealthy foods, suggesting they reflect real efforts to improve diet. There is some heterogeneity in calorie changes across households, although this heterogeneity is not well predicted by demographics or baseline diet, despite large correlations between these factors and diagnosis. I suggest a theory of 
behavior change which may explain the limited overall change and the fact that heterogeneity is not predictable.},
  language = {en},
  number = {4},
  journal = {American Economic Journal: Applied Economics},
  author = {Oster, Emily},
  year = {2018},
  keywords = {Belief,Communication,Information and Knowledge,Learning,Consumer Economics: Empirical Analysis; Search,Unawareness; Micro-Based Behavioral Economics: Role and Effects of Psychological; Emotional; Social; and Cognitive Factors on Decision Making; Health Behavior; Marketing},
  pages = {308-348},
  file = {/Users/xiefangzhou/Zotero/storage/PUG64KBA/Oster - 2018 - Diabetes and Diet Purchasing Behavior Change in R.pdf;/Users/xiefangzhou/Zotero/storage/94WEXGLP/articles.html}
}

@article{shin2018,
  title = {Measuring International Uncertainty: {{The}} Case of {{Korea}}},
  volume = {162},
  issn = {0165-1765},
  shorttitle = {Measuring International Uncertainty},
  abstract = {We leverage a data rich environment to construct and study a measure of macroeconomic uncertainty for the Korean economy. We provide several stylized facts about uncertainty in Korea from 1991M10\textendash{}2016M5. We compare and contrast this measure of uncertainty with two other popular uncertainty proxies, financial and policy uncertainty proxies, as well as the U.S. measure constructed by Jurado et al. (2015). We find that neither financial nor policy uncertainty proxies capture economy-wide uncertainty. Unlike our measure or financial uncertainty, policy uncertainty does not have much effect on real variables in Korea.},
  journal = {Economics Letters},
  author = {Shin, Minchul and Zhang, Boyuan and Zhong, Molin and Lee, Dong Jin},
  year = {2018},
  keywords = {Business cycle,Data rich environment,Korean economy,Small open economy,Stochastic volatility,Uncertainty},
  pages = {22-26},
  file = {/Users/xiefangzhou/Zotero/storage/G2QMDMW8/Shin et al. - 2018 - Measuring international uncertainty The case of K.pdf;/Users/xiefangzhou/Zotero/storage/JTGFLR6V/S0165176517304305.html}
}

@article{jurado2015,
  title = {Measuring {{Uncertainty}}},
  volume = {105},
  issn = {0002-8282},
  abstract = {This paper exploits a data rich environment to provide direct econometric estimates of time-varying macroeconomic uncertainty. Our estimates display significant independent variations from popular uncertainty proxies, suggesting that much of the variation in the proxies is not driven by uncertainty. Quantitatively important uncertainty episodes appear far more infrequently than indicated by popular uncertainty proxies, but when they do occur, they are larger, more persistent, and are more correlated with real activity. Our estimates provide a benchmark to evaluate theories for which uncertainty shocks play a role in business cycles. (JEL C53, D81, E32, G12, G35, L25)},
  language = {en},
  number = {3},
  journal = {American Economic Review},
  author = {Jurado, Kyle and Ludvigson, Sydney C. and Ng, Serena},
  year = {2015},
  keywords = {Trading Volume,Bond Interest Rates; Payout Policy; Firm Performance: Size; Diversification; and Scope,Cycles; Asset Pricing,Forecasting Models,Simulation Methods; Criteria for Decision-Making under Risk and Uncertainty; Business Fluctuations},
  pages = {1177-1216},
  file = {/Users/xiefangzhou/Zotero/storage/XJLC2K5E/Jurado et al. - 2015 - Measuring Uncertainty.pdf;/Users/xiefangzhou/Zotero/storage/7DPDSWYN/articles.html}
}

@article{hu2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1906.05450},
  primaryClass = {math},
  title = {A {{Brief Introduction}} to {{Manifold Optimization}}},
  abstract = {Manifold optimization is ubiquitous in computational and applied mathematics, statistics, engineering, machine learning, physics, chemistry and etc. One of the main challenges usually is the non-convexity of the manifold constraints. By utilizing the geometry of manifold, a large class of constrained optimization problems can be viewed as unconstrained optimization problems on manifold. From this perspective, intrinsic structures, optimality conditions and numerical algorithms for manifold optimization are investigated. Some recent progress on the theoretical results of manifold optimization are also presented.},
  journal = {arXiv:1906.05450 [math]},
  author = {Hu, Jiang and Liu, Xin and Wen, Zaiwen and Yuan, Yaxiang},
  year = {2019},
  keywords = {Mathematics - Optimization and Control},
  file = {/Users/xiefangzhou/Zotero/storage/S7LAZ2SK/Hu et al. - 2019 - A Brief Introduction to Manifold Optimization.pdf;/Users/xiefangzhou/Zotero/storage/5FTF4SQ3/1906.html}
}

@article{fan2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1811.09025},
  primaryClass = {math},
  title = {An {{Introduction}} to {{Krylov Subspace Methods}}},
  abstract = {Nowadays, many fields of study are have to deal with large and sparse data matrixes, but the most important issue is finding the inverse of these matrixes. Thankfully, Krylov subspace methods can be used in solving these types of problem. However, it is difficult to understand mathematical principles behind these methods. In the first part of the article, Krylov methods are discussed in detail. Thus, readers equipped with a basic knowledge of linear algebra should be able to understand these methods. In this part, the knowledge of Krylov methods are put into some examples for simple implementations of a commonly known Krylov method GMRES. In the second part, the article talks about CG iteration, a wildly known method which is very similar to Krylov methods. By comparison between CG iteration and Krylov methods, readers can get a better comprehension of Krylov methods based on CG iteration. In the third part of the article, aiming to improve the efficiency of Krylov methods, preconditioners are discussed. In addition, the restarting GMRES is briefly introduced to reduce the space consumption of Krylov methods in this part.},
  journal = {arXiv:1811.09025 [math]},
  author = {Fan, Shitao},
  year = {2018},
  keywords = {Mathematics - Optimization and Control},
  file = {/Users/xiefangzhou/Zotero/storage/G8KSLHVE/Fan - 2018 - An Introduction to Krylov Subspace Methods.pdf;/Users/xiefangzhou/Zotero/storage/DIGP446X/1811.html}
}

@article{vandemeent2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1809.10756},
  primaryClass = {cs, stat},
  title = {An {{Introduction}} to {{Probabilistic Programming}}},
  abstract = {This document is designed to be a first-year graduate-level introduction to probabilistic programming. It not only provides a thorough background for anyone wishing to use a probabilistic programming system, but also introduces the techniques needed to design and build these systems. It is aimed at people who have an undergraduate-level understanding of either or, ideally, both probabilistic machine learning and programming languages. We start with a discussion of model-based reasoning and explain why conditioning as a foundational computation is central to the fields of probabilistic machine learning and artificial intelligence. We then introduce a simple first-order probabilistic programming language (PPL) whose programs define static-computation-graph, finite-variable-cardinality models. In the context of this restricted PPL we introduce fundamental inference algorithms and describe how they can be implemented in the context of models denoted by probabilistic programs. In the second part of this document, we introduce a higher-order probabilistic programming language, with a functionality analogous to that of established programming languages. This affords the opportunity to define models with dynamic computation graphs, at the cost of requiring inference methods that generate samples by repeatedly executing the program. Foundational inference algorithms for this kind of probabilistic programming language are explained in the context of an interface between program executions and an inference controller. This document closes with a chapter on advanced topics which we believe to be, at the time of writing, interesting directions for probabilistic programming research; directions that point towards a tight integration with deep neural network research and the development of systems for next-generation artificial intelligence applications.},
  journal = {arXiv:1809.10756 [cs, stat]},
  author = {{van de Meent}, Jan-Willem and Paige, Brooks and Yang, Hongseok and Wood, Frank},
  year = {2018},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Programming Languages},
  file = {/Users/xiefangzhou/Zotero/storage/TAP9NQ26/van de Meent et al. - 2018 - An Introduction to Probabilistic Programming.pdf;/Users/xiefangzhou/Zotero/storage/FM8FLWXP/1809.html}
}

@article{vanelst2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1808.10173},
  primaryClass = {stat},
  title = {An {{Introduction}} to {{Inductive Statistical Inference}} -- from {{Parameter Estimation}} to {{Decision}}-{{Making}}},
  abstract = {These lecture notes aim at a post-Bachelor audience with a backgound at an introductory level in Applied Mathematics and Applied Statistics. They discuss the logic and methodology of the Bayes-Laplace approach to inductive statistical inference that places common sense and the guiding lines of the scientific method at the heart of systematic analyses of quantitative-empirical data. Following an exposition of exactly solvable cases of single- and two-parameter estimation, the main focus is laid on Markov Chain Monte Carlo (MCMC) simulations on the basis of Gibbs sampling and Hamiltonian Monte Carlo sampling of posterior joint probability distributions for regression parameters occurring in generalised linear models. The modelling of fixed as well as of varying effects (varying intercepts) is considered, and the simulation of posterior predictive distributions is outlined. The issues of model comparison with Bayes factors and the assessment of models' relative posterior predictive accuracy with information entropy-based criteria DIC and WAIC are addressed. Concluding, a conceptual link to the behavioural subjective expected utility representation of a single decision-maker's choice behaviour in static one-shot decision problems is established. Codes for MCMC simulations of multi-dimensional posterior joint probability distributions with the JAGS and Stan packages implemented in the statistical software R are provided. The lecture notes are fully hyperlinked. They direct the reader to original scientific research papers and to pertinent biographical information.},
  journal = {arXiv:1808.10173 [stat]},
  author = {{van Elst}, Henk},
  year = {2018},
  keywords = {Statistics - Applications},
  file = {/Users/xiefangzhou/Zotero/storage/YHFSI3QA/van Elst - 2018 - An Introduction to Inductive Statistical Inference.pdf;/Users/xiefangzhou/Zotero/storage/RDVQEB6J/1808.html}
}

@article{nielsen2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1808.08271},
  primaryClass = {cs, math, stat},
  title = {An Elementary Introduction to Information Geometry},
  abstract = {We describe the fundamental differential-geometric structures of information manifolds, state the fundamental theorem of information geometry, and illustrate some uses of these information manifolds in information sciences. The exposition is self-contained by concisely introducing the necessary concepts of differential geometry with proofs omitted for brevity.},
  journal = {arXiv:1808.08271 [cs, math, stat]},
  author = {Nielsen, Frank},
  year = {2018},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Computer Science - Information Theory},
  file = {/Users/xiefangzhou/Zotero/storage/DNDNLDPH/Nielsen - 2018 - An elementary introduction to information geometry.pdf;/Users/xiefangzhou/Zotero/storage/GP5XJJN2/1808.html}
}

@article{kaabar2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1807.08633},
  primaryClass = {math},
  title = {A {{Friendly Introduction}} to {{Differential Equations}}},
  abstract = {In this book, there are five chapters: The Laplace Transform, Systems of Homogeneous Linear Differential Equations (HLDE), Methods of First and Higher Orders Differential Equations, Extended Methods of First and Higher Orders Differential Equations, and Applications of Differential Equations. In addition, there are exercises at the end of each chapter above to let students practice additional sets of problems other than examples, and they can also check their solutions to some of these exercises by looking at "Answers to Odd-Numbered Exercises" section at the end of this book. This book is a very useful for college students who studied Calculus II, and other students who want to review some concepts of differential equations before studying courses such as partial differential equations, applied mathematics, and electric circuits II. This book is available online for free in google books and ResearchGate in PDF format under a Creative Commons license.},
  journal = {arXiv:1807.08633 [math]},
  author = {Kaabar, Mohammed K. A.},
  year = {2015},
  keywords = {Mathematics - History and Overview},
  file = {/Users/xiefangzhou/Zotero/storage/BLZ43ITR/Kaabar - 2015 - A Friendly Introduction to Differential Equations.pdf;/Users/xiefangzhou/Zotero/storage/4LT9RAU9/1807.html}
}

@article{quiroz2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1807.08409},
  primaryClass = {stat},
  title = {Subsampling {{MCMC}} - {{An}} Introduction for the Survey Statistician},
  abstract = {The rapid development of computing power and efficient Markov Chain Monte Carlo (MCMC) simulation algorithms have revolutionized Bayesian statistics, making it a highly practical inference method in applied work. However, MCMC algorithms tend to be computationally demanding, and are particularly slow for large datasets. Data subsampling has recently been suggested as a way to make MCMC methods scalable on massively large data, utilizing efficient sampling schemes and estimators from the survey sampling literature. These developments tend to be unknown by many survey statisticians who traditionally work with non-Bayesian methods, and rarely use MCMC. Our article explains the idea of data subsampling in MCMC by reviewing one strand of work, Subsampling MCMC, a so called pseudo-marginal MCMC approach to speeding up MCMC through data subsampling. The review is written for a survey statistician without previous knowledge of MCMC methods since our aim is to motivate survey sampling experts to contribute to the growing Subsampling MCMC literature.},
  journal = {arXiv:1807.08409 [stat]},
  author = {Quiroz, Matias and Villani, Mattias and Kohn, Robert and Tran, Minh-Ngoc and Dang, Khue-Dung},
  year = {2018},
  keywords = {Statistics - Machine Learning,Statistics - Computation,Statistics - Methodology},
  file = {/Users/xiefangzhou/Zotero/storage/5PQYVCYQ/Quiroz et al. - 2018 - Subsampling MCMC - An introduction for the survey .pdf;/Users/xiefangzhou/Zotero/storage/DBAJR8HF/1807.html}
}

@article{montufar2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1806.07066},
  primaryClass = {cs, math, stat},
  title = {Restricted {{Boltzmann Machines}}: {{Introduction}} and {{Review}}},
  shorttitle = {Restricted {{Boltzmann Machines}}},
  abstract = {The restricted Boltzmann machine is a network of stochastic units with undirected interactions between pairs of visible and hidden units. This model was popularized as a building block of deep learning architectures and has continued to play an important role in applied and theoretical machine learning. Restricted Boltzmann machines carry a rich structure, with connections to geometry, applied algebra, probability, statistics, machine learning, and other areas. The analysis of these models is attractive in its own right and also as a platform to combine and generalize mathematical tools for graphical models with hidden variables. This article gives an introduction to the mathematical analysis of restricted Boltzmann machines, reviews recent results on the geometry of the sets of probability distributions representable by these models, and suggests a few directions for further investigation.},
  journal = {arXiv:1806.07066 [cs, math, stat]},
  author = {Montufar, Guido},
  year = {2018},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Mathematics - Probability,Computer Science - Information Theory,Mathematics - Statistics Theory},
  file = {/Users/xiefangzhou/Zotero/storage/6LHWDQTK/Montufar - 2018 - Restricted Boltzmann Machines Introduction and Re.pdf;/Users/xiefangzhou/Zotero/storage/ZHESP2KM/1806.html}
}

@article{stone2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1802.05968},
  primaryClass = {cs, math, stat},
  title = {Information {{Theory}}: {{A Tutorial Introduction}}},
  shorttitle = {Information {{Theory}}},
  abstract = {Shannon's mathematical theory of communication defines fundamental limits on how much information can be transmitted between the different components of any man-made or biological system. This paper is an informal but rigorous introduction to the main ideas implicit in Shannon's theory. An annotated reading list is provided for further reading.},
  journal = {arXiv:1802.05968 [cs, math, stat]},
  author = {Stone, James V.},
  year = {2018},
  keywords = {Statistics - Machine Learning,Computer Science - Information Theory,94A05},
  file = {/Users/xiefangzhou/Zotero/storage/JTLCZ8F6/Stone - 2018 - Information Theory A Tutorial Introduction.pdf;/Users/xiefangzhou/Zotero/storage/VQJQTGSV/1802.html}
}

@article{saxena2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1712.08328},
  primaryClass = {cs, math},
  title = {A Simple Introduction to {{Karmarkar}}'s {{Algorithm}} for {{Linear Programming}}},
  abstract = {An extremely simple, description of Karmarkar's algorithm with very few technical terms is given.},
  journal = {arXiv:1712.08328 [cs, math]},
  author = {Saxena, Sanjeev},
  year = {2017},
  keywords = {Mathematics - Optimization and Control,Computer Science - Data Structures and Algorithms},
  file = {/Users/xiefangzhou/Zotero/storage/EYRLEB9X/Saxena - 2017 - A simple introduction to Karmarkar's Algorithm for.pdf;/Users/xiefangzhou/Zotero/storage/B4PCGW8S/1712.html}
}

@article{borot2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1710.10792},
  primaryClass = {math},
  title = {An Introduction to Random Matrix Theory},
  abstract = {These are lectures notes for a 4h30 mini-course held in Ulaanbaatar, National University of Mongolia, August 5-7th 2015, at the summer school "Stochastic Processes and Applications". It aims at presenting an introduction to basic results of random matrix theory and some of its motivations, targeted to a large panel of students coming from statistics, finance, etc. Only a small background in probability is required.},
  journal = {arXiv:1710.10792 [math]},
  author = {Borot, Ga{\"e}tan},
  year = {2017},
  keywords = {Mathematics - Probability,15B52; 60B20; 62-07},
  file = {/Users/xiefangzhou/Zotero/storage/DB3M3AQ2/Borot - 2017 - An introduction to random matrix theory.pdf;/Users/xiefangzhou/Zotero/storage/DIM7MFXH/1710.html}
}

@article{chazal2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1710.04019},
  primaryClass = {cs, math, stat},
  title = {An Introduction to {{Topological Data Analysis}}: Fundamental and Practical Aspects for Data Scientists},
  shorttitle = {An Introduction to {{Topological Data Analysis}}},
  abstract = {Topological Data Analysis (tda) is a recent and fast growing eld providing a set of new topological and geometric tools to infer relevant features for possibly complex data. This paper is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of tda for non experts. 1 Introduction and motivation Topological Data Analysis (tda) is a recent eld that emerged from various works in applied (algebraic) topology and computational geometry during the rst decade of the century. Although one can trace back geometric approaches for data analysis quite far in the past, tda really started as a eld with the pioneering works of Edelsbrunner et al. (2002) and Zomorodian and Carlsson (2005) in persistent homology and was popularized in a landmark paper in 2009 Carlsson (2009). tda is mainly motivated by the idea that topology and geometry provide a powerful approach to infer robust qualitative, and sometimes quantitative, information about the structure of data-see, e.g. Chazal (2017). tda aims at providing well-founded mathematical, statistical and algorithmic methods to infer, analyze and exploit the complex topological and geometric structures underlying data that are often represented as point clouds in Euclidean or more general metric spaces. During the last few years, a considerable eort has been made to provide robust and ecient data structures and algorithms for tda that are now implemented and available and easy to use through standard libraries such as the Gudhi library (C++ and Python) Maria et al. (2014) and its R software interface Fasy et al. (2014a). Although it is still rapidly evolving, tda now provides a set of mature and ecient tools that can be used in combination or complementary to other data sciences tools. The tdapipeline. tda has recently known developments in various directions and application elds. There now exist a large variety of methods inspired by topological and geometric approaches. Providing a complete overview of all these existing approaches is beyond the scope of this introductory survey. However, most of them rely on the following basic and standard pipeline that will serve as the backbone of this paper: 1. The input is assumed to be a nite set of points coming with a notion of distance-or similarity between them. This distance can be induced by the metric in the ambient space (e.g. the Euclidean metric when the data are embedded in R d) or come as an intrinsic metric dened by a pairwise distance matrix. The denition of the metric on the data is usually given as an input or guided by the application. It is however important to notice that the choice of the metric may be critical to reveal interesting topological and geometric features of the data.},
  journal = {arXiv:1710.04019 [cs, math, stat]},
  author = {Chazal, Fr{\'e}d{\'e}ric and Michel, Bertrand},
  year = {2017},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Mathematics - Statistics Theory,Mathematics - Algebraic Topology},
  file = {/Users/xiefangzhou/Zotero/storage/BNF7EPH2/Chazal and Michel - 2017 - An introduction to Topological Data Analysis fund.pdf;/Users/xiefangzhou/Zotero/storage/XVU3DMLU/1710.html}
}

@article{chodrow2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1708.07459},
  primaryClass = {physics, stat},
  title = {Divergence, {{Entropy}}, {{Information}}: {{An Opinionated Introduction}} to {{Information Theory}}},
  shorttitle = {Divergence, {{Entropy}}, {{Information}}},
  abstract = {Information theory is a mathematical theory of learning with deep connections with topics as diverse as artificial intelligence, statistical physics, and biological evolution. Many primers on information theory paint a broad picture with relatively little mathematical sophistication, while many others develop specific application areas in detail. In contrast, these informal notes aim to outline some elements of the information-theoretic "way of thinking," by cutting a rapid and interesting path through some of the theory's foundational concepts and results. They are aimed at practicing systems scientists who are interested in exploring potential connections between information theory and their own fields. The main mathematical prerequisite for the notes is comfort with elementary probability, including sample spaces, conditioning, and expectations. We take the Kullback-Leibler divergence as our most basic concept, and then proceed to develop the entropy and mutual information. We discuss some of the main results, including the Chernoff bounds as a characterization of the divergence; Gibbs' Theorem; and the Data Processing Inequality. A recurring theme is that the definitions of information theory support natural theorems that sound ``obvious'' when translated into English. More pithily, ``information theory makes common sense precise.'' Since the focus of the notes is not primarily on technical details, proofs are provided only where the relevant techniques are illustrative of broader themes. Otherwise, proofs and intriguing tangents are referenced in liberally-sprinkled footnotes. The notes close with a highly nonexhaustive list of references to resources and other perspectives on the field.},
  journal = {arXiv:1708.07459 [physics, stat]},
  author = {Chodrow, Philip},
  year = {2017},
  keywords = {Computer Science - Information Theory,Mathematics - Statistics Theory,Physics - Data Analysis; Statistics and Probability},
  file = {/Users/xiefangzhou/Zotero/storage/69347MNB/Chodrow - 2017 - Divergence, Entropy, Information An Opinionated I.pdf;/Users/xiefangzhou/Zotero/storage/LELCMC2L/1708.html}
}

@article{leobacher2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1707.04293},
  primaryClass = {math, q-fin},
  title = {A Short Introduction to Quasi-{{Monte Carlo}} Option Pricing},
  abstract = {One of the main practical applications of quasi-Monte Carlo (QMC) methods is the valuation of financial derivatives. We aim to give a short introduction into option pricing and show how it is facilitated using QMC. We give some practical examples for illustration.},
  journal = {arXiv:1707.04293 [math, q-fin]},
  author = {Leobacher, Gunther},
  year = {2014},
  keywords = {Mathematics - Numerical Analysis,Quantitative Finance - Computational Finance},
  file = {/Users/xiefangzhou/Zotero/storage/HE2KI3GD/Leobacher - 2014 - A short introduction to quasi-Monte Carlo option p.pdf;/Users/xiefangzhou/Zotero/storage/MTE6GYZU/1707.html}
}

@article{gillis2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1703.00663},
  primaryClass = {cs, math, stat},
  title = {Introduction to {{Nonnegative Matrix Factorization}}},
  abstract = {In this paper, we introduce and provide a short overview of nonnegative matrix factorization (NMF). Several aspects of NMF are discussed, namely, the application in hyperspectral imaging, geometry and uniqueness of NMF solutions, complexity, algorithms, and its link with extended formulations of polyhedra. In order to put NMF into perspective, the more general problem class of constrained low-rank matrix approximation problems is first briefly introduced.},
  journal = {arXiv:1703.00663 [cs, math, stat]},
  author = {Gillis, Nicolas},
  year = {2017},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning,Mathematics - Optimization and Control,Computer Science - Computer Vision and Pattern Recognition,Mathematics - Numerical Analysis},
  file = {/Users/xiefangzhou/Zotero/storage/L96WRD5Z/Gillis - 2017 - Introduction to Nonnegative Matrix Factorization.pdf;/Users/xiefangzhou/Zotero/storage/UCFXKC7A/1703.html}
}

@article{betancourt2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1701.02434},
  primaryClass = {stat},
  title = {A {{Conceptual Introduction}} to {{Hamiltonian Monte Carlo}}},
  abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  journal = {arXiv:1701.02434 [stat]},
  author = {Betancourt, Michael},
  year = {2017},
  keywords = {Statistics - Methodology},
  file = {/Users/xiefangzhou/Zotero/storage/HIVH265T/Betancourt - 2017 - A Conceptual Introduction to Hamiltonian Monte Car.pdf;/Users/xiefangzhou/Zotero/storage/U8UCR229/1701.html}
}

@article{chen2016a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.09316},
  primaryClass = {cs, math},
  title = {A {{Brief Introduction}} to {{Shannon}}'s {{Information Theory}}},
  abstract = {This article consists of a brief introduction to the Shannon information theory. Two topics, entropy and channel capacity, are mainly covered. All these concepts are developed in a totally combinatorial favor. Some issues usually not addressed in the literature are discussed here as well.},
  journal = {arXiv:1612.09316 [cs, math]},
  author = {Chen, Ricky X. F.},
  year = {2016},
  keywords = {Computer Science - Information Theory,05A16; 94A15,Mathematics - Combinatorics},
  file = {/Users/xiefangzhou/Zotero/storage/4JZI44SC/Chen - 2016 - A Brief Introduction to Shannon's Information Theo.pdf;/Users/xiefangzhou/Zotero/storage/VJSPLHSP/1612.html}
}

@article{witte2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.06244},
  primaryClass = {cs, q-fin},
  title = {The {{Blockchain}}: {{A Gentle Four Page Introduction}}},
  shorttitle = {The {{Blockchain}}},
  abstract = {Blockchain is a distributed database that keeps a chronologically-growing list (chain) of records (blocks) secure from tampering and revision. While computerisation has changed the nature of a ledger from clay tables in the old days to digital records in modern days, blockchain technology is the first true innovation in record keeping that could potentially revolutionise the basic principles of information keeping. In this note, we provide a brief self-contained introduction to how the blockchain works.},
  journal = {arXiv:1612.06244 [cs, q-fin]},
  author = {Witte, Jan Hendrik},
  year = {2016},
  keywords = {Computer Science - Cryptography and Security,Quantitative Finance - General Finance},
  file = {/Users/xiefangzhou/Zotero/storage/PF6G2PB6/Witte - 2016 - The Blockchain A Gentle Four Page Introduction.pdf;/Users/xiefangzhou/Zotero/storage/C9FGIPXJ/1612.html}
}

@article{sochi2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1603.01660},
  primaryClass = {math},
  title = {Introduction to {{Tensor Calculus}}},
  abstract = {These are general notes on tensor calculus which can be used as a reference for an introductory course on tensor algebra and calculus. A basic knowledge of calculus and linear algebra with some commonly used mathematical terminology is presumed.},
  journal = {arXiv:1603.01660 [math]},
  author = {Sochi, Taha},
  year = {2016},
  keywords = {Mathematics - History and Overview},
  file = {/Users/xiefangzhou/Zotero/storage/Z9KF947R/Sochi - 2016 - Introduction to Tensor Calculus.pdf;/Users/xiefangzhou/Zotero/storage/GLKCTVWJ/1603.html}
}

@article{blume2015,
  series = {Computer {{Science}} and {{Economic Theory}}},
  title = {Introduction to Computer Science and Economic Theory},
  volume = {156},
  issn = {0022-0531},
  abstract = {This essay introduces the symposium on computer science and economic theory.},
  journal = {Journal of Economic Theory},
  author = {Blume, Lawrence and Easley, David and Kleinberg, Jon and Kleinberg, Robert and Tardos, {\'E}va},
  year = {2015},
  keywords = {Algorithmic game theory,Implementation,Learning in games,Mechanism design,Networks},
  pages = {1-13},
  file = {/Users/xiefangzhou/Zotero/storage/RGJ7VSUW/Blume et al. - 2015 - Introduction to computer science and economic theo.pdf;/Users/xiefangzhou/Zotero/storage/DC9XF3QP/S0022053114001616.html}
}

@article{alaya2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1906.08540},
  primaryClass = {cs, stat},
  title = {Screening {{Sinkhorn Algorithm}} for {{Regularized Optimal Transport}}},
  abstract = {We introduce in this paper a novel strategy for efficiently approximate the Sinkhorn distance between two discrete measures. After identifying neglectible components of the dual solution of the regularized Sinkhorn problem, we propose to screen those components by directly setting them at that value before entering the Sinkhorn problem. This allows us to solve a smaller Sinkhorn problem while ensuring approximation with provable guarantees. More formally, the approach is based on a reformulation of dual of Sinkhorn divergence problem and on the KKT optimality conditions of this problem, which enable identification of dual components to be screened. This new analysis leads to the Screenkhorn algorithm. We illustrate the efficiency of Screenkhorn on complex tasks such as dimensionality reduction or domain adaptation involving regularized optimal transport.},
  journal = {arXiv:1906.08540 [cs, stat]},
  author = {Alaya, Mokhtar Z. and B{\'e}rar, Maxime and Gasso, Gilles and Rakotomamonjy, Alain},
  year = {2019},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/xiefangzhou/Zotero/storage/3IU953TU/Alaya et al. - 2019 - Screening Sinkhorn Algorithm for Regularized Optim.pdf;/Users/xiefangzhou/Zotero/storage/IHHVH4ZW/1906.html}
}

@article{appadurai1990,
  title = {Disjuncture and {{Difference}} in the {{Global Cultural Economy}}},
  volume = {2},
  issn = {0899-2363},
  language = {en},
  number = {2},
  journal = {Public Culture},
  author = {Appadurai, Arjun},
  year = {1990},
  pages = {1-24},
  file = {/Users/xiefangzhou/Zotero/storage/WBXYLFCT/Disjuncture-and-Difference-in-the-Global-Cultural.html}
}


